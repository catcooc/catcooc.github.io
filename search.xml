<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>那些年我做过的菜（持续更新）</title>
    <url>/post/%E2%80%980%E2%80%99.html</url>
    <content><![CDATA[<p><img
src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/default_cover5.jpg" /></p>
<p>一些菜谱和图片</p>
<span id="more"></span>
<h2 id="抹茶芝士小蛋糕-6个">抹茶芝士小蛋糕 6个</h2>
<p><a
href="https://www.bilibili.com/video/BV1J8411J7Vz/?spm_id_from=333.999.0.0">参考视频</a></p>
<ul>
<li><p>奶油奶酪 200g 微波炉10 s 至软乎</p></li>
<li><p>加入 糖 10g</p></li>
<li><p>另一个 白巧克力40g 隔水加热</p></li>
<li><p>加入 抹茶粉 8g 隔水加热 加入 巧克力 搅拌</p></li>
<li><p>加入鸡蛋 常温 搅拌</p></li>
<li><p>加入 淡奶油 80g 到 细腻光滑的糊状 挤入摸具烤盘加入热水 水浴法
烤箱中层 155度 烘烤 20分钟 晾凉 冷藏一夜食用更佳</p>
<!--more-->
<center>
<p><img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/%E5%A4%B1%E8%B4%A5%E7%9A%84%E6%8A%B9%E8%8C%B6%E8%8A%9D%E5%A3%AB%E5%B0%8F%E8%9B%8B%E7%B3%95.jpg"/></p>
</center>
<center>
<p><b><font size ='2'>失败的抹茶芝士蛋糕</font></b></p>
</center>
<p></font></p></li>
</ul>
<h2 id="平底锅可做夹心面包">平底锅可做夹心面包</h2>
<p><a
href="https://www.bilibili.com/video/BV16M411a7aG/?spm_id_from=333.999.0.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e">参考视频</a></p>
<ul>
<li><p>蛋黄3个</p></li>
<li><p>玉米淀粉 20g</p></li>
<li><p>细砂糖25g</p></li>
<li><p>牛奶200g<br />
过筛得到细腻糊状<br />
倒入不粘锅 中小火 不停搅拌<br />
熬到能够挂勺子 后关火 放凉待用</p></li>
<li><p>高筋面粉 160g</p></li>
<li><p>细砂糖15g</p></li>
<li><p>牛奶120g</p></li>
<li><p>酵母 2g</p></li>
<li><p>盐 1g<br />
揉成光滑面团 盖上保鲜膜 醒发 15分钟<br />
用手按压排气后 平均分成8等分 揉圆以后 用擀面杖擀成牛舌状<br />
挤入 之前卡仕达酱 提起面皮 盖上收口捏边<br />
盖上保鲜膜发酵至1.5倍大 平底锅 小火预热 放入面包胚 边缘放少许清水
（20g）<br />
加盖焖煎至底部金黄翻面 重复</p></li>
</ul>
<h2 id="雪媚娘">雪媚娘</h2>
<p><a
href="https://www.bilibili.com/video/BV1rS4y1r7BW/?spm_id_from=333.999.0.0">参考简简厨房视频</a></p>
<p>饼皮</p>
<ul>
<li><p>糯米粉 100g</p></li>
<li><p>玉米淀粉300g</p></li>
<li><p>细砂糖65g</p></li>
<li><p>牛奶180g<br />
搅拌均匀 过筛 蒙上保鲜膜上锅蒸15到20分钟</p></li>
<li><p>黄油 40g<br />
加进去 拌一下 放凉 轻微烫手 揉 在放板上揉 要撒一些熟檽米粉防粘</p></li>
<li><p>蓝风车 淡奶油 150g 糖粉10.5g</p></li>
<li><p>奶油75g 水果75g（草莓推荐 奶油草莓 芒果小台农最好
其次大台农</p></li>
</ul>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/失败雪媚娘1.png"/>
</center>
<center>
<b><font size ='2'>失败的雪媚娘</font></b>
</center>
<p></font></p>
<h2 id="红薯小方">红薯小方</h2>
<p><a
href="https://www.bilibili.com/video/BV1ve4y1K7KS/?spm_id_from=333.999.0.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e">参考视频</a></p>
<ul>
<li>200g 红薯</li>
</ul>
<p>上锅蒸熟 压成泥</p>
<ul>
<li><p>25g 白砂糖</p>
<p>揉成不粘手面团 分成25g小剂子，再整成小方块</p></li>
<li><p>150g 糯米粉</p>
<p>刷一点水 加芝麻 空气炸锅 170度20分钟 烤箱是180度二十分钟</p>
<p><img
src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/%E7%BA%A2%E8%96%AF%E5%B0%8F%E6%96%B9.jpg" /></p></li>
</ul>
<h2 id="咖啡杏仁饼">咖啡杏仁饼</h2>
<p><a
href="https://www.bilibili.com/video/BV15K411276e/?spm_id_from=333.999.0.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e">参考链接</a></p>
<ul>
<li><p>黄油 70g</p></li>
<li><p>高筋面粉100g</p></li>
<li><p>糖粉 37g</p></li>
<li><p>盐1g</p></li>
<li><p>杏仁片40g</p>
<p>揉混合均匀 不能 长时间搅拌</p></li>
<li><p>速溶咖啡粉 3g</p></li>
<li><p>牛奶 30g</p>
<p>然后加入融化咖啡 加入杏仁片 桌面上 加一点面粉 揉成一条 冷冻
半小时</p>
<p>风炉模式170度 20分钟</p></li>
</ul>
<h2 id="伯爵红茶曲奇">伯爵红茶曲奇</h2>
<p><a
href="https://www.bilibili.com/video/BV1ZG4y1h7HP/?spm_id_from=333.337.search-card.all.click&amp;vd_source=89cd1bd958a3eea212de763dc113559e">参考链接</a></p>
<ul>
<li><p>黄油100g</p></li>
<li><p>糖粉45g</p></li>
<li><p>蛋黄液10g 搅拌顺滑</p></li>
<li><p>低筋粉140g</p></li>
<li><p>伯爵红茶粉5g</p>
<p>揉成面团 搞成圆柱状 再滚一层白糖 冷冻30分钟 切片 室温放一会 烤箱
170度 20分钟</p></li>
</ul>
<h2 id="提拉米苏">提拉米苏</h2>
<p><a
href="https://www.bilibili.com/video/BV164411E78L/?spm_id_from=333.999.0.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e">参考大碗拿铁视频</a></p>
<ul>
<li>2到3个蛋黄 糖60g 一点利口酒 隔水加热</li>
<li>马斯卡彭250g 加一点利口酒</li>
<li>奶油200-250ml 打发至不流动有清晰痕迹</li>
</ul>
<h2 id="猫舌饼干蛋清消耗">猫舌饼干（蛋清消耗）</h2>
<p><a
href="https://www.bilibili.com/video/BV14i4y1Q74v/?spm_id_from=333.999.0.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e">参考视频</a></p>
<p>黄油40g 糖粉40g</p>
<p>分两到三次加入蛋清40g</p>
<p>可可味 低筋面粉35g，可可粉5g 抹茶味 低筋面粉37g 抹茶粉3g</p>
<p>烤箱预热后 上下火180度10分钟</p>
<h2 id="芒果班戟">芒果班戟</h2>
<h3 id="饼皮">饼皮</h3>
<ul>
<li>大号鸡蛋两颗 （60-65克/个）</li>
<li>牛奶 280克</li>
<li>低筋面粉 100克</li>
<li>细砂糖 35克</li>
<li>无盐黄油（融化）20克</li>
</ul>
<h3 id="馅料">馅料</h3>
<ul>
<li>淡奶油 300克</li>
<li>糖粉 25克</li>
<li>2个芒果</li>
</ul>
<p>冰箱冷藏2小时后食用<br />
<a
href="https://www.bilibili.com/video/BV1ZP411T7m5/?spm_id_from=333.337.search-card.all.click&amp;vd_source=89cd1bd958a3eea212de763dc113559e">参考视频</a></p>
<h2 id="磅蛋糕">磅蛋糕</h2>
<ul>
<li>发酵黄油100g</li>
<li>细砂糖100g</li>
<li>鸡蛋100g</li>
<li>低粉100g</li>
<li>泡打粉2g</li>
<li>香草半根</li>
</ul>
<ol type="1">
<li>低粉过筛、泡打粉过筛，混合。</li>
<li>黄油室温软化，加入细砂糖，打至颜色变浅。</li>
<li>分3次加入蛋液，每加一次，打发融合再加入下一次。</li>
<li>筛入粉类，拌至无干粉，出现光泽。</li>
<li>装入裱花袋，挤入模具，刮刀整成两边高中间低。</li>
<li>烤箱中下层，实际温度170烤45分钟左右。</li>
<li>距离工作台10cm震一下，脱膜冷却。</li>
<li>放凉后裹上保鲜膜，冰箱冷藏到第三天，可食用。</li>
</ol>
<p>视频中模具尺寸:长20cm 上口宽10cm 底宽9cm 高7cm</p>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/%E9%A6%99%E8%8D%89%E7%A3%85%E8%9B%8B%E7%B3%95.jpg"/>
</center>
<center>
<b><font size ='2'>磅蛋糕</font></b>
</center>
<p></font></p>
<h2 id="粑粑糕">粑粑糕</h2>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/%E6%AA%BD%E7%B1%B3%E7%B2%91%E7%B2%91%E7%B3%95.jpg"/>
</center>
<center>
<b><font size ='2'>檽米粑粑糕</font></b>
</center>
<p></font></p>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/%E7%B2%91%E7%B2%91%E7%B3%95.jpg"/>
</center>
<center>
<b><font size ='2'>粑粑糕</font></b>
</center>
<p></font></p>
<ul>
<li>全蛋150g</li>
<li>细砂糖40g</li>
<li>糯米粉90g</li>
<li>泡打粉2g</li>
<li>黄油30g</li>
<li>牛奶30g</li>
</ul>
<ol type="1">
<li>糯米粉和泡打粉提前混合，黄油、牛奶，隔水加热至50-60度左右。</li>
<li>蛋液里加入砂糖，高速打发4分钟左右，画Z字缓慢消失，低速打发2分钟左右。</li>
<li>筛入低粉，搅拌至无干粉后 (约40下)。</li>
<li>顺着刮刀淋入黄油和牛奶(温度在50-60度之间)
，继续搅拌30次左右，拌匀即可。</li>
<li>倒入模具，震两下，烤箱实际温度150度烤30-35分钟左右.出炉脱模晾凉。</li>
</ol>
<p><a
href="https://www.bilibili.com/video/BV1UG4y1479Q/?spm_id_from=333.337.search-card.all.click&amp;vd_source=89cd1bd958a3eea212de763dc113559e">视频</a>中双倍烤了40分钟，用的古早模具
(24cm 24cm 8cm)</p>
<h2 id="蛋糕卷">蛋糕卷</h2>
<p>蛋糕体:</p>
<p>蛋黄85g 玉米油50g 牛奶60g 低粉70g<br />
蛋白170g 砂糖60g 盐1g 柠檬汁或白醋5g</p>
<ol type="1">
<li>蛋黄和蛋白分离，蛋白冷冻。蛋黄常温或者隔水加热到20-30度。</li>
<li>玉米油和牛奶隔水加热到40度左右，同时乳化。</li>
<li>乳化好的玉米油和牛奶加入到蛋黄里搅拌融合。</li>
<li>筛入低粉用Z字搅拌法拌匀。</li>
<li>蛋白里加入盐、柠檬汁或者白醋，三次加糖打至小弯钩。</li>
<li>取3分之一蛋白加入蛋黄糊，拌匀后，全部倒入剩下蛋白霜里拌匀。</li>
<li>从高处倒入烤盘150度烤30分钟，按需再加烤5分钟左右 (热风循环)</li>
<li>出炉凉至温热。抹上香提奶油，放上芒果粒，卷起来冷藏1小时。</li>
</ol>
<p>夹心: 淡奶油250g 糖粉15g台农芒果粒200g</p>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/%E8%9B%8B%E7%B3%95%E5%8D%B7%E8%BF%98%E6%B2%A1%E5%8D%B7.jpg"/>
</center>
<center>
<b><font size ='2'>蛋糕卷还没有卷</font></b>
</center>
<p></font></p>
<p><a
href="https://www.bilibili.com/video/BV1QY4y1t7fu/?spm_id_from=333.999.0.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e">视频</a></p>
<h2 id="芒果戚风蛋糕">芒果戚风蛋糕</h2>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/%E8%8A%92%E6%9E%9C%E5%A5%B6%E6%B2%B9%E6%88%9A%E9%A3%8E%E8%9B%8B%E7%B3%95.jpg"/>
</center>
<center>
<b><font size ='2'>没有抹面的工具 所以品相不太好</font></b>
</center>
<p></font></p>
<h2 id="巴斯克芝士蛋糕">巴斯克芝士蛋糕</h2>
<p>奶油奶酪 350<br />
白砂糖 90g<br />
2全蛋+1蛋 黄<br />
鲜奶油 150g<br />
低筋面粉 10g</p>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/%E5%B7%B4%E6%96%AF%E5%85%8B%E8%8A%9D%E5%A3%AB.jpg"/>
</center>
<center>
<b><font size ='2'>巴斯克芝士蛋糕</font></b>
</center>
<p></font></p>
<p><a
href="https://www.bilibili.com/video/BV1P5411L7hY/?spm_id_from=333.337.search-card.all.click&amp;vd_source=89cd1bd958a3eea212de763dc113559e">视频</a></p>
<h2 id="古早蛋糕">古早蛋糕</h2>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/%E5%8F%A4%E6%97%A9%E8%9B%8B%E7%B3%95%E5%A4%AA%E6%B9%BF%E4%BA%86.jpg"/>
</center>
<center>
<b><font size ='2'>古早蛋糕太湿了</font></b>
</center>
<p></font></p>
<p>蛋黄120 蛋白260 低粉105 砂糖85 植物油85 牛奶96 檬汁或白醋5g</p>
<ol type="1">
<li>蛋白蛋黄分离，蛋白拿去冷冻。</li>
<li>牛奶加热至40度左右备用，低粉过筛.</li>
<li>玉米油加热至70度，倒入面粉里拌匀，往面粉里倒的时候温度是75度左右</li>
<li>加入生奶拌匀，加入蛋黄拌匀。</li>
<li>蛋白加盐、柠檬汁或白醋，低速打发至鱼眼泡加入三分之一砂糖，高速打发到细腻状态</li>
<li>再加入三分之一砂糖，中速打发到有纹路状态</li>
<li>加入剩下砂糖。低速到打至提起打蛋头为小弯钩盆里是大弯钩的状态。约6分钟左右。</li>
<li>三分之一蛋白加入蛋黄拌匀，再倒入剩下蛋白拌匀</li>
<li>水浴法 (加入2-3cm常温水)</li>
<li>40升以下烤箱140度90分钟左右。或者130度烘烤110分钟左右40升以上烤箱150度70分钟左右。</li>
<li>脱模撕掉油纸或油布即可。</li>
</ol>
<p>如果是活底磨具，可以烤盘加水放在最下层然后上面放烤网，烤网上放蛋糕模具。或者多包几层锡纸。</p>
<h2 id="香蕉巧克力蛋糕">香蕉巧克力蛋糕</h2>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/%E9%A6%99%E8%95%89%E5%B7%A7%E5%85%8B%E5%8A%9B%E8%9B%8B%E7%B3%95.jpg"/>
</center>
<center>
<b><font size ='2'> 香蕉巧克力蛋糕</font></b>
</center>
<p></font></p>
<h2 id="烤鸡翅">烤鸡翅</h2>
<p><a
href="https://www.bilibili.com/video/BV14b411g7Gm/?spm_id_from=333.999.0.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e">大碗拿铁版</a></p>
<p>13个鸡翅版</p>
<ul>
<li>盐 1g</li>
<li>胡椒粉 1g</li>
<li>生抽酱油 10g 耗油 8g</li>
<li>食用油 20g 当中润滑剂</li>
</ul>
<p>鸡翅两面包好锡纸，放到预热到150度的烤箱45分钟，刷蜂蜜水
再放进230度的烤箱3分钟左右 翻面在3分钟（或许要久一点还有待研究 如果炙烤
（可以选高温和低温 就选低温）3分钟一面 鸡翅出现黑班就换一面）</p>
<p><a
href="https://www.bilibili.com/video/BV1JK4y1v77U/?spm_id_from=333.999.0.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e">二狗版</a></p>
<ul>
<li><p>蜂蜜1勺</p></li>
<li><p>耗油1勺</p></li>
<li><p>生抽2勺</p></li>
<li><p>蒜粉 1勺</p></li>
<li><p>料酒 0.5勺</p></li>
<li><p>胡椒粉一点点</p></li>
<li><p>十三香一点点</p>
<p>烤箱180度 刷蜂蜜 上下火150 度 烤15分钟 再刷水 继续180°
10分钟</p></li>
</ul>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/烤翅1.png"/>
</center>
<center>
<b><font size ='2'>烤翅 表面还不够焦</font></b>
</center>
<p></font></p>
<h2 id="葱爆羊肉">葱爆羊肉</h2>
<p><a
href="https://www.bilibili.com/video/BV1tM411b7PU/?spm_id_from=333.999.0.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e">参考简简厨房视频</a></p>
<p>腌制</p>
<ul>
<li>小苏打1g</li>
<li>糖 2g</li>
<li>料酒12g</li>
<li>酱油12 g</li>
<li>生粉（玉米淀粉）5g</li>
<li>植物油25g</li>
</ul>
<p>腌制30分钟</p>
<p>料汁</p>
<ul>
<li>盐1g</li>
<li>白糖3g</li>
<li>料酒5g</li>
<li>酱油 5g</li>
<li>陈醋5g</li>
<li>味精1g</li>
</ul>
<p>大葱（切成滚刀葱 露出截面）</p>
<p>大火锅热 300°c 放油转匀 放羊肉 停几秒 再翻面 羊肉8成熟 边缘微焦</p>
倒掉一些油 留一点 大火暴香大葱 加入 羊肉 料汁 大火一分钟<br />

<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/葱爆羊肉1.png"/>
</center>
<center>
<b><font size ='2'>第一次尝试的葱爆羊肉</font></b>
</center>
<p></font></p>
<h1 id="烹饪知识">烹饪知识</h1>
<h2 id="风炉热风平炉模式怎么用">风炉、热风、平炉模式怎么用？</h2>
<p>许多准备入手和新入手风炉一体烤箱的集美，了解这2点，风炉、热风、平炉3⃣️种模式轻松掌握切换！</p>
<p>首先我们了解三种模式的运作方式：</p>
<p>❤️平炉：通过上下管发热进行烘烤，是我们最常用的烤箱模式；</p>
<p>❤️热风：通过侧面风扇配合上下发热管进行烘烤；</p>
<p>❤️风炉：通过后置风扇配合后置发热管进行烘烤；</p>
<p>接着我们了解这3种模式的使用：</p>
<p>❤️平炉：可以单独使用，适合烤制蛋糕、面包、司康等湿润口感的食物；</p>
<p>❤️热风：不能单独使用，一般在平炉最后10分钟开启，适合需要表面上色均匀，如巴斯克蛋糕、蛋挞、焦糖类食物；</p>
<p>❤️风炉：可以单独使用，适合烤制麻薯、饼干、蛋黄酥、薄脆等酥松口感类食物；</p>
<p>希望通过以上这2点能让大家更直面的分清烤箱的平炉、热风、风炉三个模式。</p>
<p>对于风炉一体烤箱我个人也有一些建议：</p>
<p>不论是私房烘焙还是新手入门，选择风炉一体烤箱是最能一步到位的；</p>
<p>1.容量选50L或以上，这样能保证出品量和效率；</p>
<p>2.内胆材质选易清洗、耐用的陶瓷油内胆；</p>
<p>3.炉灯选能长亮的，配合拍摄录像；</p>
<p>4.玻璃门选双层，隔热和防爆炸；</p>
<h2
id="烤箱没有风炉模式可以用什么替代">烤箱没有风炉模式可以用什么替代</h2>
<p>没有热风模式一样可以烤，但是要通过一次次试验，掌握温度，用165度中层。<br />
根据烤箱和烤盘厚薄调整。但是决定成败的绝不仅仅是烤箱和温度，有很多因素，比如蛋清干湿程度、糖粉质量、糖浆温度、搅拌手法等等。<br />
如果是风干食材的数量比较大的话，建议还是采用风干机。因为烤箱热风循环功能对于食材的温度一般在230℃左右，烘烤时间会比较长。如果是对食材的烘干程度和时间有追求的话，建议还是采用风干机。</p>
<h2 id="不同面粉分类以及特性用法">不同面粉分类以及特性用法</h2>
<h3 id="分类">分类</h3>
<p>按照面粉中蛋白质含量的高低，面粉分为特高筋面粉、高筋面粉、中筋面粉、低筋面粉四类。特高筋面粉中蛋白质含量为14%以上；高筋面粉中蛋白质含量约12.5-13.5%；中筋面粉中蛋白质含量为9.5-12.0%；低筋面粉中蛋白质含量在8.5%以下</p>
<h3 id="特性用法">特性用法</h3>
<p>特高筋面粉：面粉中蛋白质含量最高的一种面粉，它的蛋白质含量在14%以上。因为特高筋面粉具有的筋度强、粘度大的特点，所以比较适合用来炸油条、做空心面条，以及做面筋，还有其他咬劲大的面食和点心用。</p>
<p>高筋面粉：它的蛋白质含量在13.5%左右，一般蛋白质含量超过11.5%，就可以称为高筋面粉。高筋面粉的筋度比较大，所以我们在做面包时，应该选择高筋面粉，加入黄油以后，可以揉出“手套膜”。平时我们在制作弹性大，有嚼劲的面包、面条，以及个别烘焙食品如：泡芙、千层酥时，都要选择使用高筋面粉。</p>
<p>中筋面粉：我们平时最常见，也是最常用的一种面粉，被称为普通面粉。在我们北方人家里，一年四季吃的都是这种普通面粉。蒸馒头、蒸包子、做手擀面、包饺子都是用的中筋面粉。这种面粉外包装袋上可能不会特别标明是中筋面粉。在购买时，只要看到用途写着可以用来做馒头、包子、面条、烙饼、饺子的，就是中筋面粉。</p>
<p>低筋面粉：筋性比较弱的一种面粉，常被用来做蛋糕。像最近比较火的戚风蛋糕、古早蛋糕、以及虎皮蛋糕等，都是需要用低筋面粉来制作的。</p>
<p><strong><a href="https://github.com/Anduin2017/HowToCook"><br />
HowToCook</a></strong> 一个github上别人写的开源菜谱</p>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/%E5%A5%B6%E6%B2%B9%E5%8F%91%E6%B3%A1.png"/>
</center>
<center>
<b><font size ='2'>奶油发泡网图</font></b>
</center>
<p></font></p>
]]></content>
      <tags>
        <tag>菜</tag>
      </tags>
  </entry>
  <entry>
    <title>The Cherno C++ 教程 笔记 自用</title>
    <url>/post/191602.html</url>
    <content><![CDATA[<p>The Cherno C++ 教程 笔记 <a
href="https://www.youtube.com/playlist?list=PLlrATfBNZ98dudnM48yfGUldqGD0S4FFb">原视频</a>
<a
href="https://www.bilibili.com/video/BV1Dk4y1j7oj?p=53&amp;vd_source=89cd1bd958a3eea212de763dc113559e">b站搬运</a>
仅仅自用知乎已经有很多优秀的笔记了</p>
<span id="more"></span>
<h2 id="visual-studio如何设置才能支持c11141720这些新标准的特性">Visual
Studio如何设置才能支持C++11/14/17/20这些新标准的特性？</h2>
<p>这里以最新的 Visual Studio 2022 来说明一下设置方法吧，毕竟 Community
版本都是可以免费使用的。</p>
<p>当新建一个C++项目后（比如新建了一个“C++控制台应用”项目），然后在“解决方案资源管理器”中右击项目，在下拉菜单中点击最下面的“属性”。在打开的“属性”窗口中，选择“配置属性
| C/C++ | 语言”，找到“C++ 语言标准”。可以看到它的默认选择是支持“ISO
C++14标准”（如下图），当然C++14标准包含了C++11的特性</p>
<p>我们点开这个“C++ 语言标准”的下拉框，可以看到其它选择有“ISO
C++14标准”“ISO C++17标准”“ISO
C++20标准”等，按照需要选择其中一个就行了（提示：高版本的标准是包含低版本标准的特性的）。</p>
<p><strong>如果选择了“ISO
C++20标准”，还需要注意下面的问题</strong>：</p>
<p>Visual C++ 2022 对
C++20标准中的“模块”新特性尚未完全支持。编写或使用自己的“模块”通常没有问题，但是，导入标准库头文件（如下语句）还不能使用，编译会出错。</p>
<p>解决这个问题的方法，可以向项目中添加一个单独的头文件（比如叫“HeaderUnits.h”，如下图），</p>
<p>在这个头文件中预先导入本项目中需要导入的所有标准库头文件，比如
HeaderUnits.h 文件内容如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> once</span></span><br><span class="line"><span class="keyword">import</span> &lt;iostream&gt;;</span><br><span class="line"><span class="keyword">import</span> &lt;vector&gt;;</span><br><span class="line"><span class="keyword">import</span> &lt;optional&gt;;</span><br><span class="line"><span class="keyword">import</span> &lt;utility&gt;;</span><br></pre></td></tr></table></figure>
<p>接下来，在“解决方案资源管理器”中右击
HeaderUnits.h，选择下拉菜单的“属性”。然后在“属性”窗口中选择“配置属性 |
常规”，设置“项类型”为“C/C++编译器”（如下图），然后点击“应用”按钮。</p>
<p>下一步，选择“配置属性 | C/C++ | 高级”，将“编译为”设置为“作为 C++
标头单元编译”（如下图），然后点击“确定”按钮。(这一步不知道怎一设置就报错)</p>
<p><a
href="https://www.zhihu.com/tardis/bd/ans/3156194796?source_id=1001">源地址</a></p>
<h2 id="c-如何工作">C++ 如何工作</h2>
<p>建一个project 在 资源文件（source）添加cpp文件</p>
<p>源文件</p>
<p><code>#后面是预处理语句 # include &lt;iostream&gt; 编译器会把iostream 和我们的代码黏起来</code></p>
<p>&lt;&lt; 重载运算符</p>
<p>debug 会默认关掉所有优化 release模式会更快 我们可以定制编译的是exe
还dll（库文件）</p>
<p>cpp 编译（会把预处理的头文件和你的cpp粘好一起编译） object file.obj
linker（在属性里可以定义一些选项）合并多个obj（解析obj之间依赖的符号比如外部函数）为执行文件</p>
<p>ctrl +F7 单独编译当前文件所以不会有exe()</p>
<p>visual studio 存放很奇怪文件orz</p>
<p>我们查bug 主要看 output window error list是垃圾</p>
<p>申明 告知编译器函数存在</p>
<p>头文件可以用来放一堆申明函数</p>
<p>定义 定义一个函数要干什么</p>
<h2 id="编译">编译</h2>
<p>在项目 属性 C/C++ 预处理器 -&gt;预处理到文件设置 是 会得到
.j文件是预处理结束后的文件</p>
<p><code>#define INTEGER int  C++会替换前面的词 为后面的词</code></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">if</span>  <span class="comment">//判断是否为真决定是否执行代码</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>
<p>obj 文件是 二进制 我们可以用 项目属性 c/c++ 输出文件 汇编程序输出里
设置输出可读汇编语言</p>
<p>result=a*b</p>
<p>return result</p>
<p>和之间return result 在debug
和release模式是不一样的你可以查看汇编代码发现这一点</p>
<p>链接 主要焦点是找到每个符号和函数在哪里</p>
<p>static int Multiply</p>
<p>static 意味着该函数只在这个cpp翻译单元里定义</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span>  <span class="type">void</span> <span class="title">Log</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* message)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    std::cout&lt;&lt; message&lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>inline 会把Log函数替换为Log定义的内容</p>
<p>link c++需要一个入口点（Entry Point在 linker里面 )
入口点不一定是main</p>
<h2 id="c变量">C++变量</h2>
<p>不同变量在c++中唯一的区别就是存储的大小</p>
<p>int 一般 4字节（依赖编译器）</p>
<p>unsigned int</p>
<p>char short int long long long</p>
<p>char a=65 char a='A'</p>
<p>其他类型赋值字符会变成数字 shot a='A' 打印为65</p>
<p>float variable= 5.5 //其实定义了双精度double</p>
<p>float variable= 5.5f//f可以大写也可以小写 表示定义的是浮点数</p>
<p>bool 1 byte 虽然理论是只要1bit</p>
<p>sizeof(variable) 返回变量大小</p>
<p>指针(pointer)* 和引用(reference)&amp;</p>
<p>c++ 函数 为了减少代码重复</p>
<p>调用函数 会使用堆栈结构</p>
<p>每次我们调用函数时，编译器生成call指令 创建一个堆栈结构
把参数这样的东西推进堆栈 把一个放回地址压入堆栈
在跳到二进制执行文件的不同部分执行函数指令
为了push回结果还要回到调用函数的地方 在内存里跳来跳去
所以有时候要用inline</p>
<p>c++头文件</p>
<p><code>#pragma once //pragma 编译之前先处理 once 只在一个翻译单元复制一次</code></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifndef</span> _LOG_H</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> _LOG_H</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">InitLog</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function">strcut <span class="title">Player</span><span class="params">()</span></span>;</span><br><span class="line"><span class="comment">//如果_LOG_H没定义则运行定义这部分</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>
<p>引号可以指定相对路径的文件</p>
<p>尖括号只用与编译器包含的路径</p>
<h2 id="visual-studio-配置">visual studio 配置</h2>
<p>在设置断点以后按F5 右键断点 go to disassembly 可以查看汇编</p>
<p>visual studio 显示的 解决方案目录不是真实的点击
显示所有文件可以看到真实的目录 可以建一个src 文件夹 把所有
cpp文件加入到里面</p>
<p>我们可以自定义visu studio 的输出文件和 中间文件目录
在项目的属性常规里</p>
<p>设置输出目录<code>$(SolutionDir)bin\$(Platform)\$(Configuration)\</code></p>
<p>中间目录</p>
<p><code>$(SolutionDir)bin\intermediates\$(Platform)\$(Configuration)\</code></p>
<p><code>$(SolutionDir)</code>这些宏的意义可以在编辑里查看</p>
<h2 id="c指针">c++指针</h2>
<p>指针是一个整数 存储地址的数字
指针的类型的类型是告诉编译器存的地址指的东西是包含多少字节的
这样可以在用<code>*</code>读取的时候配置适当内存
<code>int*ptr</code>指针表示 当我们用<code>*ptr= 10;</code>
要设置四字节的内存所以<code>void *ptr</code>指针 不能
<code>*ptr=10</code></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span>* ptr = <span class="number">0</span>; <span class="comment">// NULL nullptr 都是相同的</span></span><br><span class="line"><span class="type">int</span> var = <span class="number">8</span>;</span><br><span class="line"><span class="type">void</span>* ptr2 = &amp;var;<span class="comment">// &amp; 取出 var的地址 ptr2 现在存着var的地址</span></span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">char</span>* buffer = <span class="keyword">new</span> <span class="type">char</span>[<span class="number">8</span>];<span class="comment">//申请一个 8字节的内存 记录它的第一个地址</span></span><br><span class="line"><span class="built_in">memset</span>(buffer, <span class="number">0</span>, <span class="number">8</span>);<span class="comment">//填入 0 到8个字节</span></span><br><span class="line"></span><br><span class="line"><span class="type">char</span>** ptr = &amp;buffer;<span class="comment">//指向存地址的地址 你可以在内存了读取他的值 然后查找（要倒着输入是反着存的）会找到存0的8个字节</span></span><br><span class="line"><span class="keyword">delete</span>[] buffer; <span class="comment">//删除buffer的内存</span></span><br></pre></td></tr></table></figure>
<h2 id="c引用">C++引用</h2>
<p>引用本身不是变量</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span>&amp;  <span class="comment">//&amp;是类型的一部分</span></span><br><span class="line"><span class="type">int</span> a = <span class="number">5</span>;</span><br><span class="line"><span class="type">int</span>&amp; ref = a;<span class="comment">//ref 是a的别名 要马上赋值</span></span><br></pre></td></tr></table></figure>
<p>引用可以把变量传入函数 并改变它
指针也可以做到这一点但要注意改的是地址还是地址里的值（注意优先级
<code>*value++</code> 改的是地址 <code>（*value)++</code>改的是值）</p>
<h2 id="c类">c++类</h2>
<p>类只是对数据和功能组合在一起的一种方法。类不会带来新的功能
没有它也可以实现你想要到 它有点像语法糖 。</p>
<p>与结构体的对比</p>
<p>类一般默认是私有的 结构体默认是公开的</p>
<p>可以用<code>#define struct class</code>把struct 定义为 class 当public
和private要重写</p>
<h2 id="static-有不同意义-取决上下文">static 有不同意义 取决上下文</h2>
<p>一种在类和结构体外表示该变量只在他定义的翻译单元生效
另一种在类和结构体内 表示这个类和结构体的静态变量和方法 在所有实例里生效
改变一个所有实例都会改变 可以直接用类名加变量名或者函数名引用
和命名空间很类似比如 <code>std::cout</code></p>
<p>同时在函数中使用static 可以延长变量的存在的周期 如果没有static
函数内变量会在 函数使用完后销毁 有了static 这个变量会在函数用完后还存在
且只能在函数内使用 不能再外部调用</p>
<p>extern var尝试从其他翻译单元找到变量var的定义</p>
<p>尽量用静态变量</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Log</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* message)</span></span>;</span><br><span class="line"><span class="comment">//#define struct class</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Player</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:<span class="comment">//为了可以在类外访问他们</span></span><br><span class="line">	<span class="type">int</span> x, y;</span><br><span class="line">	<span class="type">int</span> speed;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="type">void</span>  <span class="title">Move</span><span class="params">(<span class="type">int</span> xa, <span class="type">int</span> ya)</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		x += xa * speed;</span><br><span class="line">		y += ya * speed;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">Print</span><span class="params">()</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		std::cout &lt;&lt; x &lt;&lt; <span class="string">&quot;, &quot;</span> &lt;&lt; y &lt;&lt; std::endl;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;;<span class="comment">//有分号</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Singleton</span> </span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">private</span>: </span><br><span class="line">	<span class="type">static</span> Singleton* s_Instance;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="function"><span class="type">static</span> Singleton&amp; <span class="title">Get</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> *s_Instance; &#125;</span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">Hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="built_in">Log</span>(<span class="string">&quot;mmm&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Singleton2</span></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="function"><span class="type">static</span> Singleton2&amp; <span class="title">Get</span><span class="params">()</span> </span></span><br><span class="line"><span class="function">	</span>&#123; </span><br><span class="line">		<span class="type">static</span> Singleton2 instance; <span class="comment">//如果没有用static 建立的实例会在函数定义的花括号外被销毁 要把引用static Singleton2&amp; 改成复制static Singleton2</span></span><br><span class="line">		<span class="keyword">return</span> instance; </span><br><span class="line">	&#125;</span><br><span class="line">	<span class="function"><span class="type">void</span> <span class="title">Hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="built_in">Log</span>(<span class="string">&quot;mmmm&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">Singleton* Singleton::s_Instance = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;	</span><br><span class="line">	Singleton::<span class="built_in">Get</span>().<span class="built_in">Hello</span>();</span><br><span class="line">	Singleton2::<span class="built_in">Get</span>().<span class="built_in">Hello</span>();</span><br><span class="line">	<span class="keyword">if</span> (<span class="number">6</span> == <span class="number">6</span>)</span><br><span class="line">		<span class="built_in">Log</span>(<span class="string">&quot;Hello World!&quot;</span>);<span class="comment">//可以加&#123;&#125; 也可以不加 esle if 其实是 else + if 所以可以写成 </span></span><br><span class="line">	<span class="comment">//else </span></span><br><span class="line">	<span class="comment">//		if ()&#123;</span></span><br><span class="line">	<span class="comment">// &#125;</span></span><br><span class="line">	<span class="comment">//std::cout &lt;&lt; &quot; hello &quot; &lt;&lt; std::endl;</span></span><br><span class="line">	<span class="type">void</span>* ptr = <span class="number">0</span>; <span class="comment">// NULL nullptr 和0 都是相同的</span></span><br><span class="line">	<span class="type">int</span> var = <span class="number">8</span>;</span><br><span class="line">	<span class="type">void</span>* ptr2 = &amp;var;<span class="comment">// &amp; 取出 var的地址 ptr2 现在存着var的地址</span></span><br><span class="line">	Player player;</span><br><span class="line">	player.x = <span class="number">5</span>;</span><br><span class="line">	player.y = <span class="number">5</span>;</span><br><span class="line">	Player player2 = &#123; <span class="number">8</span>,<span class="number">7</span> &#125;;</span><br><span class="line">	player2.<span class="built_in">Print</span>();</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">if</span> (i % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line">			<span class="keyword">continue</span>;<span class="comment">//跳过符合此次判断的i  如果是break直接跳出循环  如果是return 直接结束函数</span></span><br><span class="line">		<span class="built_in">Log</span>(<span class="string">&quot;Hello&quot;</span>);</span><br><span class="line"></span><br><span class="line">		<span class="type">char</span>* buffer = <span class="keyword">new</span> <span class="type">char</span>[<span class="number">8</span>];<span class="comment">//申请一个 8字节的内存 记录它的第一个地址</span></span><br><span class="line">		<span class="built_in">memset</span>(buffer, <span class="number">0</span>, <span class="number">8</span>);<span class="comment">//填入 0 到8个字节</span></span><br><span class="line"></span><br><span class="line">		<span class="type">char</span>** ptr = &amp;buffer;<span class="comment">//指向存地址的地址 你可以在内存了读取他的值 然后查找（要倒着输入是反着存的）会找到存0的8个字节</span></span><br><span class="line">		<span class="keyword">delete</span>[] buffer; <span class="comment">//删除buffer的内存</span></span><br><span class="line">		std::cout &lt;&lt; i &lt;&lt; std::endl;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	std::cin.<span class="built_in">get</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="c-枚举">c++ 枚举</h2>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">MyEnum</span> </span><br><span class="line">&#123;</span><br><span class="line">	A,B,C</span><br><span class="line">&#125;;</span><br><span class="line">MyEnum test = A;</span><br></pre></td></tr></table></figure>
<h2 id="c虚函数">c++虚函数</h2>
<p>可以复写继承类的虚函数实现特定功能
会生成v表来实现引入额外内存开销但是是可以接受的</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Play</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> std::string <span class="title">GetName</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="string">&quot;Play&quot;</span>; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Player</span> : <span class="keyword">public</span> Play</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	std::string m_Name;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="built_in">Player</span>(<span class="type">const</span> std::string&amp; name)</span><br><span class="line">		: <span class="built_in">m_Name</span>(name) &#123;&#125;</span><br><span class="line">	<span class="function">std::string <span class="title">GetName</span><span class="params">()</span> <span class="keyword">override</span></span>&#123; <span class="keyword">return</span> m_Name; &#125;<span class="comment">//override不是必要的但可以保证不出错</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PrintName</span><span class="params">(Play* e)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	std::cout &lt;&lt; e-&gt;<span class="built_in">GetName</span>() &lt;&lt; std::endl;<span class="comment">//如果Play没有virtual虚函数那么GetName就不会被复写打印的总是Play</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>纯虚函数允许我们定义一个没有定义的函数然后强迫使用子类去实现它
不然不能实例化</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Printable</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="function"><span class="keyword">virtual</span> std::string <span class="title">GetClassName</span><span class="params">()</span> </span>= <span class="number">0</span>;<span class="comment">//纯虚函数</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">classA</span> : <span class="keyword">public</span> Printable</span><br><span class="line">&#123;</span><br><span class="line">	<span class="function">std::string <span class="title">GetClassName</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123; <span class="keyword">return</span> <span class="string">&quot;A&quot;</span>; &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Printclass</span><span class="params">(Printable* obj)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	std::cout &lt;&lt; obj-&gt;<span class="built_in">GetClassName</span>() &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="类中的可见性">类中的可见性</h2>
<p>private 只能在类中或者类的友元调用访问 protected
可以在子类和定义类调用但是不能在类外面用 public哪都行</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> expmle[<span class="number">5</span>];<span class="comment">//在函数结束就会消失</span></span><br><span class="line"><span class="type">int</span> * ptr = example;</span><br><span class="line">*(<span class="type">int</span>*)((<span class="type">char</span>*)ptr + <span class="number">8</span>) = <span class="number">6</span> ; <span class="comment">//等同与*(ptr +2 ) =6 c++中数组指针加一个数字等同于他代表的地址加乘以该指针类型大小之后的数字 </span></span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span>* another = <span class="keyword">new</span> <span class="type">int</span>[<span class="number">5</span>]; <span class="comment">//在堆上创建会一直在除非delete</span></span><br><span class="line"><span class="keyword">delete</span>[] another;</span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span>* another = <span class="keyword">new</span> <span class="type">int</span>[<span class="number">5</span>];<span class="comment">//在类中定义会导致间接寻址类不是保存数组数据而是地址</span></span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;array&gt;</span></span></span><br><span class="line"><span class="type">int</span> a[<span class="number">5</span>];</span><br><span class="line"><span class="type">int</span> count = <span class="built_in">sizeof</span>(a)/<span class="built_in">sizeof</span>(<span class="type">int</span>);</span><br><span class="line">std::array&lt;<span class="type">int</span>,5&gt; another;<span class="comment">//another.size() 会有额外开销所以用原始数组会比较快</span></span><br></pre></td></tr></table></figure>
<h2 id="const">const</h2>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">char</span>*  name=<span class="string">&quot;mkk&quot;</span>;<span class="comment">//字符串用双引号 字符用单引号 用const是因为这个字符串常常不能修改 要想有可以改的请定义字符数组 char name[]=&quot;mkk&quot;;</span></span><br><span class="line"><span class="type">char</span> name2[<span class="number">4</span>]=&#123;<span class="string">&#x27;m&#x27;</span>,<span class="string">&#x27;k&#x27;</span>,<span class="string">&#x27;k&#x27;</span>,<span class="number">0</span>&#125;;<span class="comment">//最后打&#x27;\0&#x27;也行 这样打印name2会直打到mkk不会显示其他内存的东西 </span></span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt; stdlib.h&gt;</span><span class="comment">//可以用strlen得到长度但是如果中间有\0会得到到\0的长度</span></span></span><br><span class="line">std::string name=<span class="string">&quot;mkk&quot;</span>;<span class="comment">// std::string(&quot;mkk&quot;) + &quot;hello!&quot;;</span></span><br><span class="line">name += <span class="string">&quot; hello!&quot;</span>;</span><br><span class="line"><span class="type">bool</span> contains = name.<span class="built_in">find</span>(<span class="string">&quot;kk&quot;</span>) != std::string:npos</span><br><span class="line">    </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">PrintString</span><span class="params">(<span class="type">const</span> std::string&amp; string)</span><span class="comment">// const 表示承诺不修改变量 std::string&amp;表示引用不是复制  直接std::string string 也行不过会额外复制数据造成开销</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	std::cout &lt;&lt; string  &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">char</span>* name = <span class="string">u8&quot;mkk&quot;</span>;<span class="comment">//u8是不必须的每个字母1字节</span></span><br><span class="line"><span class="type">const</span> <span class="type">wchar_t</span>* name2 = <span class="string">L&quot;mkk&quot;</span>;<span class="comment">//windows 每个字母2字节 Linux 每个字母4字节 mac 可能有也是4</span></span><br><span class="line"><span class="type">const</span> <span class="type">char16_t</span>* name3 = <span class="string">u&quot;mkk&quot;</span>;<span class="comment">//每个字母2字节</span></span><br><span class="line"><span class="type">const</span> <span class="type">char32_t</span>* name4 = <span class="string">U&quot;mkk&quot;</span>;<span class="comment">//每个字母4字节</span></span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> MAX_AGE = <span class="number">90</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span>* a = <span class="keyword">new</span> <span class="type">int</span>;<span class="comment">//和 int const* a = new int;一样 不能改变指针指向的值 但是可以改变指针本身即地址</span></span><br><span class="line">*a = <span class="number">2</span>;<span class="comment">//把指针指向2 不行因为定义了const指针</span></span><br><span class="line">a = (<span class="type">int</span>*)&amp;MAX_AGE;<span class="comment">//改变a本身即地址</span></span><br><span class="line"><span class="type">int</span>* <span class="type">const</span> b = <span class="keyword">new</span> <span class="type">int</span>;<span class="comment">//可以改变指向的东西但不能改变指向地址</span></span><br><span class="line">*b = <span class="number">2</span>;<span class="comment">//把指针指向2 可以</span></span><br><span class="line">b = (<span class="type">int</span>*)&amp;MAX_AGE;<span class="comment">//不可以</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span>* <span class="type">const</span> c = <span class="keyword">new</span> <span class="type">int</span>;<span class="comment">//</span></span><br><span class="line">*c = <span class="number">2</span>;<span class="comment">//把指针指向2 不可以</span></span><br><span class="line">c = (<span class="type">int</span>*)&amp;MAX_AGE;<span class="comment">//不可以</span></span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Entity</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	<span class="type">int</span> m_X, m_Y;</span><br><span class="line">    <span class="keyword">mutable</span> <span class="type">int</span> var;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="function"><span class="type">int</span> <span class="title">GetX</span><span class="params">()</span> <span class="type">const</span><span class="comment">//仅在类中的用法表示改方法不会改变类成员的值</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">        var=<span class="number">2</span>; <span class="comment">// 可以因为是mutable</span></span><br><span class="line">        <span class="comment">// m_X = 10; 会报错</span></span><br><span class="line">		<span class="keyword">return</span> m_X;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Entity</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	<span class="type">int</span>* m_X, m_Y;<span class="comment">//这里只有m_X是指针 m_Y不是 要想是 这样int* m_X, *m_y</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="function"><span class="type">const</span> <span class="type">int</span>* <span class="type">const</span> <span class="title">GetX</span><span class="params">()</span> <span class="type">const</span><span class="comment">//仅在类中的用法表示改方法不会改变类成员的值</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">        </span><br><span class="line">		<span class="keyword">return</span> m_X;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">PrintEntity</span><span class="params">(<span class="type">const</span> Entity&amp; e)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    std::cout &lt;&lt; e.<span class="built_in">GetX</span>() &lt;&lt; std::endl;<span class="comment">//要求GetX是一个const方法不让不行 另外类里面也可以有两个GetX方法一个是const的一个不是 这里会自动调用const的</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> x = <span class="number">8</span>;</span><br><span class="line"><span class="keyword">auto</span> f = [=]() <span class="keyword">mutable</span> <span class="comment">// [=] 表示把值传进lambda函数f里面 所以正常情况下不能改变x </span></span><br><span class="line">	<span class="comment">//加了mutable 相当于把x的值赋值给一个y然后外面y++ 在打印他不会改变外面的x函数</span></span><br><span class="line">	<span class="comment">//[&amp;]表示引用传递</span></span><br><span class="line">	&#123;</span><br><span class="line">		x++;</span><br><span class="line">		std::cout &lt;&lt; x &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">	&#125;;</span><br><span class="line"><span class="built_in">f</span>();<span class="comment">//9</span></span><br><span class="line">std::cout &lt;&lt; x &lt;&lt; std::endl;<span class="comment">//8</span></span><br></pre></td></tr></table></figure>
<h2 id="三元判断算符">三元判断算符</h2>
<p>python</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x <span class="keyword">if</span> (x &gt; y) <span class="keyword">else</span> y</span><br></pre></td></tr></table></figure>
<p>c++</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">(x &gt; y) ? x : y;</span><br></pre></td></tr></table></figure>
<p>julia</p>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line">(x &gt; y) ? x : y;</span><br></pre></td></tr></table></figure>
<h2 id="new">new</h2>
<p>在堆上创建 会比较慢 要主动delete 不然会一直在</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> a = <span class="number">2</span>;</span><br><span class="line"><span class="type">int</span>* b = <span class="keyword">new</span> <span class="type">int</span>[<span class="number">50</span>];</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Entity* e = <span class="keyword">new</span> <span class="built_in">Entity</span>();<span class="comment">//还可以写成这样Entity* e = new Entity[50];</span></span><br><span class="line"><span class="comment">//Entity* e = (Entity*)malloc(sizeof(Entity)); //和Entity* e = new Entity();相同不过malloc只是分配了内存没有分配构造函数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">delete</span>[] b;</span><br><span class="line"><span class="keyword">delete</span> e;</span><br></pre></td></tr></table></figure>
<h2 id="隐式转换">隐式转换</h2>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Entity</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	std::string m_Name;</span><br><span class="line">	<span class="type">int</span> m_Age;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="built_in">Entity</span>(<span class="type">const</span> std::string&amp; name)</span><br><span class="line">		: <span class="built_in">m_Name</span>(name), <span class="built_in">m_Age</span>(<span class="number">-1</span>)&#123;&#125;</span><br><span class="line">	<span class="built_in">Entity</span>(<span class="type">int</span> age)</span><br><span class="line">		: <span class="built_in">m_Name</span>(<span class="string">&quot;Unknown&quot;</span>) , <span class="built_in">m_Age</span>(age) &#123;&#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">PrintEntity</span><span class="params">(<span class="type">const</span> Entity&amp; entity)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">//print</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> main</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PrintEntity</span>(<span class="number">22</span>);</span><br><span class="line"><span class="built_in">PrintEntity</span>(<span class="built_in">Entity</span>(<span class="string">&quot;Cherno&quot;</span>));<span class="comment">//PrintEntity(&quot;Cherno&quot;); 注释的是不可行的 </span></span><br><span class="line"><span class="comment">//因为要两次转换一次是从const char 到string 再从string到entity</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Entity  aa = <span class="built_in">Entity</span>(<span class="string">&quot;mkk&quot;</span>);<span class="comment">//Entity aa = &quot;mkk&quot;;//aa(&quot;mkk&quot;); Entity aa = Entity(&quot;mkk&quot;);</span></span><br><span class="line"><span class="comment">//未注释的写法是一种隐式转换 在构造函数前面加上explicit可以禁止隐式转换 必须显式调用构造函数才可以比如Entity aa(&quot;mkk&quot;);</span></span><br><span class="line">Entity bb = <span class="number">22</span>;<span class="comment">//bb(22);Entity  bb = Entity(22);</span></span><br><span class="line">Entity* aaa = <span class="keyword">new</span> <span class="built_in">Entity</span>(std::<span class="built_in">string</span>(<span class="string">&quot;mkk&quot;</span>));<span class="comment">//直接 Entity* aaa = new Entity(&quot;mkk&quot;)不行</span></span><br><span class="line"><span class="keyword">delete</span> aaa;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="运算符重载">运算符重载</h2>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Vector2</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">float</span> x, y;</span><br><span class="line">	<span class="built_in">Vector2</span>(<span class="type">float</span> x, <span class="type">float</span> )</span><br><span class="line">		: <span class="built_in">x</span>(x) ,<span class="built_in">y</span>(y) &#123;&#125;</span><br><span class="line">	<span class="function">Vector2 <span class="title">Add</span><span class="params">(<span class="type">const</span> Vector2&amp; other)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function">	</span>&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="built_in">Vector2</span>(x + other.x, y + other.y);</span><br><span class="line">	&#125;</span><br><span class="line">	Vector2 <span class="keyword">operator</span>+(<span class="type">const</span> Vector2&amp; other)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="built_in">Add</span>(other);</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="type">bool</span> <span class="keyword">operator</span>==(<span class="type">const</span> Vector2&amp; other) <span class="type">const</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">return</span> x == other.x  &amp;&amp; y == other.y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">std::ostream&amp; <span class="keyword">operator</span>&lt;&lt;(std::ostream&amp; stream, <span class="type">const</span> Vector2&amp; other)</span><br><span class="line">&#123;</span><br><span class="line">	stream &lt;&lt; other.x &lt;&lt; <span class="string">&quot;,&quot;</span> &lt;&lt; other.y ;</span><br><span class="line">	<span class="keyword">return</span> stream;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    	<span class="function">Vector2 <span class="title">p</span><span class="params">(<span class="number">4.0f</span>, <span class="number">4.0f</span>)</span></span>;</span><br><span class="line">	<span class="function">Vector2 <span class="title">s</span><span class="params">(<span class="number">0.5f</span>, <span class="number">1.1f</span>)</span></span>;</span><br><span class="line">	Vector2 result1 = p + s;</span><br><span class="line">	std::cout &lt;&lt; p &lt;&lt; std::endl;</span><br><span class="line">	std::cout &lt;&lt; result1 &lt;&lt; std::endl;</span><br><span class="line">	std::cin.<span class="built_in">get</span>();</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="this">this</h2>
<p>this 是一个指向当前对象实例的指针，该方法属于这个对象的实例。</p>
<p>为了调用非静态方法，要一个实例化对象 这就要用到this</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">Void <span class="title">PrintEntity</span><span class="params">(<span class="type">const</span> Entity&amp; e)</span><span class="comment">//类内要用先声明一下</span></span></span><br><span class="line"><span class="function"><span class="keyword">class</span> Entity</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">    	<span class="type">int</span> x,y;</span><br><span class="line">    <span class="built_in">Entity</span>(<span class="type">int</span> x ,<span class="type">int</span> y)<span class="comment">//这里的x和成员名一样直接x=x;不行 当然</span></span><br><span class="line">        <span class="comment">//:x(x),y(y)可以</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">//Entity* const e =this; </span></span><br><span class="line">        <span class="keyword">this</span>-&gt;x=x;</span><br><span class="line">        <span class="keyword">this</span>-&gt;y=y;</span><br><span class="line">        Entity&amp; e = *<span class="keyword">this</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">PrintEntity</span>(*<span class="keyword">this</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//delet this 可以但不要</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">GetX</span><span class="params">()</span> <span class="type">const</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="type">const</span> Entity&amp; e = *<span class="keyword">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"><span class="function">Void <span class="title">PrintEntity</span><span class="params">(<span class="type">const</span> Entity&amp; e)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//Print</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="作用域指针">作用域指针</h2>
<p>自动消除new 创建的东西</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ScopedPtr</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    Entity* m_Ptr;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">ScopedPtr</span>(Entity* ptr)</span><br><span class="line">        : <span class="built_in">m_Ptr</span>(ptr)</span><br><span class="line">        &#123;</span><br><span class="line">            </span><br><span class="line">        &#125;</span><br><span class="line">    ~<span class="built_in">ScopedPtr</span>()</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">delete</span> m_Ptr;</span><br><span class="line">    &#125;</span><br><span class="line">        </span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    &#123;</span><br><span class="line">       ScopedPtr e = <span class="keyword">new</span> <span class="built_in">Entity</span>();</span><br><span class="line">        </span><br><span class="line">    &#125;<span class="comment">//尽管用来了new 但是ScopedPtr 在作用域之后会自动销毁Entity</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="智能指针">智能指针</h2>
<p>让你摆脱new 和delete的方法</p>
<p>unique_ptr你不能复制他 一复制就消失一个</p>
<p>shared_ptr会计数你 的引用（复制或者共享） 当计数为0 释放内存</p>
<p>weak_ptr 不会增加引用计数其他和shared_ptr一样</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="comment">//std::unique_ptr&lt;Entity&gt; entity(new Entity());</span></span><br><span class="line">	std::unique_ptr&lt;Entity&gt; entity = std::<span class="built_in">make_unique</span>&lt;Entity&gt;();</span><br><span class="line">	<span class="comment">//std::unique_ptr&lt;Entity&gt; e0 = entity; 不行</span></span><br><span class="line">	entity-&gt;<span class="built_in">Print</span>();<span class="comment">//(*entity).Print();</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">	std::shared_ptr&lt;Entity&gt; e0;</span><br><span class="line">	&#123;</span><br><span class="line">		std::shared_ptr&lt;Entity&gt; sharedEntity = std::<span class="built_in">make_shared</span>&lt;Entity&gt;();</span><br><span class="line"></span><br><span class="line">		std::shared_ptr&lt;Entity&gt; e0 = sharedEntity;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	&#125;<span class="comment">//e0还在 因为现在引用计数是1</span></span><br><span class="line">&#125;<span class="comment">//e0会坚持到这里</span></span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">	std::weak_ptr&lt;Entity&gt; e1;</span><br><span class="line">	&#123;</span><br><span class="line">		std::shared_ptr&lt;Entity&gt; sharedEntity1 = std::<span class="built_in">make_shared</span>&lt;Entity&gt;();</span><br><span class="line">		e1 = sharedEntity1;</span><br><span class="line">	&#125;<span class="comment">//e1消失 因为weak_ptr不增加引用计数</span></span><br><span class="line">&#125;<span class="comment">//e1不会坚持到这里</span></span><br></pre></td></tr></table></figure>
<h2 id="c的复制与拷贝">c++的复制与拷贝</h2>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> a =<span class="number">1</span>;</span><br><span class="line"><span class="type">int</span> b =a;<span class="comment">//ab是两个不同的的变量 有不同的地址</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Vector2 * a= new Vector2();</span><br><span class="line">Vector2 * b =a;</span><br><span class="line">b-&gt;x=2;</span><br></pre></td></tr></table></figure>
<h2 id="箭头算符-">箭头算符-&gt;</h2>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">e-&gt;x=<span class="number">0</span>;<span class="comment">// (*e).x=0;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Vector3</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">float</span> x, y,z;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">int</span> offset= (<span class="type">int</span>)&amp;((Vector3*)<span class="literal">nullptr</span>)-&gt;z;</span><br><span class="line">	std::cout&lt;&lt; offset &lt;&lt; std:;endl;<span class="comment">//x打印0 y打印4 z打印8</span></span><br><span class="line">	std::cin.<span class="built_in">get</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="动态数组">动态数组</h2>
<p>Vector 其实是arraylist</p>
<p>一般很慢要优化</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt; string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Vertex</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">float</span> x, y, z;</span><br><span class="line">	<span class="built_in">Vertex</span>(<span class="type">float</span> x, <span class="type">float</span> y, <span class="type">float</span> z)</span><br><span class="line">		: <span class="built_in">x</span>(x), <span class="built_in">y</span>(y), <span class="built_in">z</span>(z)</span><br><span class="line">	&#123;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="built_in">Vertex</span>(<span class="type">const</span> Vertex&amp; vertex)</span><br><span class="line">		: <span class="built_in">x</span>(vertex.x) ,<span class="built_in">y</span>(vertex.y),<span class="built_in">z</span>(vertex.z)</span><br><span class="line">	&#123;</span><br><span class="line">		std::cout &lt;&lt; <span class="string">&quot;copied!&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">std::ostream&amp; <span class="keyword">operator</span>&lt;&lt;(std::ostream&amp; stream, <span class="type">const</span> Vertex&amp; vertex)</span><br><span class="line">&#123;</span><br><span class="line">	stream &lt;&lt; vertex.x &lt;&lt; <span class="string">&quot;,&quot;</span> &lt;&lt; vertex.y &lt;&lt; <span class="string">&#x27;,&#x27;</span> &lt;&lt; vertex.z;</span><br><span class="line">	<span class="keyword">return</span> stream;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Function</span><span class="params">(<span class="type">const</span> std::vector&lt;Vertex&gt;&amp; vertices)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	std::vector&lt;Vertex&gt; vertices;<span class="comment">//尽量不要用指针分配因为这样可以在一条线上存储会更快 </span></span><br><span class="line">	<span class="comment">//当然如果一条线不够 要重新分配内存要复制会很慢这时候指针会好一些因为数据不在连续内存里</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">//vertices.reserve(3);告诉要分配多少内存这样在内存小于3时不用减少内存可以减少复制</span></span><br><span class="line">	vertices.<span class="built_in">push_back</span>(&#123; <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span> &#125;);<span class="comment">//会产生两次复制 一次是把在main函数栈上的变量复制到vecotor里面 </span></span><br><span class="line">	<span class="comment">//一次是调整大小的复制</span></span><br><span class="line">	vertices.<span class="built_in">push_back</span>(&#123;<span class="number">16</span>,<span class="number">73</span>,<span class="number">9</span> &#125;);<span class="comment">//vertices.emplace_back(16,73,9 );</span></span><br><span class="line">	<span class="comment">//注释这段直接在vecotor那里建立变量所以不会增加复制</span></span><br><span class="line">	</span><br><span class="line">	<span class="built_in">Function</span>(vertices);</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; vertices.<span class="built_in">size</span>(); i++)</span><br><span class="line">		std::cout &lt;&lt; vertices[i] &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">	vertices.<span class="built_in">erase</span>(vertices.<span class="built_in">begin</span>() + <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> (Vertex v : vertices)  <span class="comment">//Vetex&amp; v : vertices</span></span><br><span class="line">		std::cout &lt;&lt; v &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	std::cin.<span class="built_in">get</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>优化技巧</p>
<p><code>vertices.reserve(3);</code></p>
<p><code>vertices.emplace_back(1,2,3);</code></p>
<h2 id="c使用库">c++使用库</h2>
<p>库包含 库目录library和包含目录include 包含目录是一堆头文件
lib目录是预先构建的二进制文件</p>
<p>动态库和静态库区别是静态库已经包含在exe里面了
而动态库要是通过exe在运行时调用外部库函数要额外链接</p>
<p>https://www.glfw.org/</p>
<p>下你要的文件 32 或64</p>
<p>然后会用到include 和lib-vrc20？？(选最新的)</p>
<p>在lib-vrc20？？里面</p>
<p>glfw3.dll 运行时动态链接的库</p>
<p>glfw3dll.lib是一种静态库 和glfw3.dll一起用
(可以不用我们可以在glfw3.dll访问 但有它可以更快)</p>
<p>glfw3.lib静态库(你不想用其他两个dll可以链接它)</p>
<h2 id="c创建使用库">C++创建使用库</h2>
<p>创建一个game项目 在里面创建src 创建Appliction.cpp 在game
添加一个Engine项目 然后设置属性 常规 配置类型为静态库 添加 Engine
一个src 创建Engine.h Engine.cpp</p>
<p>点击game解决方案属性 C/C++ 附属包含目录填入
<code>$(SolutionDir)Engine\src;</code>
点击game解决方案在添加里点引用勾选 Engine</p>
]]></content>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title>时间序列比赛(一)草稿</title>
    <url>/post/f9ac47d6.html</url>
    <content><![CDATA[<p>尝试学习时间序列预测 用它参加比赛</p>
<span id="more"></span>
<h1 id="时间序列比赛一草稿">时间序列比赛(一)草稿</h1>
<h2 id="lightgbm">LightGBM</h2>
<h2 id="数据预处理">数据预处理</h2>
<p>LightGBM
针对样本多的问题提出了<strong>基于梯度的单边采样算法（Gradient-based
One-Side
Sampling，GOSS）</strong>；针对特征多的问题提出了<strong>互斥特征捆绑算法（Exclusive
Feature Bundling，EFB）</strong></p>
<p>GOSS 处理大梯度数据在加上随机抽样得到的梯度的数据</p>
<p>EFB</p>
<p>对于稀疏的特征合并（合并的特征相应的偏移一定量 相加）
减少特征降低维度</p>
<p>直方图加速运算</p>
<h2 id="多机并行">多机并行</h2>
<p>选举并行</p>
<p>每个 worker
拥有一部分数据的全部特征，它们输出各自的局部直方图，然后汇总成全局直方图，在全局直方图上找出最优分裂点。</p>
<h1 id="比赛内容">比赛内容</h1>
<p><a
href="https://www.marsbigdata.com/competition/details?id=40144958741">比赛网站</a></p>
<p><img
src="https://file.public.marsbigdata.com/2023/09/28/62dfR3wroe_f0osL.png" /></p>
<p>评估指标: RMSE.<br />
<span class="math display">\[
R M S E=\sqrt{\frac{1}{\mathrm{n}}
\sum_{\mathrm{i}=1}^{\mathrm{n}}\left(\mathrm{y}_{\mathrm{i}}-\mathrm{y}_{\mathrm{i}}^*\right)^2}
\]</span><br />
<span class="math inline">\(\mathrm{y}_1\)</span>
式中为第个数据的真实值， <span
class="math inline">\(\mathrm{y}_1^*\)</span> 为第个数据的预测值， <span
class="math inline">\(\mathrm{n}\)</span> 为样本总数。</p>
<p>观察数据 （着重观察一些标准差奇怪的数据 或者
模型预测的均方误差很大的点） 考虑是否剔除一些数据比如去年数据
一些异常数据可以剔除 或者 插值</p>
<p>结合数据查找 外部数据 比如天气气温</p>
<p>节假日信息</p>
<p>h3数据解码可以考虑解码成经纬度 直接丢入模型里
也可以总结成城市作为一个特征（同时如果有城市的拥堵数据也可以利用）</p>
<p>是按小时的预测然后相加预测天 还是按天预测吗
取决于你有没有小时特征的数据没有的话 按天预测会更好</p>
<h2 id="数据清理以及预处理">数据清理以及预处理</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">train_power_forecast_history = pd.read_csv(<span class="string">&#x27;./data1/train/power_forecast_history.csv&#x27;</span>)</span><br><span class="line">train_power = pd.read_csv(<span class="string">&#x27;./data1/train/power.csv&#x27;</span>)</span><br><span class="line">train_stub_info = pd.read_csv(<span class="string">&#x27;./data1/train/stub_info.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">test_power_forecast_history = pd.read_csv(<span class="string">&#x27;./data1/test/power_forecast_history.csv&#x27;</span>)</span><br><span class="line">test_stub_info = pd.read_csv(<span class="string">&#x27;./data1/test/stub_info.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 聚合数据</span></span><br><span class="line">train_df = train_power_forecast_history.groupby([<span class="string">&#x27;id_encode&#x27;</span>,<span class="string">&#x27;ds&#x27;</span>]).head(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">del</span> train_df[<span class="string">&#x27;hour&#x27;</span>]</span><br><span class="line"></span><br><span class="line">test_df = test_power_forecast_history.groupby([<span class="string">&#x27;id_encode&#x27;</span>,<span class="string">&#x27;ds&#x27;</span>]).head(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">del</span> test_df[<span class="string">&#x27;hour&#x27;</span>]</span><br><span class="line"></span><br><span class="line">tmp_df = train_power.groupby([<span class="string">&#x27;id_encode&#x27;</span>,<span class="string">&#x27;ds&#x27;</span>])[<span class="string">&#x27;power&#x27;</span>].<span class="built_in">sum</span>()</span><br><span class="line">tmp_df.columns = [<span class="string">&#x27;id_encode&#x27;</span>,<span class="string">&#x27;ds&#x27;</span>,<span class="string">&#x27;power&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并充电量数据</span></span><br><span class="line">train_df = train_df.merge(tmp_df, on=[<span class="string">&#x27;id_encode&#x27;</span>,<span class="string">&#x27;ds&#x27;</span>], how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 合并数据</span></span><br><span class="line">train_df = train_df.merge(train_stub_info, on=<span class="string">&#x27;id_encode&#x27;</span>, how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line"></span><br><span class="line">cs=train_df[<span class="string">&#x27;h3&#x27;</span>].apply(<span class="keyword">lambda</span> x:h3.h3_to_geo(x))</span><br><span class="line">cs1=[cs[i][<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(cs))];</span><br><span class="line">cs2=[cs[i][<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(cs))];</span><br><span class="line">train_df[<span class="string">&#x27;ceter1&#x27;</span>]=cs1;</span><br><span class="line">train_df[<span class="string">&#x27;ceter12&#x27;</span>]=cs2;</span><br><span class="line"><span class="keyword">del</span> train_df[<span class="string">&#x27;h3&#x27;</span>]</span><br><span class="line">test_df = test_df.merge(test_stub_info, on=<span class="string">&#x27;id_encode&#x27;</span>, how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line"></span><br><span class="line">cs=test_df[<span class="string">&#x27;h3&#x27;</span>].apply(<span class="keyword">lambda</span> x:h3.h3_to_geo(x))</span><br><span class="line">cs1=[cs[i][<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(cs))];</span><br><span class="line">cs2=[cs[i][<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(cs))];</span><br><span class="line">test_df[<span class="string">&#x27;ceter1&#x27;</span>]=cs1;</span><br><span class="line">test_df[<span class="string">&#x27;ceter12&#x27;</span>]=cs2;</span><br><span class="line"><span class="keyword">del</span> test_df[<span class="string">&#x27;h3&#x27;</span>]</span><br><span class="line"><span class="comment">###填充缺失值</span></span><br><span class="line">train_df[<span class="string">&#x27;f3&#x27;</span>][train_df[<span class="string">&#x27;f3&#x27;</span>].isnull()]=train_df.mean()[<span class="string">&#x27;f3&#x27;</span>]</span><br><span class="line">test_df[<span class="string">&#x27;f3&#x27;</span>][train_df[<span class="string">&#x27;f3&#x27;</span>].isnull()]=test_df.mean()[<span class="string">&#x27;f3&#x27;</span>]</span><br><span class="line">train_df=train_df.fillna(method = <span class="string">&#x27;bfill&#x27;</span>)</span><br><span class="line">test_df=test_df.fillna(method = <span class="string">&#x27;bfill&#x27;</span>)</span><br><span class="line"><span class="comment">### 数据预处理</span></span><br><span class="line">train_df[<span class="string">&#x27;flag&#x27;</span>] = train_df[<span class="string">&#x27;flag&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;A&#x27;</span>:<span class="number">0</span>,<span class="string">&#x27;B&#x27;</span>:<span class="number">1</span>&#125;)</span><br><span class="line">test_df[<span class="string">&#x27;flag&#x27;</span>] = test_df[<span class="string">&#x27;flag&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;A&#x27;</span>:<span class="number">0</span>,<span class="string">&#x27;B&#x27;</span>:<span class="number">1</span>&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="利用坐标查找城市依赖百度地图api">利用坐标查找城市依赖<a
href="https://lbsyun.baidu.com/faq/api?title=webapi">百度地图api</a></h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> h3 <span class="keyword">import</span> h3</span><br><span class="line">train_stub_info = pd.read_csv(<span class="string">&quot;....train\\stub_info.csv&quot;</span>)</span><br><span class="line">test_stub_info = pd.read_csv(<span class="string">&quot;....test\\stub_info.csv&quot;</span>)</span><br><span class="line">train_day=[<span class="string">&quot;2022&quot;</span>+(<span class="string">&quot;0&quot;</span>+<span class="built_in">str</span>(i) <span class="keyword">if</span> i &lt; <span class="number">10</span> <span class="keyword">else</span> <span class="built_in">str</span>(i)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>,<span class="number">13</span>)]+[<span class="string">&quot;2023&quot;</span>+(<span class="string">&quot;0&quot;</span>+<span class="built_in">str</span>(i) <span class="keyword">if</span> i &lt; <span class="number">10</span> <span class="keyword">else</span> <span class="built_in">str</span>(i)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">5</span>)]</span><br><span class="line">test_day=[<span class="string">&quot;202304&quot;</span>]</span><br><span class="line"><span class="comment"># encoding:utf-8</span></span><br><span class="line"><span class="comment"># 根据您选择的AK已为您生成调用代码</span></span><br><span class="line"><span class="comment"># 检测您当前的AK设置了sn检验，本示例中已为您生成sn计算代码</span></span><br><span class="line"><span class="comment"># encoding:utf-8</span></span><br><span class="line"><span class="comment"># python版本为3.6.2</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立访问函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_city_frombd</span>(<span class="params">row</span>):</span><br><span class="line">    <span class="comment"># 服务地址</span></span><br><span class="line">    host = <span class="string">&quot;https://api.map.baidu.com&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 接口地址</span></span><br><span class="line">    uri = <span class="string">&quot;/reverse_geocoding/v3&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 此处填写你在控制台-应用管理-创建应用后获取的AK</span></span><br><span class="line">    ak = <span class="string">&quot;你的ak&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 此处填写你在控制台-应用管理-创建应用时，校验方式选择sn校验后生成的SK</span></span><br><span class="line">    sk = <span class="string">&quot;你的sk&quot;</span></span><br><span class="line">    coordinate = <span class="built_in">str</span>(row[<span class="string">&quot;latitude&quot;</span>]) +<span class="string">&#x27;,&#x27;</span>+ <span class="built_in">str</span>(row[<span class="string">&quot;longitude&quot;</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置您的请求参数</span></span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&quot;ak&quot;</span>:       ak,</span><br><span class="line">        <span class="string">&quot;output&quot;</span>:    <span class="string">&quot;json&quot;</span>,</span><br><span class="line">        <span class="string">&quot;coordtype&quot;</span>:    <span class="string">&quot;wgs84ll&quot;</span>,</span><br><span class="line">        <span class="string">&quot;extensions_poi&quot;</span>:    <span class="string">&quot;0&quot;</span>,</span><br><span class="line">        <span class="string">&quot;location&quot;</span>:   coordinate,</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 拼接请求字符串</span></span><br><span class="line">    paramsArr = []</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> params:</span><br><span class="line">        paramsArr.append(key + <span class="string">&quot;=&quot;</span> + params[key])</span><br><span class="line"></span><br><span class="line">    queryStr = uri + <span class="string">&quot;?&quot;</span> + <span class="string">&quot;&amp;&quot;</span>.join(paramsArr)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对queryStr进行转码，safe内的保留字符不转换</span></span><br><span class="line">    encodedStr = urllib.request.quote(queryStr, safe=<span class="string">&quot;/:=&amp;?#+!$,;&#x27;@()*[]&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在最后直接追加上您的SK</span></span><br><span class="line">    rawStr = encodedStr + sk</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算sn</span></span><br><span class="line">    sn = hashlib.md5(urllib.parse.quote_plus(rawStr).encode(<span class="string">&quot;utf8&quot;</span>)).hexdigest()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将sn参数添加到请求中</span></span><br><span class="line">    queryStr = queryStr + <span class="string">&quot;&amp;sn=&quot;</span> + sn</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 请注意，此处打印的url为非urlencode后的请求串</span></span><br><span class="line">    <span class="comment"># 如果将该请求串直接粘贴到浏览器中发起请求，由于浏览器会自动进行urlencode，会导致返回sn校验失败</span></span><br><span class="line">    url = host + queryStr</span><br><span class="line">    response = requests.get(url)</span><br><span class="line">    <span class="keyword">return</span> response.json().get(<span class="string">&#x27;result&#x27;</span>).get(<span class="string">&#x27;addressComponent&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">df_stub_process</span>(<span class="params">df</span>):</span><br><span class="line">    df[<span class="string">&#x27;center&#x27;</span>] = df[<span class="string">&#x27;h3&#x27;</span>].apply(<span class="keyword">lambda</span> x: h3.h3_to_geo(x))</span><br><span class="line">    df[[<span class="string">&#x27;latitude&#x27;</span>, <span class="string">&#x27;longitude&#x27;</span>]] = pd.DataFrame(df[<span class="string">&#x27;center&#x27;</span>].tolist(), columns=[<span class="string">&#x27;latitude&#x27;</span>, <span class="string">&#x27;longitude&#x27;</span>])</span><br><span class="line">    df[<span class="string">&#x27;latitude&#x27;</span>] = df[ <span class="string">&#x27;latitude&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">round</span>(x,<span class="number">6</span>))</span><br><span class="line">    df[<span class="string">&#x27;longitude&#x27;</span>] = df[ <span class="string">&#x27;longitude&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">round</span>(x,<span class="number">6</span>))</span><br><span class="line">    <span class="comment">#通过百度api返回城市信息</span></span><br><span class="line">    df[<span class="string">&#x27;address&#x27;</span>] = df[[<span class="string">&#x27;latitude&#x27;</span>,<span class="string">&#x27;longitude&#x27;</span>]].apply(get_city_frombd, axis = <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line">train_stub_info =df_stub_process(train_stub_info)</span><br><span class="line">train_stub_info[<span class="string">&#x27;city&#x27;</span>] = train_stub_info[<span class="string">&#x27;address&#x27;</span>].apply(<span class="keyword">lambda</span> x: x.get(<span class="string">&#x27;city&#x27;</span>))</span><br><span class="line"><span class="comment">#trian_stub_info.to_parquet(&#x27;trian_stub_info.parquet&#x27;)</span></span><br><span class="line">test_stub_info =df_stub_process(test_stub_info)</span><br><span class="line">test_stub_info[<span class="string">&#x27;city&#x27;</span>] = test_stub_info[<span class="string">&#x27;address&#x27;</span>].apply(<span class="keyword">lambda</span> x: x.get(<span class="string">&#x27;city&#x27;</span>))</span><br><span class="line"><span class="comment">#trian_stub_info.to_parquet(&#x27;trian_stub_info.parquet&#x27;)</span></span><br><span class="line">train_stub_info.loc[<span class="number">70</span>,<span class="string">&quot;city&quot;</span>]=<span class="string">&quot;南通市&quot;</span></span><br><span class="line">test_stub_info.loc[<span class="number">70</span>,<span class="string">&quot;city&quot;</span>]=<span class="string">&quot;南通市&quot;</span></span><br><span class="line">train_stub_info.to_csv(<span class="string">&#x27;train_stub_info.csv&#x27;</span>,index=<span class="string">&#x27;False&#x27;</span>,encoding=<span class="string">&#x27;gbk&#x27;</span>)</span><br><span class="line">test_stub_info.to_csv(<span class="string">&#x27;test_stub_info.csv&#x27;</span>,index=<span class="string">&#x27;False&#x27;</span>,encoding=<span class="string">&#x27;gbk&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> pypinyin</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pin</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;&quot;</span>.join(pypinyin.lazy_pinyin(x))</span><br><span class="line">city_name=<span class="built_in">set</span>(train_stub_info[<span class="string">&#x27;city&#x27;</span>].to_numpy())</span><br><span class="line">city_name_dict=&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> city_name:</span><br><span class="line">    city_name_dict[i]=pin(i)</span><br></pre></td></tr></table></figure>
<h2 id="爬取天气的代码">爬取天气的代码</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Get_data</span>(<span class="params">url</span>):</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/html;q=0.9,*/*;q=0.8&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Accept-Charset&#x27;</span>: <span class="string">&#x27;ISO-8859-1,utf-8;q=0.7,*;q=0.3&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Accept-Encoding&#x27;</span>: <span class="string">&#x27;gzip&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;close&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 请求得到网页内容</span></span><br><span class="line">    req = requests.get(url,headers=headers)</span><br><span class="line">    <span class="comment"># 格式化网页</span></span><br><span class="line">    soup=BeautifulSoup(req.text,<span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">    <span class="comment"># 使用soup对象findl所需内容</span></span><br><span class="line">    tables = soup.find(name=<span class="string">&#x27;table&#x27;</span>)</span><br><span class="line">    <span class="comment"># 提取需要的数据</span></span><br><span class="line">    data=pd.read_html(<span class="built_in">str</span>(tables),encoding=<span class="string">&#x27;utf-8&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_process</span>(<span class="params">datac,c</span>):</span><br><span class="line">    datac.columns=datac.values.tolist()[<span class="number">0</span>]</span><br><span class="line">    datac.drop(<span class="number">0</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">    datac[<span class="string">&#x27;ds&#x27;</span>] = datac[<span class="string">&#x27;日期&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(<span class="string">&quot;&quot;</span>.join(re.split(<span class="string">&quot;年|月|日&quot;</span>,x))))</span><br><span class="line">    datac[<span class="string">&#x27;ltmp&#x27;</span>] = datac[<span class="string">&#x27;最低气温/最高气温&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(re.split(<span class="string">&quot;℃|/|日&quot;</span>,x)[<span class="number">0</span>]))</span><br><span class="line">    datac[<span class="string">&#x27;htmp&#x27;</span>] = datac[<span class="string">&#x27;最低气温/最高气温&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">int</span>(re.split(<span class="string">&quot;℃|/|日&quot;</span>,x)[<span class="number">2</span>]))</span><br><span class="line">    datac[<span class="string">&#x27;city&#x27;</span>]=c</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> datac</span><br><span class="line">       </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> city_name:</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> train_day:</span><br><span class="line">        create_url = <span class="string">&#x27;http://www.tianqihoubao.com/lishi/&#x27;</span>+city_name_dict[i]+<span class="string">&#x27;/month/&#x27;</span>+j+<span class="string">&#x27;.html&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(i))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;正在打开网页：&#x27;</span>,create_url)</span><br><span class="line">        <span class="comment"># 获取数据</span></span><br><span class="line">        data = Get_data(create_url)</span><br><span class="line">       </span><br><span class="line">        <span class="comment"># 数据处理</span></span><br><span class="line">        data = data_process(data,i)</span><br><span class="line">        <span class="built_in">print</span>(data)</span><br><span class="line">        namedata=i+<span class="string">&#x27;month&#x27;</span>+j</span><br><span class="line">        data.to_csv(namedata+<span class="string">&#x27;.csv&#x27;</span>,index=<span class="string">&#x27;False&#x27;</span>,encoding=<span class="string">&#x27;gbk&#x27;</span>)</span><br><span class="line">        result.append(data)</span><br><span class="line">        <span class="built_in">print</span>(result[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_all = pd.concat(result,axis=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(data_all)</span><br><span class="line"><span class="comment"># 输出到本地</span></span><br><span class="line">data_all.to_csv(<span class="string">&#x27;cityweather.csv&#x27;</span>,index=<span class="string">&#x27;False&#x27;</span>,encoding=<span class="string">&#x27;gbk&#x27;</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>时间序列</tag>
        <tag>python</tag>
        <tag>LSTM</tag>
        <tag>RNN</tag>
        <tag>LightGBM</tag>
      </tags>
  </entry>
  <entry>
    <title>julia 数值分析</title>
    <url>/post/f212ddce.html</url>
    <content><![CDATA[<p>用julia实现一些数值方法 不过这些方法julia肯定有现成的库和函数解决了
我只是练练手瞎写一些东西</p>
<span id="more"></span>
<h2 id="浮点数-和多项式">浮点数 和多项式</h2>
<h3 id="多项式求值">多项式求值</h3>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> hornor(x::<span class="built_in">Float64</span>,n::<span class="built_in">Int64</span>,c::<span class="built_in">Vector</span>&#123;<span class="built_in">Float64</span>&#125;=[<span class="number">1.</span> <span class="keyword">for</span>  i <span class="keyword">in</span> <span class="number">1</span>:n+<span class="number">1</span>],b::<span class="built_in">Vector</span>&#123;<span class="built_in">Float64</span>&#125;=[<span class="number">0.</span> <span class="keyword">for</span>  i <span class="keyword">in</span> <span class="number">1</span>:n+<span class="number">1</span>])</span><br><span class="line">	y = c[<span class="keyword">end</span>]</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> n:-<span class="number">1</span>:<span class="number">1</span></span><br><span class="line">		y = y*( x- b[i])+c[i]</span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h3 id="实现浮点数表示">实现浮点数表示</h3>
<p><span class="math display">\[\pm 1 . b b b \cdots b \times
2^p\]</span></p>
<p>存储时需要尾数 bbbb 和指数p</p>
<p>IEEE舍入最近法则<br />
对于浮点精度，如果在二进制数右边的第 53 位是0，则向下舍去(在第 52
位后面截断)。如果第53位是1，则向上进位(在第 52位上加
1)，除了在1右边的所有已知位都是0，在这种情况下当且仅当第52位是1时在第52位上加1。</p>
<p>一个有趣的快速求平方根倒数算法 <a
href="https://www.bilibili.com/video/BV18j411i7bp/?spm_id_from=333.788.top_right_bar_window_default_collection.content.click&amp;vd_source=89cd1bd958a3eea212de763dc113559e">视频链接</a></p>
<p>一个浮点数y在二进制里存贮形式Y 是 S M E （S为0和1表示符号 0为正 部分
M为0和1 表示尾数 这里省略了小数点前的1. E为为指数也有0和1表示
不过它有正负使用实际值是补码)</p>
<p><span class="math inline">\(y=\left(1+\frac{M}{2^{23}}\right) \cdot
2^{E-127}\)</span> M是尾数部分的值 E是指数部分的值</p>
<p>举个例子 y=1.5 Y 是 0(S表示正数) 01111111(E表示0 )
10000000000000000000000(M本来应该是1.10000000000000000000000)</p>
<p><span class="math display">\[
log_2(y)=&amp;log_2\left(1+\frac{M}{2^{23}}\right) + E-127\\
log_2(y) \approx &amp;\left(\frac{M}{2^{23}}\right) + E-127\\
log_2(y) \approx &amp;2^{-23}\left(M+2^{23}*E\right) -127\\
log_2(y) \approx &amp;2^{-23}Y -127
\]</span><br />
这里考虑到<span
class="math inline">\(log_2\left(1+x\right)\)</span>曲线在0和1之间接近x曲线
用x 代替了<span class="math inline">\(log_2\left(1+x\right)\)</span>
当然这种近似仅在0和1处最好 所以加一个修正可以是整体误差最小
后面会在代码里看到修正<br />
<span class="math display">\[
log_2(a)=&amp;-\frac{1}{2} log_2(y)\\
2^{-23}A -127 \approx &amp;-\frac{1}{2}\left(2^{-23}Y -127\right)\\
A  \approx &amp;-\frac{1}{2}Y +2^{22}\left( 381\right)
\]</span><br />
这里a是y的平方根倒数A是a的二进制表示</p>
<p>对于<span class="math inline">\(\frac{1}{2}Y\)</span>右移解决
虽然遇到奇数会有误差但我们只是求近似值所以可以接受</p>
<p><span class="math inline">\(2^{22}\left(
381\right)\)</span>十六进制为0x5400000
不过为了修正后面用了0x5f3759df</p>
<p>至此我们得到了平方根倒数近似值我们把它用牛顿法在近似迭代一下可以得到非常精确的值</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">float</span> <span class="title">Q_sqrt</span><span class="params">( <span class="type">float</span> number)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="type">long</span> i;</span><br><span class="line">	<span class="type">float</span> x2,y;</span><br><span class="line">	<span class="type">const</span> <span class="type">float</span> threehalfs = <span class="number">1.5F</span>;</span><br><span class="line">	x2 = number * <span class="number">0.5F</span>;</span><br><span class="line">	y = number;</span><br><span class="line">	i = *( <span class="type">long</span> * ) $y; <span class="comment">//转换二进制类型</span></span><br><span class="line">	i = <span class="number">0x5f3759df</span> - (i &gt;&gt; i );<span class="comment">//计数平方根倒数近似值 0x5400000</span></span><br><span class="line">	y = *( <span class="type">float</span> *) &amp;i ;<span class="comment">//转回浮点数</span></span><br><span class="line">	y = y *( threehalfs -(x2 * y * y));<span class="comment">//牛顿法 求 x^(-2) -y =0 </span></span><br><span class="line">    <span class="keyword">return</span> y;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="求解方程">求解方程</h2>
<h3 id="二分法">二分法</h3>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> bisect(f::<span class="built_in">Function</span>,a::<span class="built_in">Float64</span>,b::<span class="built_in">Float64</span>,tol::<span class="built_in">Float64</span>=<span class="number">10</span>^-<span class="number">10</span>)</span><br><span class="line">	<span class="keyword">if</span> f(a)*f(b)&gt;<span class="number">0</span></span><br><span class="line">		error(<span class="string">&quot;f(a)f(b)&lt;0 not statisfied!&quot;</span>)</span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">		println(ceil(log(<span class="number">2</span>,(b-a)/tol))+<span class="number">1</span>)</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">1</span>:ceil(log(<span class="number">2</span>,(b-a)/tol))+<span class="number">1</span></span><br><span class="line">		<span class="keyword">global</span> c= (a + b)*<span class="number">.5</span></span><br><span class="line">		<span class="keyword">if</span> abs(f(c)) &lt; tol</span><br><span class="line">			println(<span class="string">&quot;find the solution&quot;</span>)</span><br><span class="line">			<span class="keyword">return</span> [c,f(c)]</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">		(a,b)= f(c) &lt; <span class="number">0</span> ? (c,b) : (a,c)</span><br><span class="line"></span><br><span class="line">		</span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">return</span> [c,f(c)]</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h3 id="不动点迭代">不动点迭代</h3>
<p>假设函数 <span class="math inline">\(g\)</span> 是连续可微函数, <span
class="math inline">\(g(r)=r,
S=\left|g^{\prime}(r)\right|&lt;1\)</span>, 则不动点迭代对
于一个足够接近 <span class="math inline">\(r\)</span> 的初始估计, 以速度
<span class="math inline">\(S\)</span> 线性收玫到不动点 <span
class="math inline">\(r\)</span>.</p>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> FPI(f::<span class="built_in">Function</span>,x0::<span class="built_in">Float64</span>,k::<span class="built_in">Int64</span>)</span><br><span class="line">	x=x0</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span>  <span class="number">1</span>:k</span><br><span class="line">		x0=f(x)</span><br><span class="line">		<span class="keyword">if</span> abs(x-x0)&lt; <span class="number">10</span>^-<span class="number">6</span>	</span><br><span class="line">			println(<span class="string">&quot;FPI convergence in &quot;</span>,i,<span class="string">&quot; step&quot;</span>)</span><br><span class="line">			<span class="keyword">return</span> x0</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">		x=x0</span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">println(<span class="string">&quot;FPI &quot;</span>,FPI(x-&gt;<span class="number">1</span>-x^<span class="number">3.0</span> ,<span class="number">0.5</span>,<span class="number">100</span>))</span><br><span class="line">println(<span class="string">&quot;FPI &quot;</span>,FPI(x-&gt;(<span class="number">1</span>-x)^(<span class="number">1</span>/<span class="number">3</span>) ,<span class="number">0.5</span>,<span class="number">100</span>))</span><br><span class="line">println(<span class="string">&quot;FPI &quot;</span>,FPI(x-&gt;(<span class="number">1</span>+<span class="number">2</span>*x^<span class="number">3</span>)/(<span class="number">1</span>+<span class="number">3</span>*x^<span class="number">2</span>) ,<span class="number">0.5</span>,<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#FPI 0.0</span></span><br><span class="line"><span class="comment">#FPI convergence in 39 step</span></span><br><span class="line"><span class="comment">#FPI 0.6823281782912355</span></span><br><span class="line"><span class="comment">#FPI convergence in 4 step</span></span><br><span class="line"><span class="comment">#FPI 0.682327803828347</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="牛顿法-割线法">牛顿法 割线法</h3>
<p>通过切线的方式不断求零点</p>
<p>割线法</p>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> secant_method(f::<span class="built_in">Function</span>,x0::<span class="built_in">Float64</span>,x1::<span class="built_in">Float64</span>=x0+x0*<span class="number">0.1</span>,k::<span class="built_in">Int64</span>=<span class="number">100</span>,eta::<span class="built_in">Float64</span>=<span class="number">10</span>^-<span class="number">6</span>)</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">1</span>:k </span><br><span class="line">		x2 = x1- f(x1)*(x1-x0)/(f(x1)- f(x0))</span><br><span class="line">		<span class="keyword">if</span> abs(x2-x1)/(x2+eta)&lt; eta	</span><br><span class="line">			println(<span class="string">&quot;secant_method convergence in &quot;</span>,i,<span class="string">&quot; step&quot;</span>)</span><br><span class="line">			<span class="keyword">return</span> x2</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">			</span><br><span class="line">		</span><br><span class="line"></span><br><span class="line">		x0 = x1</span><br><span class="line">		x1 = x2</span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">return</span> x1</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> Regula_Falsi(f::<span class="built_in">Function</span>,a::<span class="built_in">Float64</span>,b::<span class="built_in">Float64</span>,k::<span class="built_in">Int64</span>=<span class="number">100</span>,eta::<span class="built_in">Float64</span>=<span class="number">10</span>^-<span class="number">6</span>)</span><br><span class="line">	<span class="keyword">if</span> f(a)*f(b)&gt;<span class="number">0</span></span><br><span class="line">		<span class="keyword">return</span> <span class="string">&quot;error range&quot;</span></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">1</span>:k</span><br><span class="line">		c= (b*f(a)-a*f(b))/(f(a)-f(b))</span><br><span class="line">		<span class="keyword">if</span> abs(f(c)) ==<span class="number">0</span></span><br><span class="line">			<span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> check_tol(a,c,eta) &lt;eta ||  check_tol(a,c,eta) &lt;eta </span><br><span class="line">			println(<span class="string">&quot; Regula_Falsi in  &quot;</span>, i, <span class="string">&quot;step&quot;</span>, <span class="string">&quot;f(c)=&quot;</span>,f(c),<span class="string">&quot; c=&quot;</span>,c )</span><br><span class="line">			<span class="keyword">return</span> c</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">		(a,b) = f(a)*f(c) ? (a,c) : (c,a)</span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>试位法</p>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> secant_method(f::<span class="built_in">Function</span>,x0::<span class="built_in">Float64</span>,x1::<span class="built_in">Float64</span>=x0+x0*<span class="number">0.1</span>,k::<span class="built_in">Int64</span>=<span class="number">100</span>,eta::<span class="built_in">Float64</span>=<span class="number">10</span>^-<span class="number">6</span>)</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">1</span>:k </span><br><span class="line">		x2 = x1- f(x1)*(x1-x0)/(f(x1)- f(x0))</span><br><span class="line">		<span class="keyword">if</span> abs(x2-x1)/(x2+eta)&lt; eta	</span><br><span class="line">			println(<span class="string">&quot;secant_method convergence in &quot;</span>,i,<span class="string">&quot; step&quot;</span>)</span><br><span class="line">			<span class="keyword">return</span> x2</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">			</span><br><span class="line">		</span><br><span class="line"></span><br><span class="line">		x0 = x1</span><br><span class="line">		x1 = x2</span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">return</span> x1</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> Regula_Falsi(f::<span class="built_in">Function</span>,a::<span class="built_in">Float64</span>,b::<span class="built_in">Float64</span>,k::<span class="built_in">Int64</span>=<span class="number">100</span>,eta::<span class="built_in">Float64</span>=<span class="number">10</span>^-<span class="number">6</span>)</span><br><span class="line">	<span class="keyword">if</span> f(a)*f(b)&gt;<span class="number">0</span></span><br><span class="line">		<span class="keyword">return</span> <span class="string">&quot;error range&quot;</span></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">1</span>:k</span><br><span class="line">		c= (b*f(a)-a*f(b))/(f(a)-f(b))</span><br><span class="line">		<span class="keyword">if</span> abs(f(c)) ==<span class="number">0</span></span><br><span class="line">			<span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> check_tol(a,c,eta) &lt;eta ||  check_tol(a,c,eta) &lt;eta </span><br><span class="line">			println(<span class="string">&quot; Regula_Falsi in  &quot;</span>, i, <span class="string">&quot;step&quot;</span>, <span class="string">&quot;f(c)=&quot;</span>,f(c),<span class="string">&quot; c=&quot;</span>,c )</span><br><span class="line">			<span class="keyword">return</span> c</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">		(a,b) = f(a)*f(c) ? (a,c) : (c,a)</span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h2 id="求解方程组">求解方程组</h2>
<p>首先提一句julia中 <code>\</code>函数可以求解线性方程组<span
class="math inline">\(A x = b\)</span> ，其中<span
class="math inline">\(A\)</span>是方阵</p>
<p>当A的行数大于列数时，<code>\</code>函数可以计算超定方程的最小二乘解</p>
<p>一个坑要注意 <code>'</code> 在julia里面是厄密不仅仅是转置</p>
<h3 id="高斯消去法-lu分解">高斯消去法 LU分解</h3>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">using</span> LinearAlgebra</span><br><span class="line"><span class="keyword">function</span> back_substitution(a::(<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;),b::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;,order::<span class="built_in">Int64</span>=<span class="number">1</span>)</span><br><span class="line">	n=length(b)</span><br><span class="line">	x=zeros(<span class="number">1</span>,n)</span><br><span class="line">	l= order==<span class="number">1</span> ? (n:-<span class="number">1</span>:<span class="number">1</span>) : (<span class="number">1</span>:n)</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> l</span><br><span class="line">		l2= order==<span class="number">1</span> ? (i+<span class="number">1</span> : n) : (<span class="number">1</span>:i-<span class="number">1</span>)</span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> l2</span><br><span class="line">			b[i]-= a[i,j]*x[j]</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">		</span><br><span class="line">		x[i] = b[i]/a[i,i]</span><br><span class="line"></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">return</span> x</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> Gaussian_elimination(a::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;,b::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;)</span><br><span class="line">	n=length(b)</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span>  <span class="number">1</span> : n-<span class="number">1</span></span><br><span class="line">		<span class="keyword">if</span> abs(a[j,j]) &lt; <span class="number">10</span>^-<span class="number">20</span></span><br><span class="line">			error(<span class="string">&quot;zero pivot encountered&quot;</span>)</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span>  j+<span class="number">1</span>:n</span><br><span class="line">			mult = a[i,j]/a[j,j]</span><br><span class="line">			<span class="keyword">for</span> k = j : n</span><br><span class="line">				a[i,k] -=mult*a[j,k]  </span><br><span class="line">			<span class="keyword">end</span></span><br><span class="line">			b[i] -= mult*b[j]</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">return</span> back_substitution(a,b)</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">println(Gaussian_elimination(<span class="number">1.0</span>*[<span class="number">1</span> <span class="number">2</span> -<span class="number">1</span>; <span class="number">2</span> <span class="number">1</span> -<span class="number">2</span> ; -<span class="number">3</span> <span class="number">1</span> <span class="number">1</span>],[<span class="number">3</span> <span class="number">3</span> -<span class="number">6</span>]*<span class="number">1.0</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> LU(m::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;)</span><br><span class="line">n=length(m[<span class="number">1</span>,:])</span><br><span class="line"></span><br><span class="line">L=zeros(n,n)+I</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span>  <span class="number">1</span> : n-<span class="number">1</span></span><br><span class="line">		<span class="comment">#L[j,j]=1</span></span><br><span class="line">		<span class="keyword">if</span> abs(m[j,j]) &lt; <span class="number">10</span>^-<span class="number">20</span></span><br><span class="line">			error(<span class="string">&quot;zero pivot encountered&quot;</span>)</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span>  j+<span class="number">1</span>:n</span><br><span class="line">			</span><br><span class="line">			L[i,j]=  m[i,j]/m[j,j]</span><br><span class="line">			<span class="keyword">for</span> k = j : n</span><br><span class="line">				m[i,k] -= L[i,j]*m[j,k]  </span><br><span class="line">			<span class="keyword">end</span></span><br><span class="line">			</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> L,m</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">function</span> LU_solve(L::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;,U::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;,b::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;)</span><br><span class="line">	c=back_substitution(L,b,-<span class="number">1</span>)</span><br><span class="line">	println(c)</span><br><span class="line">	back_substitution(U,c)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">L,U=LU(<span class="number">1.0</span>*[<span class="number">1</span> <span class="number">2</span> -<span class="number">1</span> ; <span class="number">2</span> <span class="number">1</span> -<span class="number">2</span> ; -<span class="number">3</span> <span class="number">1</span> <span class="number">1</span>])</span><br><span class="line">println(L)</span><br><span class="line">println(U)</span><br><span class="line">println(LU_solve(L,U,[<span class="number">3</span> <span class="number">3</span> -<span class="number">6</span>]*<span class="number">1.0</span>))</span><br><span class="line">println(back_substitution([<span class="number">1</span> <span class="number">0</span> ; <span class="number">3</span> <span class="number">1</span> ]*<span class="number">1.0</span>,[<span class="number">3</span> <span class="number">2</span>]*<span class="number">1.0</span>,-<span class="number">1</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="误差来源">误差来源</h4>
<p>1.方阵 <span class="math inline">\(A\)</span>的性质<br />
<span class="math display">\[
\text { 误差放大因子 }=\frac{\text { 相对前向误差 }}{\text {
相对后向误差
}}=\frac{\frac{\left\|x-x_a\right\|_{\infty}}{\|x\|_{\infty}}}{\frac{\|r\|_{\infty}}{\|b\|_{\infty}}}
\]</span></p>
<p>方阵 <span class="math inline">\(A\)</span> 的条件数 <span
class="math inline">\(\operatorname{cond}(A)\)</span> 为求解 <span
class="math inline">\(A x=b\)</span> 时, 对于所有右侧向量 <span
class="math inline">\(b\)</span>, 可能出 现的最大误差放大因子.<br />
令人惊讶的是, 对于方阵有一个关于条件数的紧致的公式. 和向量范数类似, 定义
<span class="math inline">\(n \times n\)</span> 矩阵 <span
class="math inline">\(A\)</span> 的矩阵范数为<br />
<span class="math display">\[
\|A\|_{\infty}= 每行元素绝对值之和的最大值
\]</span></p>
<p>即每行元素绝对值求和, 并把 <span class="math inline">\(n\)</span>
行求和的最大值作为矩阵 <span class="math inline">\(A\)</span>
的范数.<br />
$ n n$ 矩阵 <span class="math inline">\(A\)</span> 的条件数是</p>
<p><span class="math display">\[
\operatorname{cond}(A)=\|A\| \cdot\left\|A^{-1}\right\|
\]</span></p>
<p>2.淹没</p>
<p>高斯消去法会因为第一列主元过小而导致大数小数相减而忽略小数引入误差</p>
<p>PA=LU分解</p>
<p>可以解决0主元和淹没的问题</p>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">function</span> PA_LU(m::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;)</span><br><span class="line">	println(<span class="string">&quot;PA_LU&quot;</span>)</span><br><span class="line">	n=length(m[<span class="number">1</span>,:])</span><br><span class="line">	L=zeros(n,n)+I</span><br><span class="line">	p=zeros(n,n)+I</span><br><span class="line">	order=collect(<span class="number">1</span>:n)</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span>  <span class="number">1</span> : n-<span class="number">1</span></span><br><span class="line">		<span class="comment">#L[j,j]=1</span></span><br><span class="line">		change_row=findmax(m[j:n,j])[<span class="number">2</span>]</span><br><span class="line">		<span class="keyword">if</span> change_row !=j</span><br><span class="line">			m[j,:],m[change_row,:]=m[change_row,:],m[j,:]</span><br><span class="line">			</span><br><span class="line">			order[j],order[change_row]=order[change_row],order[j]</span><br><span class="line">			</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> abs(m[j,j]) &lt; <span class="number">10</span>^-<span class="number">20</span></span><br><span class="line">			error(<span class="string">&quot;zero pivot encountered&quot;</span>)</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span>  j+<span class="number">1</span>:n</span><br><span class="line">			</span><br><span class="line">			L[i,j]=  m[i,j]/m[j,j]</span><br><span class="line">			<span class="keyword">for</span> k = j : n</span><br><span class="line">				m[i,k] -= L[i,j]*m[j,k]  </span><br><span class="line">			<span class="keyword">end</span></span><br><span class="line">			</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">    <span class="keyword">if</span> order!=collect(<span class="number">1</span>:n)</span><br><span class="line">		p=p*Permutation_matrix(order)</span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">return</span> p,L,m <span class="comment"># P L U</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">P,L,U=PA_LU(<span class="number">1.0</span>*[<span class="number">1</span> <span class="number">2</span> -<span class="number">1</span> ; <span class="number">2</span> <span class="number">1</span> -<span class="number">2</span> ; -<span class="number">3</span> <span class="number">1</span> <span class="number">1</span>])</span><br><span class="line">println(<span class="string">&quot;P: &quot;</span>),display(P)</span><br><span class="line">println(<span class="string">&quot;L: &quot;</span>),display(L)</span><br><span class="line">println(<span class="string">&quot;U: &quot;</span>),display(U)</span><br><span class="line">Pb=[i <span class="keyword">for</span> i <span class="keyword">in</span> P*[<span class="number">3</span>;<span class="number">3</span>;-<span class="number">6</span>]]</span><br><span class="line">println(<span class="string">&quot;Pb: &quot;</span>),display(Pb)</span><br><span class="line">println(LU_solve(L,U,Pb*<span class="number">1.0</span>))</span><br><span class="line">println(LU_solve(L,U,[<span class="number">3.0</span>  -<span class="number">6.0</span>  <span class="number">3.0</span>]))</span><br><span class="line"></span><br><span class="line">P,L,U=PA_LU(<span class="number">1.0</span>*[<span class="number">2</span> <span class="number">1</span> <span class="number">5</span> ; <span class="number">4</span> <span class="number">4</span> -<span class="number">4</span> ; <span class="number">1</span> <span class="number">3</span> <span class="number">1</span>])</span><br><span class="line">println(<span class="string">&quot;P: &quot;</span>),display(P)</span><br><span class="line">println(<span class="string">&quot;L: &quot;</span>),display(L)</span><br><span class="line">println(<span class="string">&quot;U: &quot;</span>),display(U)</span><br><span class="line">Pb=[i <span class="keyword">for</span> i <span class="keyword">in</span> P*[<span class="number">5</span>;<span class="number">0</span>;<span class="number">6</span>]]</span><br><span class="line">println(<span class="string">&quot;Pb: &quot;</span>),display(Pb)</span><br><span class="line">println(LU_solve(L,U,Pb*<span class="number">1.0</span>))</span><br></pre></td></tr></table></figure>
<h2 id="雅可比方法">雅可比方法</h2>
<p><span class="math display">\[
\begin{split}
&amp;x_0= 初始向量 \\
&amp;x_{k+1}=D^{-1}\left(b-(L+U) x_k\right), k=0,1,2, \cdots
\end{split}
\]</span></p>
<p>对于严格对角占优矩阵(<span class="math inline">\(\left|a_{i
j}\right|&gt;\sum\limits_{i \neq j}\left|a_{i j}\right|\)</span>)
是非奇异的且雅可比方法有唯一解</p>
<h2 id="高斯-塞徳方法gauss-seidel">高斯-塞徳方法（Gauss-Seidel)</h2>
<p><span class="math display">\[
\begin{aligned}
x_0 &amp; =\text { 初始向量 } \\
x_{k+1} &amp; =D^{-1}\left(b-U x_k-L x_{k+1}\right), k=0,1,2, \cdots
\end{aligned}
\]</span></p>
<h3 id="连续过松驰-sor">连续过松驰 (SOR)</h3>
<p><span class="math display">\[
\begin{aligned}
x_0 &amp; =\text { 初始向量 } \\
x_{k+1} &amp; =(\omega L+D)^{-1}\left[(1-\omega) D x_k-\omega U
x_k\right]+\omega(D+\omega L)^{-1} b, k=0,1,2, \cdots
\end{aligned}
\]</span></p>
<p>正如雅可比和高斯-塞德尔方法, 另一种导出 SOR
的方法是将该系统看做不动点迭代. 问题 <span class="math inline">\(A
x=b\)</span> 可以写成 <span class="math inline">\((L+D+U) x=b\)</span>,
乘上 <span class="math inline">\(\omega\)</span> 并重新组织方程,<br />
<span class="math display">\[
\begin{aligned}
(\omega L+\omega D+\omega U) x &amp; =\omega b \\
(\omega L+D) x &amp; =\omega b-\omega U x+(1-\omega) D x \\
x &amp; =(\omega L+D)^{-1}[(1-\omega) D x-\omega U x]+\omega(D+\omega
L)^{-1} b
\end{aligned}
\]</span></p>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> L_inv(m::<span class="built_in">Matrix</span>&#123;<span class="built_in">Float64</span>&#125;,n::<span class="built_in">Int64</span>=length(m[<span class="number">1</span>,:]))</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">1</span>:n</span><br><span class="line">		m[i,i]= m[i,i]!=<span class="number">0</span> ?  <span class="number">1</span>/m[i,i] : <span class="number">0</span></span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> <span class="number">1</span>:i-<span class="number">1</span></span><br><span class="line">			</span><br><span class="line">				m[i,j]=-sum([ m[i,k]*m[k,j] <span class="keyword">for</span> k <span class="keyword">in</span> j:i-<span class="number">1</span>])*m[i,i] <span class="comment">#(1/m_ii)*sum(m_i,k*inv m_kj)</span></span><br><span class="line">			</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">	</span><br><span class="line">	<span class="keyword">return</span> m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">function</span> SOR(a::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;,b::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;,w::<span class="built_in">Int64</span>=<span class="number">1</span>,k::<span class="built_in">Int64</span>=<span class="number">100</span>,eta::<span class="built_in">Float64</span>=<span class="number">10</span>^-<span class="number">6</span>)</span><br><span class="line">	<span class="keyword">if</span> w&lt;<span class="number">1</span> </span><br><span class="line">		error(<span class="string">&quot;w must be greater than 1 &quot;</span>)</span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">	n=length(b)</span><br><span class="line"></span><br><span class="line">	x=rand(n,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">	D=zeros(n,n)</span><br><span class="line">	L=zeros(n,n)</span><br><span class="line">	U=zeros(n,n)</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">1</span>:n</span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> <span class="number">1</span>:n</span><br><span class="line">			<span class="keyword">if</span> i==j</span><br><span class="line">				D[i,j]=a[i,j]</span><br><span class="line">			<span class="keyword">elseif</span> i&lt;j</span><br><span class="line">				U[i,j]=a[i,j]</span><br><span class="line">			<span class="keyword">else</span></span><br><span class="line">				L[i,j]=a[i,j]</span><br><span class="line">			<span class="keyword">end</span></span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">	println(n)</span><br><span class="line">	wLD_inv=</span><br><span class="line">    L_inv((w*L+D),n)</span><br><span class="line">	</span><br><span class="line">	w_wLD_inv_b=w*wLD_inv*(b&#x27;)</span><br><span class="line">	wd=(<span class="number">1</span>-w)*D-w*U</span><br><span class="line">	display(wd)</span><br><span class="line">	display(wLD_inv*(w*L+D))</span><br><span class="line">	display(w_wLD_inv_b)</span><br><span class="line">	display(wLD_inv)</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">1</span>:k</span><br><span class="line">		x=wLD_inv*(wd*x)+w_wLD_inv_b</span><br><span class="line">		</span><br><span class="line">		r=sum([i^<span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> (a*x-b&#x27;)])^<span class="number">0.5</span></span><br><span class="line">		println(<span class="string">&quot;r &quot;</span>,r)</span><br><span class="line">		<span class="keyword">if</span>  r &lt;eta</span><br><span class="line">			println(<span class="string">&quot;SOR convergence in &quot;</span>,i,<span class="string">&quot; step&quot;</span>)</span><br><span class="line">			<span class="keyword">return</span> x&#x27;			</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> x&#x27;</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">println(SOR(<span class="number">1.0</span>*[<span class="number">3</span> -<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0.5</span>; -<span class="number">1</span> <span class="number">3</span> -<span class="number">1</span> <span class="number">0</span> <span class="number">0.5</span> <span class="number">0</span>;<span class="number">0</span> -<span class="number">1</span> <span class="number">3</span> -<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> ;<span class="number">0</span> <span class="number">0</span> -<span class="number">1</span> <span class="number">3</span> -<span class="number">1</span> <span class="number">0</span> ;<span class="number">0</span> <span class="number">0.5</span> <span class="number">0</span> -<span class="number">1</span> <span class="number">3</span> -<span class="number">1</span> ; <span class="number">0.5</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> -<span class="number">1</span> <span class="number">3</span>],[<span class="number">5</span>/<span class="number">2.0</span> <span class="number">3</span>/<span class="number">2.0</span> <span class="number">1.0</span> <span class="number">1.0</span> <span class="number">3</span>/<span class="number">2.0</span> <span class="number">5</span>/<span class="number">2.0</span>]*<span class="number">1.0</span>))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>迭代法可以用来求稀疏矩阵比较有效</p>
<h3 id="非线性方程组">非线性方程组</h3>
<p><span class="math display">\[
\begin{aligned}
f_1(x_1, x_2,..., x_n)&amp;=0 \\
f_2(x_1, x_2,..., x_n)&amp;=0 \\
\vdots\\
f_m(x_1, x_2,..., x_n)&amp;=0
\end{aligned}
\]</span></p>
<h4 id="多变量牛顿法">多变量牛顿法</h4>
<p>类似牛顿法直接用雅可比矩阵迭代求解</p>
<h4 id="broyden方法">Broyden方法</h4>
<p><span class="math display">\[
\begin{aligned}
&amp; x_0=\text { 初始向量 } \\
&amp; A_0=\text { 初始矩阵 } \\
&amp; \text { for } i=0,1,2, \cdots \\
&amp; \qquad x_{i+1}=x_i-A_i^{-1} F\left(x_i\right) \\
&amp; \qquad A_{i+1}=A_i+\frac{\left(\Delta_{i+1}-A_i
\delta_{i+1}\right) \delta_{i+1}^{\mathrm{T}}}{\delta_{i+1}^{\mathrm{T}}
\delta_{i+1}}
\end{aligned}\notag
\]</span><br />
其中 <span class="math inline">\(\delta_{i+1}=x_{i+1}-x_i,
\Delta_{i+1}=F\left(x_{i+1}\right)-F\left(x_i\right)\)</span></p>
<h4 id="broyden-方法ii">Broyden 方法II</h4>
<p><span class="math display">\[
\begin{aligned}
&amp; x_0=\text { 初始向量 } \\
&amp; B_0=\text { 初始矩阵 } \\
&amp; \text { for } i=0,1,2, \cdots \\
&amp; \qquad x_{i+1}=x_i-B_i F\left(x_i\right) \\
&amp; \qquad B_{i+1}=B_i+\frac{\left(\delta_{i+1}-B_i
\Delta_{i+1}\right) \delta_{i+1}^{\mathrm{T}}
B_i}{\delta_{i+1}^{\mathrm{T}} B_i \Delta_{i+1}}
\end{aligned}\notag
\]</span><br />
其中 <span class="math inline">\(\delta_{i+1}=x_{i+1}-x_i,
\Delta_{i+1}=F\left(x_{i+1}\right)-F\left(x_i\right)\)</span></p>
<h2 id="插值">插值</h2>
<p>定理 3.4 假设 <span class="math inline">\(P(x)\)</span> 是 <span
class="math inline">\(n-1\)</span> 或者更低阶的插值多项式, 其拟合 <span
class="math inline">\(n\)</span> 个点 <span
class="math inline">\(\left(x_1, y_1\right), \cdots\)</span>, <span
class="math inline">\(\left(x_n, y_n\right)\)</span>. 插值误差是<br />
<span class="math display">\[
f(x)-P(x)=\frac{\left(x-x_1\right)\left(x-x_2\right)
\cdots\left(x-x_n\right)}{n !} f^{(n)}(c)
\]</span><br />
其中 <span class="math inline">\(c\)</span> 在最小和最大的 <span
class="math inline">\(n+1\)</span> 个数字 <span class="math inline">\(x,
x_1, \cdots, x_n\)</span> 之间.</p>
<h3 id="拉格朗日插值">拉格朗日插值</h3>
<p>一般来说, 如果我们有 <span class="math inline">\(n\)</span> 个点
<span class="math inline">\(\left(x_1, y_1\right), \cdots,\left(x_n,
y_n\right)\)</span>. 对于 <span class="math inline">\(1 \sim n\)</span>
之间的每个 <span class="math inline">\(k\)</span>, 定 义 <span
class="math inline">\(n-1\)</span> 次多项式<br />
<span class="math display">\[
L_k(x)=\frac{\left(x-x_1\right)
\cdots\left(x-x_{k-1}\right)\left(x-x_{k+1}\right)
\cdots\left(x-x_n\right)}{\left(x_k-x_1\right)
\cdots\left(x_k-x_{k-1}\right)\left(x_k-x_{k+1}\right)
\cdots\left(x_k-x_n\right)}
\]</span><br />
<span class="math inline">\(L_k\)</span> 具有一个有趣的性质, 即 <span
class="math inline">\(L_k\left(x_k\right)=1\)</span>, 而 <span
class="math inline">\(L_k\left(x_j\right)=0\)</span>, 其中 <span
class="math inline">\(x_j\)</span> 是任何一个其他的数据 点. 然后定义了
<span class="math inline">\(n-1\)</span> 次多项式<br />
<span class="math display">\[
P_{n-1}(x)=y_1 L_1(x)+\cdots+y_n L_n(x)
\]</span><br />
这是对 (3.1) 中多项式直接的推广, 并以相同的方式工作. 用 <span
class="math inline">\(x_k\)</span> 替代 <span
class="math inline">\(x\)</span> 得到<br />
<span class="math display">\[
P_{n-1}\left(x_k\right)=y_1 L_1\left(x_k\right)+\cdots+y_n
L_n\left(x_k\right)=0+\cdots+0+y_k L_k\left(x_k\right)+0+\cdots+0=y_k
\]</span><br />
可以看出该多项式满足设计要求.</p>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> Lagrange_inter(x0::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;,y0::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;)</span><br><span class="line">	<span class="keyword">return</span> x-&gt; sum([ y0[j]*mapreduce(m-&gt;m,*,[(x-x0[i])/(x0[j]-x0[i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">1</span>:length(y0) <span class="keyword">if</span> i!= j ])  <span class="keyword">for</span> j <span class="keyword">in</span> <span class="number">1</span>:length(y0)])</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">f_Lagrange=Lagrange_inter([<span class="number">0.0</span> <span class="number">2.0</span> <span class="number">3</span>],[<span class="number">1.0</span> <span class="number">2</span> <span class="number">4</span>])</span><br><span class="line">println(ff(<span class="number">1.0</span>))</span><br></pre></td></tr></table></figure>
<h3 id="牛顿差商">牛顿差商</h3>
<p><span class="math display">\[
\begin{aligned}
f\left[x_k\right] &amp; =f\left(x_k\right) \\
f\left[x_k x_{k+1}\right] &amp;
=\frac{f\left[x_{k+1}\right]-f\left[x_k\right]}{x_{k+1}-x_k} \\
f\left[x_k x_{k+1} x_{k+2}\right] &amp; =\frac{f\left[x_{k+1}
x_{k+2}\right]-f\left[x_k x_{k+1}\right]}{x_{k+2}-x_k} \\
f\left[\begin{array}{lll}
x_k x_{k+1} &amp; x_{k+2} &amp; x_{k+3}
\end{array}\right] &amp; =\frac{f\left[x_{k+1} x_{k+2}
x_{k+3}\right]-f\left[x_k x_{k+1} x_{k+2}\right.}{x_{k+3}-x_k}
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{array}{l|lll}
x_1 &amp; f\left[x_1\right] &amp; \\
&amp; &amp; f\left[\begin{array}{ll}
x_1 x_2
\end{array}\right] &amp; \\
x_2 &amp; f\left[x_2\right] &amp; &amp; f\left[\begin{array}{lll}
x_1 &amp; x_2 &amp; x_3
\end{array}\right] \\
&amp; &amp; f\left[x_2 x_3\right] &amp; \\
x_3 &amp; f\left[x_3\right] &amp;
\end{array}
\]</span></p>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> newtdd(x::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;,y::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;)</span><br><span class="line">	n = length(x)</span><br><span class="line">	v = zeros(n,n)</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> <span class="number">1</span>:n</span><br><span class="line">		v[j,<span class="number">1</span>]=y[j]</span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">2</span>:n</span><br><span class="line"></span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> <span class="number">1</span>: n+<span class="number">1</span>-i</span><br><span class="line">			v[j,i]= (v[j+<span class="number">1</span>,i-<span class="number">1</span>]-v[j,i-<span class="number">1</span>])/(x[j+i-<span class="number">1</span>]-x[j])</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span>(v[<span class="number">1</span>,:])</span><br></pre></td></tr></table></figure>
<h3 id="切比雪夫插值节点">切比雪夫插值节点</h3>
<p>在区间 <span class="math inline">\([a, b]\)</span>,<br />
<span class="math display">\[
x_i=\frac{b+a}{2}+\frac{b-a}{2} \cos \frac{(2 i-1) \pi}{2 n}
\]</span><br />
<span class="math inline">\(i=1, \cdots, n\)</span> ，不等式<br />
<span class="math display">\[
\left|\left(x-x_1\right) \cdots\left(x-x_n\right)\right| \leqslant
\frac{\left(\frac{b-a}{2}\right)^n}{2^{n-1}}
\]</span><br />
在区间 <span class="math inline">\([a, b]\)</span> 上成立.</p>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> mysin(x::<span class="built_in">Float64</span>,n::<span class="built_in">Int64</span>=<span class="number">10</span>)</span><br><span class="line">	xsin= [ <span class="literal">pi</span>/<span class="number">4</span> + (<span class="literal">pi</span>/<span class="number">4</span>)* cos(i*<span class="literal">pi</span>/(<span class="number">2</span>*n)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">1</span>:<span class="number">2</span>:<span class="number">2</span>*n-<span class="number">1</span>]</span><br><span class="line">	ysin= map(sin,xsin)</span><br><span class="line">	c= newtdd(xsin,ysin)</span><br><span class="line">	s=<span class="number">1</span></span><br><span class="line">	x1=mod(x,<span class="number">2</span>*<span class="literal">pi</span>)</span><br><span class="line">	<span class="keyword">if</span> x1&gt;<span class="literal">pi</span></span><br><span class="line">		x1= <span class="number">2</span>*<span class="literal">pi</span>-x1</span><br><span class="line">		s=-<span class="number">1</span></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">if</span> x1 &gt; <span class="literal">pi</span>/<span class="number">2</span></span><br><span class="line">		x1 = <span class="literal">pi</span> - x1</span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> s*hornor(x1,n-<span class="number">1</span>,c,xsin)  <span class="comment">#hornor(x::Float64,n::Int64,c::Vector&#123;Float64&#125;=[1. for  i in 1:n+1],b::Vector&#123;Float64&#125;=[0. for  i in 1:n+1])</span></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">println(sin(<span class="number">10</span>),<span class="string">&quot; &quot;</span>,mysin(<span class="number">10.0</span>))</span><br></pre></td></tr></table></figure>
<h3 id="三次样条插值">三次样条插值</h3>
<p>为了更加精确地定义三次样条的性质, 我们做出如下的定义: 假设给定 <span
class="math inline">\(n\)</span> 个点 <span
class="math inline">\(\left(x_1\right.\)</span>, <span
class="math inline">\(\left.y_1\right), \cdots,\left(x_n,
y_n\right)\)</span>, 其中 <span class="math inline">\(x_i\)</span> 不同,
并且升序. 通过点 <span class="math inline">\(\left(x_1, y_1\right),
\cdots,\left(x_n, y_n\right)\)</span> 的三次样 条 <span
class="math inline">\(S(x)\)</span> 是一组三次多项式<br />
<span class="math display">\[
\begin{aligned}
S_1(x) &amp;
=y_1+b_1\left(x-x_1\right)+c_1\left(x-x_1\right)^2+d_1\left(x-x_1\right)^3
\text { 在区间 }\left[x_1, x_2\right] \text { 上 } \\
S_2(x) &amp;
=y_2+b_2\left(x-x_2\right)+c_2\left(x-x_2\right)^2+d_2\left(x-x_2\right)^3
\text { 在区间 }\left[x_2, x_3\right] \text { 上 } \\
&amp; \vdots \\
S_{n-1}(x) &amp;
=y_{n-1}+b_{n-1}\left(x-x_{n-1}\right)+c_{n-1}\left(x-x_{n-1}\right)^2+d_{n-1}\left(x-x_{n-1}\right)^3
\text { 在区间 }\left[x_{n-1}, x_n\right] \text { 上 }
\end{aligned}
\]</span><br />
并具有如下性质:<br />
性质 1 $ S_i(x_i)=y_i, S_i(x_{i+1})=y_{i+1}$, 其中 <span
class="math inline">\(i=1, \cdots, n-1\)</span>.<br />
性质 2 $ S_{i-1}<sup>{}(x_i)=S_i</sup>{}(x_i)$, 其中 <span
class="math inline">\(i=2, \cdots, n-1\)</span>.<br />
性质 3 $ S_{i-1}<sup>{}(x_i)=S_i</sup>{}(x_i)$, 其中 <span
class="math inline">\(i=2, \cdots, n-1\)</span>.<br />
性质 1 保证样条 <span class="math inline">\(S(x)\)</span> 插值数据点.
性质 2 使得相邻的样条段在它们相遇的地方斜率相 同, 性质 3
则保证在两条样条段相邻的地方曲率相同, 该曲率由二阶导数表示.</p>
<p>这三个性质只能提供3n-5个独立方程
所以要给出一个确定的样条插值需要添加额外的性质 从而构成了不同的样条</p>
<h4 id="自然样条">自然样条</h4>
<p>性质 4a $ S_{1}<sup>{}(x_1)=0,S_{n-1}</sup>{}(x_n)=0$</p>
<p>使用自然样条条件 (性质 <span class="math inline">\(4 a\)</span> )
可以得到另外的两个方程:<br />
<span class="math display">\[
\begin{aligned}
S_1^{\prime \prime}\left(x_1\right) &amp; =0 \rightarrow 2 c_1=0 \\
S_{n-1}^{\prime \prime}\left(x_n\right) &amp; =0 \rightarrow 2 c_n=0
\end{aligned}
\]</span><br />
引人额外的未知变量 <span class="math inline">\(c_n=S_{n-1}^{\prime
\prime}\left(x_n\right) / 2\)</span>, 计算会更简单. 同时,
我们引人速记表示法 <span class="math inline">\(\delta_i=x_{i+1}-x_i,
\Delta_i=y_{i+1}-y_i\)</span></p>
<p>对于 <span class="math inline">\(n\)</span> 个未知变量 <span
class="math inline">\(c_i\)</span>, 一共给出了 <span
class="math inline">\(n\)</span> 个方程, 可以写成矩阵形式<br />
<span class="math display">\[
\left[\begin{array}{cccccc}
1 &amp; 0 &amp; 0 &amp; &amp; &amp; \\
\delta_1 &amp; 2 \delta_1+2 \delta_2 &amp; \delta_2 &amp; \ddots &amp;
&amp; \\
0 &amp; \delta_2 &amp; 2 \delta_2+2 \delta_3 &amp; \delta_3 &amp; &amp;
\\
&amp; \ddots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \\
&amp; &amp; &amp; \delta_{n-2} &amp; 2 \delta_{n-2}+2 \delta_{n-1} &amp;
\delta_{n-1} \\
&amp; &amp; &amp; 0 &amp; 0 &amp; 1
\end{array}\right]\left[\begin{array}{c}
c_1 \\
\vdots \\
c_n
\end{array}\right]=\left[\begin{array}{c}
0 \\
3\left(\frac{\Delta_2}{\delta_2}-\frac{\Delta_1}{\delta_1}\right) \\
3\left(\frac{\Delta_{n-1}}{\delta_{n-1}}-\frac{\Delta_{n-2}}{\delta_{n-2}}\right)
\\
0
\end{array}\right]
\]</span></p>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> Spline_Interpolation(x::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;, y::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;)</span><br><span class="line">	n = length(x)</span><br><span class="line">	</span><br><span class="line">	delta=[(x[i+<span class="number">1</span>] - x[i], y[i+<span class="number">1</span>] -y[i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">1</span>:n-<span class="number">1</span>]</span><br><span class="line">	</span><br><span class="line">	m=zeros(n,n)</span><br><span class="line">	m[<span class="number">1</span>,<span class="number">1</span>]=<span class="number">1</span></span><br><span class="line">	m[n,n]=<span class="number">1</span></span><br><span class="line">	b=zeros(n,<span class="number">1</span>)</span><br><span class="line">	<span class="keyword">for</span>  i <span class="keyword">in</span> <span class="number">2</span>:n-<span class="number">1</span></span><br><span class="line">	</span><br><span class="line">		m[i,i-<span class="number">1</span>], m[i,i] ,m[i,i+<span class="number">1</span>] = delta[i-<span class="number">1</span>][<span class="number">1</span>] , <span class="number">2</span>*delta[i-<span class="number">1</span>][<span class="number">1</span>] + <span class="number">2</span>*delta[i][<span class="number">1</span>] ,delta[i][<span class="number">1</span>]</span><br><span class="line">		</span><br><span class="line">		b[i]= <span class="number">3</span>* (delta[i][<span class="number">2</span>]/delta[i][<span class="number">1</span>] -delta[i-<span class="number">1</span>][<span class="number">2</span>]/delta[i-<span class="number">1</span>][<span class="number">1</span>])</span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	c=m\b</span><br><span class="line">	</span><br><span class="line">	d=zeros(<span class="number">1</span>,n)</span><br><span class="line">	b=zeros(<span class="number">1</span>,n)</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">1</span>:n-<span class="number">1</span></span><br><span class="line">		d[i]=(c[i+<span class="number">1</span>]-c[i])/(<span class="number">3</span>*delta[i][<span class="number">1</span>])<span class="comment">#[((c[i+1]-c[i])/(3*delta[i][1]), delta[i][2]/delta[i][1] - delta[i][1](2* c[i] + c[i+1])/3) for i in 1:n-1]</span></span><br><span class="line">		b[i]=delta[i][<span class="number">2</span>]/delta[i][<span class="number">1</span>] - delta[i][<span class="number">1</span>]*(<span class="number">2</span>* c[i] + c[i+<span class="number">1</span>])/<span class="number">3</span></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"><span class="keyword">return</span> y , b , c ,d</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">println(Spline_Interpolation([<span class="number">0</span> <span class="number">1</span> <span class="number">2</span>]*<span class="number">1.0</span>,[<span class="number">3</span> -<span class="number">2</span> <span class="number">1</span>]*<span class="number">1.0</span>))</span><br></pre></td></tr></table></figure>
<h3 id="贝塞尔曲线">贝塞尔曲线</h3>
<h2 id="最小二乘法">最小二乘法</h2>
<p>首先提一句julia中 <code>\</code>函数可以求解线性方程组<span
class="math inline">\(A x = b\)</span> ，其中<span
class="math inline">\(A\)</span>是方阵</p>
<p>当A的行数大于列数时，<code>\</code>函数可以计算超定方程的最小二乘解</p>
<h3 id="法线方程">法线方程</h3>
<p>最小二乘的法线方程<br />
对于不一致系统<br />
<span class="math display">\[
A x=b
\]</span><br />
求解 <span class="math inline">\(\bar{x}\)</span> 的计算公式如下.
我们已经知道<br />
<span class="math display">\[
(b-A \bar{x}) \perp\left\{A x \mid x \in R^n\right\}
\]</span><br />
把垂直性表示为矩阵的乘法, 我们发现对于 <span
class="math inline">\(R^n\)</span> 上所有的 <span
class="math inline">\(x\)</span>,<br />
<span class="math display">\[
(A x)^{\mathrm{T}}(b-A \bar{x})=0
\]</span><br />
使用前面关于转置的事实, 我们可以重写该式子, 即对于 <span
class="math inline">\(R^n\)</span> 上所有的 <span
class="math inline">\(x\)</span>,<br />
<span class="math display">\[
x^{\mathrm{T}} A^{\mathrm{T}}(b-A \bar{x})=0
\]</span><br />
求解<br />
<span class="math display">\[
A^{\mathrm{T}} A \bar{x}=A^{\mathrm{T}} b
\]</span><br />
得到的 <span class="math inline">\(\bar{x}\)</span>, 就是最小二乘解,
它可以最小化余项 <span class="math inline">\(r=b-A x\)</span>
的欧氏长度.</p>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> least_sqaure(a::(<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;),b::<span class="built_in">Array</span>&#123;<span class="built_in">Float64</span>&#125;)</span><br><span class="line"></span><br><span class="line">	A=a&#x27;*a</span><br><span class="line">	ab=a&#x27;*b&#x27;</span><br><span class="line">	P,L,U=PA_LU(A)</span><br><span class="line">	Pb=[i <span class="keyword">for</span> i <span class="keyword">in</span> P*ab]</span><br><span class="line">	<span class="keyword">return</span> LU_solve(L,U,Pb*<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h3 id="qr-分解">QR 分解</h3>
<h4 id="经典格拉姆-施密特正交">经典格拉姆-施密特正交</h4>
令 <span class="math inline">\(A_j(j=1, \cdots, n)\)</span>
为线性无关向量.<br />
$$<br />

<span class="math display">\[\begin{gathered}

\begin{array}{l}
\text { for } j=1,2, \cdots, n \\
\quad \quad y=A_j \\
\quad \quad \text { for } i=1,2, \cdots, j-1 \\
\quad \quad \quad r_{i j}=q_i^{\mathrm{T}} A_j \\
\quad \quad \quad y=y-r_{i j} q_i\\
\quad  \quad  \text { end } \\


%\begin{array}{l}
\quad  \quad  y=\|y \|_2 \\
\quad  \quad  r_{j j}=y / r_{j j}\\
   \text { end }
%\end{array}
\end{array} \\
\end{gathered} \notag\]</span>
<p>$$</p>
<h4 id="改进格拉姆-施密特正交">改进格拉姆-施密特正交</h4>
<p><span class="math display">\[
\begin{gathered}
\begin{array}{l}
\text { for } j=1,2, \cdots, n \\
\quad \quad y=A_j \\
\quad \quad \text { for } i=1,2, \cdots, j-1 \\
\quad \quad \quad r_{i j}=q_i^{\mathrm{T}} y \\
\quad \quad \quad y=y-r_{i j} q_i\\
\quad  \quad  \text { end } \\%\begin{array}{l}
\quad  \quad  y=\|y \|_2 \\
\quad  \quad  r_{j j}=y / r_{j j}\\   
\text { end }%\end{array}
\end{array} \\
\end{gathered} \notag
\]</span></p>
<h4 id="豪斯霍尔徳-方法">豪斯霍尔徳 方法</h4>
<p>豪斯霍尔德反射子令 <span class="math inline">\(x\)</span> 和 <span
class="math inline">\(w\)</span> 是向量, <span
class="math inline">\(\|x\|_2=\|w\|_2\)</span>, 并定义 <span
class="math inline">\(v=w-\)</span> <span
class="math inline">\(x\)</span>. 则 <span class="math inline">\(H=I-2 v
v^{\mathrm{T}} / v^{\mathrm{T}}\)</span> 是对称正交矩阵, 并且 <span
class="math inline">\(H x=w\)</span>.</p>
<p>求出A矩阵每列向量的豪斯霍尔徳反射子H 得到 Q= H1 H2 H3 R= H3 H2 H1(
如果矩阵是列数为3的话)</p>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">function</span> Householder(x::<span class="built_in">Vector</span>&#123;<span class="built_in">Float64</span>&#125;,w::<span class="built_in">Vector</span>&#123;<span class="built_in">Float64</span>&#125;)</span><br><span class="line">	v=w-x</span><br><span class="line">	P= v* (v&#x27;)/(v&#x27;*v)</span><br><span class="line">	<span class="keyword">return</span> I- <span class="number">2</span>*P</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> QR(m::<span class="built_in">Matrix</span>&#123;<span class="built_in">Float64</span>&#125;,method::<span class="built_in">String</span>=<span class="string">&quot;QR class&quot;</span>)</span><br><span class="line">	n=size(m)</span><br><span class="line">	Q=zeros(n[<span class="number">1</span>],n[<span class="number">2</span>])</span><br><span class="line">	Q[:,<span class="number">1</span>]=m[:,<span class="number">1</span>]</span><br><span class="line">	r=zeros(n[<span class="number">1</span>],n[<span class="number">2</span>])</span><br><span class="line">	println(method)</span><br><span class="line">	<span class="keyword">if</span> method ==<span class="string">&quot;Householder method&quot;</span></span><br><span class="line">		H=I+zeros(n[<span class="number">1</span>],n[<span class="number">1</span>])</span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> <span class="number">1</span>:n[<span class="number">2</span>]</span><br><span class="line">		<span class="keyword">if</span> method == <span class="string">&quot;Householder method&quot;</span></span><br><span class="line">			H2=I +zeros(n[<span class="number">1</span>],n[<span class="number">1</span>])</span><br><span class="line">	 		H2[j:n[<span class="number">1</span>],j:n[<span class="number">1</span>]] =Householder(m[j:n[<span class="number">1</span>],j],[k== j ? norm(m[j:n[<span class="number">1</span>],j]) : <span class="number">0.0</span> <span class="keyword">for</span> k <span class="keyword">in</span> j:n[<span class="number">1</span>]])</span><br><span class="line">	 		H= H*H2</span><br><span class="line">	 		m=H2*m</span><br><span class="line">			</span><br><span class="line">		<span class="keyword">else</span> </span><br><span class="line">			y=m[:,j]</span><br><span class="line">			<span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">1</span>:j-<span class="number">1</span></span><br><span class="line"></span><br><span class="line">				r[i,j] =  method ==<span class="string">&quot;QR class&quot;</span> ? Q[:,i]&#x27; *m[:,j] :  Q[:,i]&#x27; *y</span><br><span class="line">				y= y- r[i,j]* Q[:,i]</span><br><span class="line">			<span class="keyword">end</span></span><br><span class="line">			r[j,j]=  sqrt(sum([ i^<span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> y ]))<span class="comment">#norm(y)</span></span><br><span class="line">			Q[:,j]= y/r[j,j]</span><br><span class="line"></span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> method ==<span class="string">&quot;Householder method&quot;</span></span><br><span class="line">		Q,r =H , m</span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> Q ,r</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Q,r = QR([<span class="number">1</span> -<span class="number">4</span> ; <span class="number">2</span> <span class="number">3</span> ;<span class="number">2</span> <span class="number">2</span> ]*<span class="number">1.0</span>,<span class="string">&quot;QR class&quot;</span>)</span><br><span class="line">display(Q)</span><br><span class="line">display(r)</span><br><span class="line">Q,r = QR([<span class="number">1</span> -<span class="number">4</span> ; <span class="number">2</span> <span class="number">3</span> ;<span class="number">2</span> <span class="number">2</span> ]*<span class="number">1.0</span>,<span class="string">&quot;QR&quot;</span>)</span><br><span class="line">display(Q)</span><br><span class="line">display(r)</span><br><span class="line"></span><br><span class="line">Q,r = QR([<span class="number">1</span> -<span class="number">4</span> ; <span class="number">2</span> <span class="number">3</span> ;<span class="number">2</span> <span class="number">2</span> ]*<span class="number">1.0</span>,<span class="string">&quot;Householder method&quot;</span>)</span><br><span class="line">display(Q)</span><br><span class="line">display(r)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="通过-q-r-分解实现最小二乘">通过 <span class="math inline">\(Q
R\)</span> 分解实现最小二乘</h4>
<p>给定 <span class="math inline">\(m \times n\)</span> 不一致系统<br />
<span class="math display">\[
A x=b
\]</span><br />
找出完全 <span class="math inline">\(Q R\)</span> 分解 <span
class="math inline">\(A=Q R\)</span>, 令<span
class="math inline">\(\hat{R}=R\)</span> 的上 <span
class="math inline">\(n \times n\)</span> 子矩阵<span
class="math inline">\(\hat{d}=d=Q^{\mathrm{T}} b\)</span> 的上面的 <span
class="math inline">\(n\)</span> 个元素 求解 <span
class="math inline">\(\hat{R} \bar{x}=\hat{d}\)</span> 得到最小二乘解
<span class="math inline">\(\bar{x}\)</span>.</p>
<h3 id="非线性最小二乘法">非线性最小二乘法</h3>
<p>高斯-牛顿方法的重要应用是拟合具有非线性系数的模型. 令 <span
class="math inline">\(\left(t_1, y_1\right), \cdots,\left(t_m,
y_m\right)\)</span> 是数据点, <span
class="math inline">\(y=f_c(x)\)</span> 是要进行拟合函数, 其中 <span
class="math inline">\(c=\left[c_1, \cdots, c_p\right]\)</span>
是一组选择的参数, 用以最小化余项的平方和<br />
<span class="math display">\[
\begin{gathered}
r_1(c)=f_c\left(t_1\right)-y_1 \\
\vdots \\
r_m(c)=f_c\left(t_m\right)-y_m
\end{gathered}
\]</span><br />
的特定情况被更一般地看待, 以保证这里的特殊处理.</p>
<h4 id="高斯一牛顿方法">高斯一牛顿方法</h4>
<p>忽略了二阶导（海森矩阵）</p>
<p>为了最小化<br />
<span class="math display">\[
r_1(x)^2+\cdots+r_m(x)^2 \notag
\]</span><br />
令 <span class="math inline">\(x^0=\)</span> 初始向量,</p>
<p><span class="math display">\[
\begin{aligned}
\text { for } k=0,1 ， 2 \text {, } \cdots \\
A &amp; =\operatorname{Dr}\left(x^k\right) \\
A^{\mathrm{T}} A v^k &amp; =-A^{\mathrm{T}} r\left(x^k\right) \\
x^{k+1} &amp; =x^k+v^k \\
\text{end}
\end{aligned} \notag
\]</span></p>
<h4 id="levenberg-marquardt-方法">Levenberg-Marquardt 方法</h4>
<p>为了最小化<br />
<span class="math display">\[
r_1(x)^2+\cdots+r_m(x)^2 \notag
\]</span><br />
令 <span class="math inline">\(x^0=\)</span> 初始向量,<span
class="math inline">\(\lambda =\)</span> 常数<br />
<span class="math display">\[
\begin{aligned}
\text { for } k=0,1 ， 2 \text {, } \cdots \\
A &amp; =\operatorname{Dr}\left(x^k\right) \\
(A^{\mathrm{T}} A + \lambda diag(A^{\mathrm{T}} A))v^k &amp;
=-A^{\mathrm{T}} r\left(x^k\right) \\
x^{k+1} &amp; =x^k+v^k \\
\text{end}
\end{aligned} \notag
\]</span></p>
<h2 id="数值微分和积分">数值微分和积分</h2>
<h4 id="积分">积分</h4>
<h5 id="复合梯形法则">复合梯形法则</h5>
<p><span class="math display">\[
\int_a^b f(x) \mathrm{d} x=\frac{h}{2}\left(y_0+y_m+2 \sum_{i=1}^{n-1}
y_i\right)-\frac{(b-a) h^2}{12} f^{\prime \prime}(c)
\]</span><br />
其中 <span class="math inline">\(h=(b-a) / m, c\)</span> 在 <span
class="math inline">\(a\)</span> 和 <span
class="math inline">\(b\)</span> 之间.</p>
<p>推导思路对二个点进行拉格朗日插值 再积分 得到</p>
<h5 id="复合辛普森公式">复合辛普森公式</h5>
<p><span class="math display">\[
\int_a^b f(x) \mathrm{d} x=\frac{h}{3}\left[y_0+y_{2 m}+4 \sum_{i=1}^m
y_{2 i-1}+2 \sum_{i=1}^{m-1} y_{2 i}\right]-\frac{(b-a) h^4}{180}
f^{(4)}(c)
\]</span><br />
其中$h=(b-a) / m $ c 在 <span class="math inline">\(a\)</span> 和 <span
class="math inline">\(b\)</span> 之间.</p>
<p>辛普森公式推导思路对三个点进行拉格朗日插值 在积分 得到</p>
<h5 id="复合中点法则">复合中点法则</h5>
<p><span class="math display">\[
\int_a^b f(x) \mathrm{d} x=h \sum_{i=1}^m w_{i}+\frac{(b-a) h^2}{24}
f^{\prime \prime}(c)
\]</span></p>
<p>其中$h=(b-a) / m $ <span class="math inline">\(w_{i}\)</span> 是 在
a-b 中 m个相等子区间的中点 c 在 <span class="math inline">\(a\)</span>
和 <span class="math inline">\(b\)</span> 之间.</p>
<h5 id="龙贝格积分romberg-quadrature-formula">龙贝格积分Romberg
quadrature formula</h5>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> romberg(f::<span class="built_in">Function</span>,a::<span class="built_in">Float64</span>,b::<span class="built_in">Float64</span>,n::<span class="built_in">Int64</span>,tol::<span class="built_in">Float64</span>=<span class="number">10</span>^-<span class="number">10</span>)</span><br><span class="line">	l=b-a</span><br><span class="line">	r=zeros(<span class="built_in">Float64</span>,n,n)</span><br><span class="line">	r[<span class="number">1</span>,<span class="number">1</span>]=(l)*(f(a)+f(b))/<span class="number">2</span></span><br><span class="line">	<span class="comment">#r=[ (l)*(f(a)+f(b))/2]</span></span><br><span class="line">	h= l</span><br><span class="line">	<span class="meta">@simd</span> <span class="keyword">for</span> j <span class="keyword">in</span> <span class="number">2</span>:n</span><br><span class="line">		h = h/<span class="number">2</span></span><br><span class="line">		r[j,<span class="number">1</span>]=<span class="number">0.5</span>* r[j-<span class="number">1</span>,<span class="number">1</span>] + h * sum([ f(a+(<span class="number">2</span>*i-<span class="number">1</span>)*h)   <span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">1</span>:<span class="number">2</span>^(j-<span class="number">2</span>)] )</span><br><span class="line">		<span class="meta">@simd</span> <span class="keyword">for</span> k <span class="keyword">in</span> <span class="number">2</span>:j</span><br><span class="line"></span><br><span class="line">			r[j,k]=(<span class="number">4</span>^(k-<span class="number">1</span>) * r[j,k-<span class="number">1</span>] -r[j-<span class="number">1</span>,k-<span class="number">1</span>])/(<span class="number">4</span>^(k-<span class="number">1</span>)-<span class="number">1</span>)</span><br><span class="line">			</span><br><span class="line">		  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">			<span class="keyword">if</span> abs(r[j,j] - r[j-<span class="number">1</span>,j-<span class="number">1</span>]) &lt;= tol</span><br><span class="line">				println(<span class="string">&quot;finsh in &quot;</span>, j ,<span class="string">&quot;step&quot;</span>)</span><br><span class="line">				<span class="keyword">return</span> r[j,j]</span><br><span class="line">			<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">	println(<span class="string">&quot;finsh in &quot;</span>, j ,<span class="string">&quot;step&quot;</span> ,<span class="string">&quot; error :&quot;</span>, abs(r[n,n] - r[n-<span class="number">1</span>,n-<span class="number">1</span>]))</span><br><span class="line">	<span class="keyword">return</span> r[n,n]</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">println(romberg(x-&gt; log(x),<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">100</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>自适应积分</p>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> trapezoidal_rule(f::<span class="built_in">Function</span>,a::<span class="built_in">Float64</span>,b::<span class="built_in">Float64</span>)</span><br><span class="line">	<span class="keyword">return</span>  (f(a)+f(b))*(b-a)/<span class="number">2.0</span></span><br><span class="line">	</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#println(trapezoidal_rule(x-&gt;1+ sin(exp(3*x)),-1.0,1.0))</span></span><br><span class="line"><span class="keyword">function</span>  Simpson_rule(f::<span class="built_in">Function</span>,a::<span class="built_in">Float64</span>,b::<span class="built_in">Float64</span>)</span><br><span class="line">		h=(b-a)/<span class="number">2.0</span></span><br><span class="line">		<span class="keyword">return</span>  h*(f(a)+f(b)+<span class="number">4</span>*f(a+h))/<span class="number">3.0</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> adapquad(f::<span class="built_in">Function</span>,a::<span class="built_in">Float64</span>,b::<span class="built_in">Float64</span>,S::<span class="built_in">Function</span>,Tol::<span class="built_in">Float64</span>=<span class="number">10</span>^-<span class="number">5</span>,n::<span class="built_in">Int64</span>=<span class="number">100</span>,a_orig::<span class="built_in">Float64</span>=a,b_orig::<span class="built_in">Float64</span>=b)</span><br><span class="line">	</span><br><span class="line">	c = (a+b)/<span class="number">2.0</span></span><br><span class="line">	Sab=S(f,a,b)</span><br><span class="line">	Sac=S(f,a,c)</span><br><span class="line">	Scb=S(f,c,b)</span><br><span class="line">	get_Tol=abs(Sab-Sac-Scb)</span><br><span class="line">	<span class="keyword">if</span>  get_Tol &lt; Tol*(b-a)/(b_orig-a_orig)</span><br><span class="line">		<span class="comment">#println(&quot;convergence  in &quot; , n, &quot;step&quot;)</span></span><br><span class="line">		<span class="keyword">return</span>  Sac + Scb</span><br><span class="line">	<span class="keyword">elseif</span> n&lt;<span class="number">0</span></span><br><span class="line">		println(<span class="string">&quot;no convergence get_Tol:&quot;</span> ,get_Tol)</span><br><span class="line">		<span class="keyword">return</span>  Sac + Scb</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		 <span class="keyword">return</span> adapquad(f,a,c,S,Tol,n-<span class="number">1</span>,a_orig,b_orig) + adapquad(f,c,b,S,Tol,n-<span class="number">1</span>,a_orig,b_orig)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">println(adapquad(x-&gt;<span class="number">1.0</span>+ sin(exp(<span class="number">3.0</span>*x)),-<span class="number">1.0</span>,<span class="number">1.0</span>,trapezoidal_rule))</span><br><span class="line"></span><br><span class="line">println(adapquad(x-&gt;<span class="number">1.0</span>+ sin(exp(<span class="number">3.0</span>*x)),-<span class="number">1.0</span>,<span class="number">1.0</span>,Simpson_rule))</span><br></pre></td></tr></table></figure>
<h2 id="随机数和应用">随机数和应用</h2>
<p>随机数生成器的目的是使输出的数字满足独立同分布。</p>
<h4 id="线性同余生成器">线性同余生成器</h4>
<p><span class="math inline">\(x_i=a x_{i-1}+b(\bmod m)\)</span>,
a为乘子 b为偏移 m为模数 （如 a=13,b=0,m=31，以30为周期)</p>
<p>Park 和 Miller 提出一中随机数生成的方案 使用梅森（Mersennse) 素数
<span class="math inline">\(2^p -1\)</span> p为整数 （如 a=<span
class="math inline">\(7^5\)</span>,b=0,m=<span
class="math inline">\(2^{31}-1\)</span>，重复周期理论最大值为<span
class="math inline">\(2^{31}-2\)</span>)</p>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> LCG(x::<span class="built_in">Int64</span>,n::<span class="built_in">Int64</span>=<span class="number">1</span>,a::<span class="built_in">Int64</span>=<span class="number">7</span>^<span class="number">5</span>,m::<span class="built_in">Int64</span>=<span class="number">2</span>^<span class="number">31</span>-<span class="number">1</span>,b::<span class="built_in">Int64</span>=<span class="number">0</span>)</span><br><span class="line">	result=[]</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="number">1</span>:n</span><br><span class="line">		x= (a*x +b )%m</span><br><span class="line">		push!(result,<span class="number">1.0</span>*x/m)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">end</span> </span><br><span class="line">	<span class="keyword">return</span> result</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">#求 x^2 在0-1的积分值</span></span><br><span class="line">println(sum([ i^<span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> LCG(<span class="number">1</span>,<span class="number">3000</span>)])/<span class="number">3000</span>)</span><br></pre></td></tr></table></figure>
<h4 id="生成正态分布">生成正态分布</h4>
<h4 id="蒙卡1型问题">蒙卡1型问题</h4>
<p>求函数的均值</p>
<h4 id="蒙卡2型问题">蒙卡2型问题</h4>
<p>问题无法转换为计算函数平均值的问题 如求一个区域的面积</p>
<p>两类问题用伪随机数得到的误差</p>
<p><span class="math inline">\(\text { Error } \propto
n^{-\frac{1}{2}}\)</span></p>
<h4 id="扩展">扩展</h4>
<p>延迟斐波那契生成器 重复周期超过<span
class="math inline">\(2^{1400}\)</span></p>
<h4 id="拟随机数">拟随机数</h4>
<p>在条件允许下 放弃对随机数 的独立性要求</p>
<p>halton 选定一种进制 如 2 进制 第i随机数为 如 6 在二进制下 为110
倒转这个表示 为 011 写成小数 0.011 然后变回原来十进制 0.375</p>
<figure class="highlight julia"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> halton(p::<span class="built_in">Int64</span>,n::<span class="built_in">Int64</span>=<span class="number">1</span>)</span><br><span class="line">	num=<span class="built_in">Int</span>(ceil(log(p,n)))+<span class="number">1</span></span><br><span class="line">	b=zeros(num,<span class="number">1</span>)</span><br><span class="line">	eps=<span class="number">10</span>^-<span class="number">6</span></span><br><span class="line">	u=zeros(n,<span class="number">1</span>)</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> <span class="number">1</span>:n</span><br><span class="line">		</span><br><span class="line">		i=<span class="number">1</span></span><br><span class="line">		b[<span class="number">1</span>] += <span class="number">1</span></span><br><span class="line">		<span class="keyword">while</span> (b[i] &gt; (p-<span class="number">1</span> +eps))</span><br><span class="line">			</span><br><span class="line">			b[i] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">			i+=<span class="number">1</span></span><br><span class="line">			b[i] += <span class="number">1</span></span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line">		</span><br><span class="line">		u[j] = <span class="number">0</span></span><br><span class="line">		<span class="keyword">for</span> k <span class="keyword">in</span> <span class="number">1</span>:num</span><br><span class="line">			</span><br><span class="line">			u[j] = u[j] + b[k]*(<span class="number">1.0</span>*p)^(-k)</span><br><span class="line">			</span><br><span class="line">		<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="keyword">end</span></span><br><span class="line">	<span class="keyword">return</span> u</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>两类蒙卡问题用拟随机数得到的误差</p>
<p>1型蒙卡 <span class="math inline">\(\text { Error } \propto(\ln n)^d
n^{-1}\)</span></p>
<p>2型蒙卡 <span class="math inline">\(\text { Error }
\propto(n)^{\frac{1}{2}} n^{-\frac{1}{2 d}}\)</span></p>
<p>d是维度</p>
<h2 id="奇异值分解">奇异值分解</h2>
<h2 id="参考书籍">参考书籍</h2>
<p>数值分析 作者: <a href="https://book.douban.com/search/萨奥尔">萨奥尔
(Timothy Sauer)</a> 译者: <a
href="https://book.douban.com/search/裴玉茹">裴玉茹</a> / <a
href="https://book.douban.com/search/马赓宇">马赓宇</a></p>
]]></content>
      <tags>
        <tag>数值分析</tag>
        <tag>julia</tag>
      </tags>
  </entry>
  <entry>
    <title>苹果病害图像识别挑战赛</title>
    <url>/post/326483f6.html</url>
    <content><![CDATA[<p>一次比赛记录</p>
<span id="more"></span>
<p>数据下载<a
href="https://challenge.xfyun.cn/topic/info?type=apple-diseases&amp;option=stsj&amp;ch=vWxQGFU">地址</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os, sys, glob, argparse</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment">#%matplotlib inline</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, StratifiedKFold, KFold</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.manual_seed(<span class="number">0</span>)</span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">False</span></span><br><span class="line">torch.backends.cudnn.benchmark = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> datasets</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="comment">#from torch.utils.data.dataset import Dataset</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> albumentations <span class="keyword">as</span> A</span><br><span class="line"></span><br><span class="line">train_path = glob.glob(<span class="string">&#x27;./苹果病害图像识别挑战赛公开数据/train/*/*&#x27;</span>)</span><br><span class="line">test_path = glob.glob(<span class="string">&#x27;./苹果病害图像识别挑战赛公开数据/test/*&#x27;</span>)</span><br><span class="line"></span><br><span class="line">np.random.shuffle(train_path)</span><br><span class="line">np.random.shuffle(test_path)</span><br><span class="line"></span><br><span class="line">DATA_CACHE = &#123;&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">XunFeiDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="comment">#DATA_CACHE = &#123;&#125;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_path, transform=<span class="literal">None</span></span>):</span><br><span class="line">        self.img_path = img_path</span><br><span class="line">        <span class="keyword">if</span> transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.transform = transform</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.transform = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">    	</span><br><span class="line">        <span class="keyword">if</span> self.img_path[index] <span class="keyword">in</span> DATA_CACHE:</span><br><span class="line">            img = DATA_CACHE[self.img_path[index]]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment">#img = cv2.imread(self.img_path[index])</span></span><br><span class="line">            img = cv2.imdecode(np.fromfile(self.img_path[index], dtype=np.uint8), -<span class="number">1</span>)<span class="comment">#中文路径读取</span></span><br><span class="line">            <span class="comment"># imdecode读取的是rgb，如果后续需要opencv处理的话，需要转换成bgr，转换后图片颜色会变化</span></span><br><span class="line">            <span class="comment">#img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)但是测试结果是读取为bgr所以不用转换</span></span><br><span class="line">            DATA_CACHE[self.img_path[index]] = img</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#print(self.img_path[index].split(&#x27;\\&#x27;)[1])</span></span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img = self.transform(image = img)[<span class="string">&#x27;image&#x27;</span>]</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> self.img_path[index].split(<span class="string">&#x27;\\&#x27;</span>)[<span class="number">1</span>] <span class="keyword">in</span> [<span class="string">&#x27;d1&#x27;</span>, <span class="string">&#x27;d2&#x27;</span>, <span class="string">&#x27;d3&#x27;</span>, <span class="string">&#x27;d4&#x27;</span>, <span class="string">&#x27;d5&#x27;</span>, <span class="string">&#x27;d6&#x27;</span>, <span class="string">&#x27;d7&#x27;</span>, <span class="string">&#x27;d8&#x27;</span>, <span class="string">&#x27;d9&#x27;</span>]:</span><br><span class="line">        <span class="comment">#if self.img_path[index].split(&#x27;/&#x27;)[-2] in [&#x27;d1&#x27;, &#x27;d2&#x27;, &#x27;d3&#x27;, &#x27;d4&#x27;, &#x27;d5&#x27;, &#x27;d6&#x27;, &#x27;d7&#x27;, &#x27;d8&#x27;, &#x27;d9&#x27;]:</span></span><br><span class="line">            label = [<span class="string">&#x27;d1&#x27;</span>, <span class="string">&#x27;d2&#x27;</span>, <span class="string">&#x27;d3&#x27;</span>, <span class="string">&#x27;d4&#x27;</span>, <span class="string">&#x27;d5&#x27;</span>, <span class="string">&#x27;d6&#x27;</span>, <span class="string">&#x27;d7&#x27;</span>, <span class="string">&#x27;d8&#x27;</span>, <span class="string">&#x27;d9&#x27;</span>].index(self.img_path[index].split(<span class="string">&#x27;\\&#x27;</span>)[<span class="number">1</span>])<span class="comment">#.split(&#x27;/&#x27;)[-2])</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            label = -<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        img = img.transpose([<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">return</span> img, torch.from_numpy(np.array(label))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.img_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">XunFeiNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,l=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(XunFeiNet, self).__init__()</span><br><span class="line">                </span><br><span class="line">        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)<span class="comment">#(True)</span></span><br><span class="line">        model.avgpool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        model.fc = nn.Linear(<span class="number">512</span>, <span class="number">9</span>)</span><br><span class="line">        <span class="keyword">if</span> l!=<span class="literal">None</span>:</span><br><span class="line">            model=model.load_state_dict(torch.load(<span class="string">&#x27;model1.pth&#x27;</span>))</span><br><span class="line">        self.resnet = model</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img</span>):        </span><br><span class="line">        out = self.resnet(img)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">train_loader, model, criterion, optimizer</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    train_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i, (x, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        x = x.cuda(non_blocking=<span class="literal">True</span>)</span><br><span class="line">        target=target.<span class="built_in">float</span>()</span><br><span class="line">        target = target.cuda(non_blocking=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute output</span></span><br><span class="line">        output = model(x)</span><br><span class="line">        loss = criterion(output, target.long())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute gradient and do SGD step</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Train loss&#x27;</span>, loss.item())</span><br><span class="line">            </span><br><span class="line">        train_loss += loss.item()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> train_loss/<span class="built_in">len</span>(train_loader)</span><br><span class="line">            </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">validate</span>(<span class="params">val_loader, model, criterion</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    </span><br><span class="line">    val_acc = <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        end = time.time()</span><br><span class="line">        <span class="keyword">for</span> i, (x, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(val_loader):</span><br><span class="line">            x = x.cuda()</span><br><span class="line">            target=target.<span class="built_in">float</span>()</span><br><span class="line">            target = target.cuda()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute output</span></span><br><span class="line">            output = model(x)</span><br><span class="line">            loss = criterion(output, target.long())</span><br><span class="line">            </span><br><span class="line">            val_acc += (output.argmax(<span class="number">1</span>) == target).<span class="built_in">sum</span>().item()</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> val_acc / <span class="built_in">len</span>(val_loader.dataset)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">test_loader, model, criterion</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    val_acc = <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line">    test_pred = []</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        end = time.time()</span><br><span class="line">        <span class="keyword">for</span> i, (x, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader):</span><br><span class="line">            x = x.cuda()</span><br><span class="line">            target=target.<span class="built_in">float</span>()</span><br><span class="line">            target = target.cuda()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute output</span></span><br><span class="line">            output = model(x)</span><br><span class="line">            test_pred.append(output.data.cpu().numpy())</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> np.vstack(test_pred)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">    XunFeiDataset(train_path[:-<span class="number">1000</span>],</span><br><span class="line">            A.Compose([</span><br><span class="line">            A.RandomRotate90(),</span><br><span class="line">            A.Resize(<span class="number">256</span>, <span class="number">256</span>),</span><br><span class="line">            A.RandomCrop(<span class="number">224</span>, <span class="number">224</span>),</span><br><span class="line">            A.HorizontalFlip(p=<span class="number">0.5</span>),</span><br><span class="line">            A.RandomBrightnessContrast(p=<span class="number">0.5</span>),<span class="comment">#A.RandomContrast(p=0.5),</span></span><br><span class="line">            A.RandomBrightnessContrast(p=<span class="number">0.5</span>),</span><br><span class="line">            A.Normalize(mean=(<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>), std=(<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>))</span><br><span class="line">        ])</span><br><span class="line">    ), batch_size=<span class="number">30</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">4</span><span class="comment">#, pin_memory=False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">val_loader = torch.utils.data.DataLoader(</span><br><span class="line">    XunFeiDataset(train_path[-<span class="number">1000</span>:],</span><br><span class="line">            A.Compose([</span><br><span class="line">            A.Resize(<span class="number">256</span>, <span class="number">256</span>),</span><br><span class="line">            A.RandomCrop(<span class="number">224</span>, <span class="number">224</span>),</span><br><span class="line">            <span class="comment"># A.HorizontalFlip(p=0.5),</span></span><br><span class="line">            <span class="comment"># A.RandomContrast(p=0.5),</span></span><br><span class="line">            A.Normalize(mean=(<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>), std=(<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>))</span><br><span class="line">        ])</span><br><span class="line">    ), batch_size=<span class="number">30</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">4</span><span class="comment">#, pin_memory=False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">    XunFeiDataset(test_path,</span><br><span class="line">            A.Compose([</span><br><span class="line">            A.Resize(<span class="number">256</span>, <span class="number">256</span>),</span><br><span class="line">            A.RandomCrop(<span class="number">224</span>, <span class="number">224</span>),</span><br><span class="line">            A.HorizontalFlip(p=<span class="number">0.5</span>),</span><br><span class="line">            A.RandomBrightnessContrast(p=<span class="number">0.5</span>),<span class="comment">#RandomContrast(p=0.5),</span></span><br><span class="line">            A.Normalize(mean=(<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>), std=(<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>))</span><br><span class="line">        ])</span><br><span class="line">    ), batch_size=<span class="number">2</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">4</span><span class="comment">#, pin_memory=False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = XunFeiNet()</span><br><span class="line"></span><br><span class="line">model = model.to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">criterion = nn.CrossEntropyLoss().cuda()</span><br><span class="line">optimizer = torch.optim.AdamW(model.parameters(), <span class="number">0.00005</span>)<span class="comment">#0.001)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">	<span class="keyword">for</span> i  <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">		<span class="built_in">print</span>(i,<span class="string">&#x27;开始&#x27;</span>)</span><br><span class="line">		train_loss = train(train_loader, model, criterion, optimizer)</span><br><span class="line">		val_acc  = validate(val_loader, model, criterion)</span><br><span class="line">		train_acc = validate(train_loader, model, criterion)</span><br><span class="line"></span><br><span class="line">		<span class="built_in">print</span>(train_loss, train_acc, val_acc)</span><br><span class="line">	torch.save(model.state_dict(), <span class="string">&#x27;model1.pth&#x27;</span>)</span><br><span class="line">	pred = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">		<span class="keyword">if</span> pred <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">			pred = predict(test_loader, model, criterion)</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			pred += predict(test_loader, model, criterion)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	submit = pd.DataFrame(</span><br><span class="line">    	&#123;</span><br><span class="line">        	<span class="string">&#x27;uuid&#x27;</span>: [(x.split(<span class="string">&quot;\\&quot;</span>)[-<span class="number">1</span>]).split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> test_path],</span><br><span class="line">        	<span class="string">&#x27;label&#x27;</span>: [[<span class="string">&#x27;d1&#x27;</span>, <span class="string">&#x27;d2&#x27;</span>, <span class="string">&#x27;d3&#x27;</span>, <span class="string">&#x27;d4&#x27;</span>, <span class="string">&#x27;d5&#x27;</span>, <span class="string">&#x27;d6&#x27;</span>, <span class="string">&#x27;d7&#x27;</span>, <span class="string">&#x27;d8&#x27;</span>, <span class="string">&#x27;d9&#x27;</span>][x] <span class="keyword">for</span> x <span class="keyword">in</span> pred.argmax(<span class="number">1</span>)]</span><br><span class="line">	&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	submit = submit.sort_values(by=<span class="string">&#x27;uuid&#x27;</span>)</span><br><span class="line">	submit.to_csv(<span class="string">&#x27;submit1.csv&#x27;</span>, index=<span class="literal">None</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>我的棋局复盘记录</title>
    <url>/post/6361184f.html</url>
    <content><![CDATA[<p><img
src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/psc.png" /></p>
<p>和朋友下棋的记录</p>
<span id="more"></span>
<hr />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Event &quot;Casual Game&quot;]</span><br><span class="line">[Site &quot;https://lichess.org&quot;]</span><br><span class="line">[Date &quot;2023/7/15 上午12:49:16&quot;]</span><br><span class="line">[White &quot;Anonymous&quot;]</span><br><span class="line">[Black &quot;Anonymous&quot;]</span><br><span class="line">[Result &quot;*&quot;]</span><br><span class="line">[PlyCount &quot;66&quot;]</span><br><span class="line">[FEN &quot;rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1&quot;]</span><br><span class="line">[Variant &quot;Standard&quot;]</span><br><span class="line">[Termination &quot;?&quot;]</span><br><span class="line"></span><br><span class="line">1. d4 d5 2. c4 e6 3. Nf3 Nf6 4. Bg5 c5 5. cxd5 exd5 6. e3 Qb6 7. Qe2 Be7 8. Bxf6 Bxf6 9. Nc3 O-O 10. Nxd5 Qd6 11. Nxf6+ Qxf6 12. Rc1 b6 13. d5 Ba6 14. Qd2 Bxf1 15. Kxf1 Nd7 16. Qc2 h6 17. h4 g6 18. h5 g5 19. Ke2 Ne5 20. Rhd1 g4 21. Nxe5 Qxe5 22. d6 Qxh5 23. Rh1 Qg5 24. d7 g3 25. Rh3 Qg4+ 26. Kf1 Kg7 27. Rxg3 h5 28. Rxg4+ hxg4 29. Qf5 Rh8 30. Qg5+ Kf8 31. d8=Q+ Rxd8 32. Qxd8+ Kg7 33. Qg5+ Kh7 *</span><br></pre></td></tr></table></figure>
<hr />
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">[Event &quot;Casual Game&quot;]</span><br><span class="line">[Site &quot;https://lichess.org&quot;]</span><br><span class="line">[Date &quot;2023/7/20 上午12:08:56&quot;]</span><br><span class="line">[White &quot;Anonymous&quot;]</span><br><span class="line">[Black &quot;Anonymous&quot;]</span><br><span class="line">[Result &quot;*&quot;]</span><br><span class="line">[PlyCount &quot;69&quot;]</span><br><span class="line">[FEN &quot;rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1&quot;]</span><br><span class="line">[Variant &quot;Standard&quot;]</span><br><span class="line">[Termination &quot;?&quot;]</span><br><span class="line"></span><br><span class="line">1. d4 c6 2. e3 d5 3. Nf3 Bg4 4. Be2 f6 5. Bd2 Nd7 6. c3 e5 7. h3 Bh5 8. Na3 Qb6 9. Qb3 Bxa3 10. Qxa3 Ne7 11. g4 Bg6 12. Nh4 Bf7 13. Rg1 Be6 14. Nf5 Bxf5 15. gxf5 Nxf5 16. Bh5+ g6 17. Bg4 O-O-O 18. Bxf5 gxf5 19. O-O-O a6 20. Rg7 Nf8 21. Rf7 Nd7 22. Rg1 Rdf8 23. Rgg7 Rxf7 24. Rxf7 h5 25. Qe7 Qd8 26. f4 Re8 27. Qd6 Rf8 28. Rh7 Rh8 29. Rg7 Re8 30. c4 Rg8 31. Ba5 Nb6 32. Bxb6 Qxd6 33. Rxg8+ Kd7 34. Rd8+ Ke6 35. Rxd6+ *</span><br></pre></td></tr></table></figure>
<hr />
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">[Event &quot;Casual Game&quot;]</span><br><span class="line">[Site &quot;https://lichess.org&quot;]</span><br><span class="line">[Date &quot;2023/7/25 上午2:11:26&quot;]</span><br><span class="line">[White &quot;Anonymous&quot;]</span><br><span class="line">[Black &quot;Anonymous&quot;]</span><br><span class="line">[Result &quot;1-0&quot;]</span><br><span class="line">[PlyCount &quot;57&quot;]</span><br><span class="line">[FEN &quot;rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1&quot;]</span><br><span class="line">[Variant &quot;Standard&quot;]</span><br><span class="line">[Termination &quot;mate&quot;]</span><br><span class="line"></span><br><span class="line">1. d4 c6 2. e4 d5 3. e5 Bf5 4. Nf3 e6 5. Nc3 c5 6. Be3 Qb6 7. Nxd5 exd5 8. dxc5 Bxc5 9. Nd4 Ne7 10. Qd2 O-O 11. O-O-O Nbc6 12. Nxf5 Nxf5 13. Bd3 Nxe3 14. Bxh7+ Kxh7 15. Qd3+ g6 16. fxe3 Nxe5 17. Qe2 Bxe3+ 18. Kb1 Nc4 19. b3 Na3+ 20. Kb2 Rae8 21. Qf3 Bc5 22. Rxd5 Re3 23. Qg4 Rfe8 24. Rf1 R8e7 25. Rh5+ gxh5 26. Qxh5+ Kg8 27. Qg5+ Kf8 28. Qh5 Re1 29. Qh8# 1-0</span><br></pre></td></tr></table></figure>
<p>这局棋虽然白方开局丢了一匹马 但没有失去战意 后面每一步都认真对待
从而抓住黑方(我)的失误反败为胜 这也许是下棋和需要的心境</p>
<hr />
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">[Event &quot;Casual Game&quot;]</span><br><span class="line">[Site &quot;https://lichess.org&quot;]</span><br><span class="line">[Date &quot;2023/7/25 上午12:11:00&quot;]</span><br><span class="line">[White &quot;Anonymous&quot;]</span><br><span class="line">[Black &quot;me&quot;]</span><br><span class="line">1. e4 c6 2. d4 d5 3. Nf3 e6 4. Nc3 Bb4 5. a3 Bxc3+ 6. bxc3 dxe4 7. Ne5 Nd7 8. f3 Nxe5 9. dxe5 Qxd1+ 10. Kxd1 exf3 11. gxf3 Ne7 12. c4 O-O 13. Bg5 Ng6 14. Bd3 h6 15. Bxg6 hxg5 16. Bd3 b6 17. h4 gxh4 18. Rxh4 Rd8 19. Ke2 Bb7 20. Rah1 g6 21. Rh8+ Kg7 22. R1h7#</span><br></pre></td></tr></table></figure>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">[White &quot;spoe&quot;]</span><br><span class="line">[Black &quot;mkk&quot;]</span><br><span class="line">1. e4 c6 2. d4 d5 3. Nc3 Nf6 4. e5 Ne4 5. Be3 Bf5 6. f3 Nxc3 7. bxc3 h5 8. Bd3 e6 9. f4 Qa5 10. Ne2 c5 11. O-O Be4 12. Bxe4 dxe4 13. f5 Rh6 14. f6 Rh7 15. Rf4 g5 16. Rxe4 g4 17. Qb1 b6 18. a4 c4 19. Qb5+ Qxb5 20. axb5 a5 21. d5 exd5 22. Rd4 Bc5 23. Rxd5 Bxe3+ 24. Kf1 Nd7 25. Ng3 O-O-O 26. Re1 Bf4 27. e6 fxe6 28. Rxe6 Rf8 29. Rf5 Bxg3 30. hxg3 Rhf7 31. Ke2 Rxf6 32. Rfxf6 Nxf6 33. Ke3 Re8 34. Rxe8+ Nxe8</span><br></pre></td></tr></table></figure>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">[Event &quot;Casual Game&quot;]</span><br><span class="line">[Site &quot;https://lichess.org&quot;]</span><br><span class="line">[Date &quot;2023/8/2 下午11:40:28&quot;]</span><br><span class="line">[White &quot;天海悠树&quot;]</span><br><span class="line">[Black &quot;mkk&quot;]</span><br><span class="line">[Result &quot;*&quot;]</span><br><span class="line">[PlyCount &quot;45&quot;]</span><br><span class="line">[FEN &quot;rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1&quot;]</span><br><span class="line">[Variant &quot;Standard&quot;]</span><br><span class="line">[Termination &quot;?&quot;]</span><br><span class="line"></span><br><span class="line">1. e4 c6 2. Nc3 d5 3. Nf3 Bg4 4. h3 Bxf3 5. Qxf3 e6 6. exd5 cxd5 7. d4 Nc6 8. Qe3 a6 9. Bd2 Qb6 10. Nxd5 Qd8 11. Nf4 Nxd4 12. O-O-O Nf6 13. Bc3 Qc7 14. Qxd4 Rd8 15. Qxd8+ Qxd8 16. Rxd8+ Kxd8 17. Be2 Bc5 18. Nd3 Bd6 19. Bf3 b6 20. Ne5 Ke8 21. Rd1 Ke7 22. Rxd6 Kxd6 23. Nxf7+ *</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Event &quot;Casual Game&quot;]</span><br><span class="line">[Site &quot;https://lichess.org&quot;]</span><br><span class="line">[Date &quot;2023/8/13 下午12:30&quot;]</span><br><span class="line">[White &quot;全肯定&quot;]</span><br><span class="line">[Black &quot;mkk&quot;]</span><br><span class="line">1. e4 c6 2. c4 d5 3. cxd5 cxd5 4. exd5 Nf6 5. Bb5+ Bd7 6. Qa4 Nxd5 7. Bxd7+ Nxd7 8. Nf3 Nb6 9. Qd4 e6 10. O-O Bc5 11. Qxg7 Rf8 12. d4 Bd6 13. Qxh7 Rc8 14. Nc3 Nf6 15. Qh4 Be7 16. Bg5 Nc4 17. Rab1 Nd5 18. Nxd5 exd5 19. Bxe7 Qxe7 20. Rfe1</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Event &quot;Casual Game&quot;]</span><br><span class="line">[Site &quot;https://lichess.org&quot;]</span><br><span class="line">[Date &quot;2023/8/17 下午10:50:19&quot;]</span><br><span class="line">[White &quot;全肯定&quot;]</span><br><span class="line">[Black &quot;mkk&quot;]</span><br><span class="line">[Result &quot;*&quot;]</span><br><span class="line">[PlyCount &quot;35&quot;]</span><br><span class="line">[FEN &quot;rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1&quot;]</span><br><span class="line">[Variant &quot;Standard&quot;]</span><br><span class="line">[Termination &quot;?&quot;]</span><br><span class="line"></span><br><span class="line">1. e4 c6 2. Nc3 d5 3. exd5 cxd5 4. d4 e6 5. Nf3 Nc6 6. Bf4 Nf6 7. Bd3 Bd6 8. Qd2 O-O 9. O-O Re8 10. Rfe1 a6 11. a3 Qc7 12. Bxd6 Qxd6 13. h3 e5 14. dxe5 Nxe5 15. Nxe5 Rxe5 16. Rxe5 Qxe5 17. Re1 Qc7 18. Nxd5 *</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Event &quot;Casual Game&quot;]</span><br><span class="line">[Site &quot;https://lichess.org&quot;]</span><br><span class="line">[Date &quot;2023/8/19 &quot;]</span><br><span class="line">[White &quot;spoe&quot;]</span><br><span class="line">[Black &quot;mkk&quot;]</span><br><span class="line">[Result &quot;*&quot;]</span><br><span class="line">[PlyCount &quot;35&quot;]</span><br><span class="line">[FEN &quot;rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1&quot;]</span><br><span class="line">[Variant &quot;Standard&quot;]</span><br><span class="line">[Termination &quot;?&quot;]</span><br><span class="line">1. d4 c6 2. e3 d5 3. c4 Bf5 4. Nc3 e6 5. Qb3 b6 6. Nf3 Nd7 7. Qd1 Bb4 8. a3 Bd6 9. Bd3 Bxd3 10. Qxd3 Ngf6 11. b4 O-O 12. c5 Bc7 13. cxb6 axb6 14. b5 c5 15. dxc5 Nxc5 16. Qc2 e5 17. Bb2 d4 18. exd4 exd4 19. Rd1 Ne6 20. Ne4 Qd7 21. a4 Rfd8 22. Qd3 Nxe4 23. Qxe4 d3 24. O-O Nc5 25. Qh4 Rxa4 26. Qh5 Ra2 27. Ng5 Qf5 28. Bxg7 Kxg7 29. Ne6+ fxe6 30. Qh4 Ne4 31. g4 Qf4 32. f3 Nd6 33. Qe7+ Qf7 34. Qg5+ Kh8 35. Qe5+ Kg8 36. Qc3 Nxb5 37. Qb3 Ra5 38. Rfe1 Nd4 39. Qxd3 Nxf3+</span><br></pre></td></tr></table></figure>
<p>复制棋谱点击<a
href="https://lichess.org/analysis">此处</a>到lichess上复盘</p>
]]></content>
      <tags>
        <tag>国际象棋</tag>
      </tags>
  </entry>
  <entry>
    <title>国际象棋开局和体系</title>
    <url>/post/5122df53.html</url>
    <content><![CDATA[<p><img
src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Searching%20for%20Bobby%20Fischer.jpg" /></p>
<p>收集的一些棋谱和教程</p>
<span id="more"></span>
<blockquote>
<p>“尽管那些玩世不恭愤世嫉俗的犬儒主义者一再挖苦、非难我们钟爱的国际象棋,然而,犬儒主义者怎么知道棋弈本身蕴藏着无穷的科学。棋弈将我们从痛苦忧伤中解脱出来,棋弈安慰焦躁不安的恋人,棋弈用艺术的眼光评议战士,当严重的危险压迫着我们,最终又屈服于我们,当我们最需要他们的时候,他们是我们孤独时的伙伴"。伊本·阿尔姆塔兹,约于
1040 年</p>
</blockquote>
<h2 id="伦敦体系">伦敦体系</h2>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/London%20System.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'>London System</font></b>
</center>
<p></font></p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. d4 Nf6 2. Bf4 d5 3. e3 e6 4. Nd2 c5 5. c3 Nc6 6. Ngf3 Be7 7. Bd3 a6 8. Ne5 O-O 9. h4 Nxe5 10. dxe5 Nd7 11. Bxh7+ Kxh7 12. Qh5+ Kg8 13. Nf3 f6 14. Ng5 fxg5 15. hxg5 Bxg5 16. Bxg5 Qc7 17. f4 d4 18. O-O-O dxc3 19. Qh7+ Kf7 20. Rh6 cxb2+ 21. Kb1 c4 22. Qg6+ Kg8 23. Rdh1</span><br></pre></td></tr></table></figure>
<h3 id="视频教程">视频教程</h3>
<ol type="1">
<li><a
href="https://www.bilibili.com/video/BV1vi4y1m7yZ/?spm_id_from=333.337.search-card.all.click&amp;vd_source=89cd1bd958a3eea212de763dc113559e">b站搬运翻译的</a>
<a
href="https://www.chess.com/lessons/london-system-for-the-busy-chess-player">原视频</a></li>
</ol>
<h2 id="caro-kann-defence">Caro-Kann defence</h2>
<p>最早由维也纳大师 马里奥康走的 后来由德国卡罗 把大部分变例推演出来</p>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Caro-Kann_defence.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'>Caro-Kann defence</font></b>
</center>
<p></font></p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 c6 2. d4 d5 3. e5 c5 4. dxc5 Nc6 5. Nf3 Bg4 6. Be2 e6 7. Be3 Nge7 8. h3 Bxf3 9. Bxf3</span><br></pre></td></tr></table></figure>
<h3 id="视频教程-1">视频教程</h3>
<ol type="1">
<li><a
href="https://www.bilibili.com/video/BV1sh4y1y7YA/?spm_id_from=333.999.0.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e">b站搬运的</a>
；<a
href="https://www.youtube.com/watch?v=0p_881Nwoo4">YouTube原视频地址</a></li>
</ol>
<h3 id="挺兵变例">挺兵变例</h3>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 c6 2. d4 d5 3. e5 Bf5 4. Bd3 Bxd3 5. Qxd3 e6 6. Ne2 c5 7. c3 Ne7 8. Qb5+ Qd7 9. Qxc5 Nf5 10. Qa5 b6</span><br></pre></td></tr></table></figure>
<p>黑方相到f线 白方和你兑白格相要兑 不然很惨</p>
<p>https://www.youtube.com/watch?v=j17vjUbBuaE</p>
<h3 id="视频教程-2">视频教程</h3>
<p>b站 <a
href="https://www.bilibili.com/video/BV1VD4y1w7KK/?spm_id_from=333.788.recommend_more_video.2&amp;vd_source=89cd1bd958a3eea212de763dc113559e">yixinchess</a></p>
<h3 id="你会面对的陷阱">你会面对的陷阱</h3>
<h3 id="兑马变例">兑马变例</h3>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Caro-Kann%20Defencekinights%20exchangee.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'> 兑马变例</font></b>
</center>
<p></font></p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 c6 2. Nc3 d5 3. d4 dxe4 4. Nxe4 Nf6 5. Nxf6+ exf6 6. Bc4 Be7 7. Qh5 O-O 8. Ne2 g6 9. Qf3 Nd7 10. Bh6 Re8 11. Bxf7+ Kxf7 12. Qa3</span><br></pre></td></tr></table></figure>
<h3 id="视频教程-3">视频教程</h3>
<ol type="1">
<li><a
href="https://www.bilibili.com/video/BV1Eu411m7Wr/?spm_id_from=333.788.recommend_more_video.-1&amp;vd_source=89cd1bd958a3eea212de763dc113559e">B站
up yixinchess</a></li>
</ol>
<h4 id="帕诺夫攻击">帕诺夫攻击</h4>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Accelerated%20Panov%20Attack.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'>Accelerated Panov Attack</font></b>
</center>
<p></font></p>
<blockquote>
<p>Accelerated Panov Attack</p>
<ol start="2" type="1">
<li>c4</li>
</ol>
<p>Instead of playing d4, white can respond with the Accelerated Panov
Attack, an aggressive counter against the Caro-Kann. The Accelerated
Panov Attack (<strong>1. e4 1...c6 2. c4</strong>), named after the
soviet grandmaster Vasily Panov is the second most common move against
the Caro-Kann, and is an aggressive response against the Caro-Kann. This
is because if black were to play 2...d5, white can follow up with exd5
(white can also choose to play 3. cxd5) taking the pawn, black 3...cxd5
taking the pawn, white 4. cxd5 taking the pawn and black 4...Qxd5 taking
with the queen. However, this is a trade of pawns as white and black has
won the same material. White aims weaken the D-file and to take the d5
pawn, and to also wreck havoc by aiming to take the c-pawn. The idea of
the Accelerated Panov Attack is to counter the Caro-Kann and to weaken
the D-file and C-file and to take the d5 pawn, and to open up the
D-file, which weakens black’s pawn structure. The Accelerated Panov
Attack controls the d5 square, and allows the knight to develop behind
the c-pawn.</p>
<p>Black has some...</p>
<p><a
href="https://en.wikibooks.org/wiki/Chess_Opening_Theory/1._e4/1...c6/2._c4">Read
more on WikiBooks</a></p>
</blockquote>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 c6 2. c4 d5 3. exd5 cxd5 4. d4 Nf6 5. Nc3 Nc6 6. Bg5 Qb6 7. cxd5 Qxb2 8. Rc1 Nb4 9. Na4 Qxa2 10. Bc4 Qa3 11. Rc3 Nd3+ 12. Qxd3 Qd6</span><br></pre></td></tr></table></figure>
<p>第六步除了走相还有走马</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 c6 2. d4 d5 3. Nc3 dxe4 4. Nxe4 Nf6 5. Qd3 e5 6. dxe5 Qa5+ 7. Bd2 Qxe5 8. O-O-O Nxe4 9. Qd8+ Kxd8 10. Bg5+</span><br></pre></td></tr></table></figure>
<h3 id="视频教程-4">视频教程</h3>
<p><a
href="https://www.bilibili.com/video/BV12L411c7jM/?spm_id_from=333.788.recommend_more_video.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e">B站
up yixinchess</a></p>
<h3 id="双马攻击">双马攻击</h3>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Caro-Kann%20Defence%20two%20knights.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'> 双马攻击</font></b>
</center>
<p></font></p>
<p>来自阿列亨 非常现代的走法</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 c6 2. Nc3 d5 3. d4 dxe4 4. Nxe4 Nf6 5. Nxf6+ exf6 6. Bc4 Be7 7. Qh5 O-O 8. Ne2 g6 9. Qf3 Nd7 10. Bh6 Re8 11. Bxf7+ Kxf7 12. Qb3#</span><br></pre></td></tr></table></figure>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 c6 2. Nc3 d5 3. Nf3 dxe4 4. Nxe4 Bf5 5. Ng3 Bg6 6. h4 h6 7. Ne5 Bh7 8. Qh5 g6 9. Bc4 e6 10. Qf3 f5 11. Bxe6</span><br></pre></td></tr></table></figure>
<p>相不应该退</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 c6 2. Nc3 d5 3. Nf3 dxe4 4. Nxe4 Bf5 5. Ng3 Bg6 6. h4 h6 7. Ne5 Nd7 8. Nxg6 fxg6 9. d4 e5 10. Qg4 Qf6 11. Be3 Ne7 12. Ne4 Qf7 13. Nd6+ Kd8 14. Nxf7+</span><br></pre></td></tr></table></figure>
<p>不应该走马e7</p>
<h3 id="视频教程-5">视频教程</h3>
<p><a
href="https://www.bilibili.com/video/BV1qr4y1a7Ue/?spm_id_from=333.788.recommend_more_video.1&amp;vd_source=89cd1bd958a3eea212de763dc113559e">B站
up yixinchess</a></p>
<h2 id="斯堪的纳维亚防御-scandinavian-defence">斯堪的纳维亚防御
Scandinavian Defence</h2>
<blockquote>
<p>1... d5 - Scandinavian Defence</p>
<p>The Scandinavian Defense (or Centre Counter Defense) is one of the
oldest chess openings, dating back the 16th century. This opening tries
to break White's centre and stop white from taking control. The
Scandinavian defense is Black's 9th most popular response to 1.e4 and
grandmasters such as Magnus Carlsen occasionally play this move in
tournaments. White has a few possible replies:</p>
<p>This is White's strongest reply, and exposes chief drawback of the
Scandinavian Defense: in order to recover the pawn (while not mandatory)
Black must now bring out his queen providing White with a target to
attack. This was considered enough of a problem to put the opening out
of business for much of the mid-20th century. However, modern players
are a little more comfortable breaking the rules, and the Scandinavian
has enjoyed some modern popularity.</p>
<p>White can...</p>
<p><a
href="https://en.wikibooks.org/wiki/Chess_Opening_Theory/1._e4/1...d5">Read
more on WikiBooks</a></p>
</blockquote>
<h3 id="section"></h3>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Scandinavian_Defence_Modern_Variation.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'>Scandinavian Defence Modern Variation</font></b>
</center>
<p></font></p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 d5 2. exd5 Nf6 3. d4 Qxd5 4. c4 Qe4+ 5. Ne2 e5 6. Nc3 Bb4 7. Qa4+ Nc6 8. d5 Nxd5 9. cxd5 Bxc3+</span><br></pre></td></tr></table></figure>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Scandinavian_%20Defence.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'>Scandinavian Defence</font></b>
</center>
<p></font></p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 d5 2. exd5 Nf6 3. d4 Qxd5 4. c4 Qe4+ 5. Ne2 e5 6. Nc3 Bb4 7. Qa4+ Nc6 8. f3 Bxc3+ 9. bxc3 Qh4+ 10. g3 Qh5 11. d5 Qxf3 12. Rg1 Ne4 13. dxc6 Qf2+ 14. Kd1 Qxe2+ 15. Bxe2 Nxc3+ 16. Ke1 Nxa4</span><br></pre></td></tr></table></figure>
<h3 id="视频教程-6">视频教程</h3>
<p><a
href="https://www.bilibili.com/video/BV16a411y7RT/?spm_id_from=333.788.recommend_more_video.3&amp;vd_source=89cd1bd958a3eea212de763dc113559e">yixinchess</a></p>
<h2 id="俄罗斯防御-stafford-gambit">俄罗斯防御/ Stafford Gambit</h2>
<blockquote>
<p>Petrov's Defence</p>
<p>2...Nf6</p>
<p>The Petrov's Defence (or Russian game) is a solid response to White's
2. Nf3. While this opening is often drawish and boring, it is still
popular, and quite often played in chess tournaments. White has a couple
of good responses here:</p>
<p>3.Nxe5 is the main line (or <strong>Classical Variation</strong>). If
...Nc6 is played afterwards, it will most likely be the <strong>Stafford
Gambit</strong>. In this line, it's not advised for Black to take
White's pawn before having chased the knight. There is a famous trap :
3...Nxe4? 4. Qe2 Nd6?? (or 4...Nf6??) 5. Nc6+ and Black's queen is lost.
There are a few lines that are quite dangerous in the Classical
Variation, especially the Cochrane Gambit, which goes 3...d6 4. Nxf7,
sacrificing a knight for two pawns and an exposed king. Rarely do games
in the Cochrane Gambit end in a draw, especially due to the attacking
opportunities and aggression offered by the position as White tries to
gain a pawn back (3 pawns for a knight is material equality), while
Black tries to maintain its advantage of a pawn....</p>
<p><a
href="https://en.wikibooks.org/wiki/Chess_Opening_Theory/1._e4/1...e5/2._Nf3/2...Nf6">Read
more on WikiBooks</a></p>
</blockquote>
<blockquote>
<p>3... Nc6</p>
<p>Black invites White to trade knights. White, being up one pawn in
material, is compelled to accept the trade.<br />
4.Nxc6 is the main line.</p>
<p><a
href="https://en.wikibooks.org/wiki/Chess_Opening_Theory/1._e4/1...e5/2._Nf3/2...Nf6/3._Nxe5/3...Nc6">Read
more on WikiBooks</a></p>
</blockquote>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Stafford_Gambit.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'>Stafford Gambit</font></b>
</center>
<p></font></p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 e5 2. Nf3 Nf6 3. Nxe5 Nc6 4. Nxc6 dxc6 5. Nc3 Bc5 6. Bc4 Ng4 7. O-O Qh4 8. h3 Nxf2 9. Qe1 Nxh3+ 10. Kh1 Nf2+ 11. Kg1 Qh1#</span><br></pre></td></tr></table></figure>
<p>第5步的时候白棋应该出h 3</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 e5 2. Nf3 Nf6 3. Nc3 Bc5 4. Nxe5 Nc6 5. Nxc6 dxc6 6. Be2 Qd4 7. O-O h5 8. h3 Ng4 9. hxg4 hxg4 10. g3 Qe5 11. Kg2 Bxf2 12. Rxf2 Qh5 13. Rf5</span><br></pre></td></tr></table></figure>
<h3 id="视频教程-7">视频教程</h3>
<p><a
href="https://www.bilibili.com/video/BV1Zu411V7oc/?spm_id_from=333.880.my_history.page.click&amp;vd_source=89cd1bd958a3eea212de763dc113559e">b站视频</a></p>
<h2 id="古印度or格林菲德-防御">古印度or格林菲德 防御</h2>
<p>王翼印度防御是一支名为
hypermodernism（直译「超现代主义」）的流派的产物。其主要思想为：中心控制权可以藉由<em>非直接控制</em>占领。通过前期主动“邀请”对手用子力控制中心，可以使其棋形固化，进而暴露出可以攻击的弱点。在本例中，中心恰恰成为了阻隔王、后翼的壁垒，使得白方的子力无法在王翼的进攻中有效调度，进而取得局部的巨大战略优势。</p>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/King_Indian_Defense.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'>King's'Indian Defense</font></b>
</center>
<p></font></p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. d4 Nf6 2. c4 g6 3. Nc3 Bg7 4. e4 d6 5. Nf3 O-O 6. Bd3 Bg4 7. h3 Bxf3 8. Qxf3 Nc6 9. Be3 Nd7 10. Ne2 Nde5 11. dxe5 Nxe5 12. Qg3 Nxd3+ 13. Kd2 Nxb2</span><br></pre></td></tr></table></figure>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. d4 Nf6 2. c4 g6 3. Nc3 d5 4. Bf4 Nh5 5. Nxd5 (5. Be5 f6 6. Bg3 Nxg3 7. hxg3 c6 8. e3 Bg7 9. Bd3 O-O 10. Rxh7 Kxh7 11. Qh5+ Kg8 12. Bxg6 Re8 13. Bxe8) 5... Nxf4 6. Nxf4 e5 7. dxe5 (7. Nd3 Qxd4) 7... Bb4+ 8. Qd2 Qxd2#</span><br></pre></td></tr></table></figure>
<p>第一步搭建堡垒（对方出了e兵记得顶d兵）</p>
<p>第二步（可以略去） 出马b6比较激烈（会被兵攻击） 可以考虑马到e7
但之前要处理好相 （可以到g4 如果去不了可以兵b6然后相b7）</p>
<p>第三步 顶e兵攻击 如果对方和你一样是短易位可以把王翼的兵都顶起来攻击
如果对方长易位 建议封锁王城</p>
<p>自己瞎摆的谱</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. e4 d6 2. d4 Nf6 3. Nc3 (3. e5 dxe5 4. dxe5 Qxd1+ 5. Kxd1 Ne4) 3... g6 4. Nf3 Bg7 5. h3 O-O 6. Be2 b6 7. O-O Bb7 (7... e5)</span><br></pre></td></tr></table></figure>
<p>中村光的局超级复制orz</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. d4 Nf6 2. c4 g6 3. Nc3 Bg7 4. e4 d6 5. Nf3 O-O 6. Be2 e5 7. O-O (7. dxe5 dxe5 8. Qxd8 Rxd8 9. Nxe5 Nxe4 10. Nxe4 Bxe5) 7... Nc6 8. d5 Ne7 9. Ne1 Nd7 10. f3 f5 11. Be3 f4 12. Bf2 g5 13. Nd3 Ng6 14. c5 Nf6 15. Rc1 Rf7 16. Kh1 h5 17. cxd6 cxd6 18. Nb5 a6 19. Na3 b5 20. Rc6 g4 21. Qc2 Qf8 22. Rc1 Bd7 23. Rc7 Bh6 24. Be1 h4 25. fxg4 f3 26. gxf3 Nxe4 27. Rd1 (27. fxe4 Rf1+ 28. Bxf1 (28. Kg2 Be3 29. Bxf1 h3+ 30. Kxh3 Qf3+ 31. Bg3 Bxg4#) 28... Qxf1#) 27... Rxf3 28. Bxf3 (28. Rxd7 Rf1+ 29. Kg2 Be3 30. Bg3 hxg3 31. Rxf1 Nh4+ 32. Kh3 Qh6 33. g5 Nxg5+ 34. Kg4 Nhf3 35. Nf2 Qh4+ 36. Kf5 Rf8+ 37. Kg6 Rf6+ 38. Kxf6 Ne4+ 39. Kg6 Qg5#) 28... Qxf3+ 29. Qg2 Bxg4 30. h3 Qxg2+ 31. Kxg2 Bxd1</span><br></pre></td></tr></table></figure>
<h3 id="视频教程-8">视频教程</h3>
<p><a
href="https://www.bilibili.com/video/BV1us4y1r7vx/?spm_id_from=333.999.0.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e">Ali_Chess</a></p>
<p>https://www.youtube.com/watch?v=5XyayUs6J1M</p>
<p>https://www.bilibili.com/video/BV1T84y1U75C/?spm_id_from=333.999.0.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e</p>
<h2 id="nakhmanson-gambit冷门开局">Nakhmanson Gambit(冷门开局)</h2>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 e5 2. Nf3 Nc6 3. d4 exd4 4. Bc4 Nf6 5. O-O Nxe4 6. Nc3 dxc3 7. Bxf7+ Kxf7 8. Qd5+ *</span><br></pre></td></tr></table></figure>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Nakhmanson_Gambit.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'> Nakhmanson Gambit</font></b>
</center>
<p></font></p>
<h3 id="视频教程-9">视频教程</h3>
<p><a
href="https://www.bilibili.com/video/BV1V54y1D72N/?spm_id_from=333.999.top_right_bar_window_custom_collection.content.click&amp;vd_source=89cd1bd958a3eea212de763dc113559e">b站视频</a></p>
<h2 id="西西里防御-sicilian-defence">西西里防御 Sicilian Defence</h2>
<p>该开局法是由意大利棋艺理论家卡里拉(1573-16Sicilian
Defence47)首创，由英国棋手<a
href="https://www.zhihu.com/search?q=萨拉特&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A%223130932709%22%7D">萨拉特</a>(1772-1819)命名。19世纪时被认为不利于黑方，于是应用者少，20世纪出现大量新变着，渐渐成为半开放型局面中最流行的开局体系。黑方在第一步就阻碍白方形成控制中心方案，并准备攻击白方后翼，以对抗白方可能在中心或是王翼发起的进攻。
几乎所有变化极容易形成尖锐复杂的局面，也就是容易形成各攻一方。
总之这种布局黑方还是非常满意的，有利于黑方下出攻击型风格。</p>
<p>作者：散落于云海<br />
链接：https://www.zhihu.com/question/429435723/answer/3130932709<br />
来源：知乎<br />
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<p>西西里是用c兵换d兵 卡罗康是用b兵换d兵</p>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Sveshnikov%20Sicilian.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'>Sveshnikov Sicilian</font></b>
</center>
<p></font></p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e5 6. Ndb5 d6 7. Bg5 a6 8. Na3 b5 9. Nd5 Be7 10. Nxe7 Qxe7</span><br></pre></td></tr></table></figure>
你会发现西西里棋很晚才过5线 因为西西里防御是先守再攻<br />

<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Sicilian.png" style="height: 300px; width: auto;"/>
</center>
<center>
<p><b></p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 Qb6 6. Nb3 e6 7. a3 Be7 8. g3 O-O 9. Bg2 a6 10. O-O d6 11. Be3 Qc7 12. f4 Rd8</span><br></pre></td></tr></table></figure>
<p>B33里面的后b6的变种</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 Qb6 (5... e6) 6. Ndb5 (6. Nb3</span><br><span class="line">e6 7. a3 Be7 8. g3 O-O 9. Bg2 a6 10. O-O Qc7 (10... Rd8) (10... d6 11. Be3 Qc7</span><br><span class="line">12. f4 Rd8) 11. Be3)</span><br></pre></td></tr></table></figure>
<h2 id="保尔逊体系-b40-49">保尔逊体系 B40-49</h2>
<table rules="none" align="center">
<tr>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Sicilian_e6.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA">2</font><br />

</center>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Sicilian_e6_2.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA">5</font><br />

</center>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Sicilian_e6_3.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA">8</font><br />

</center>
</td>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Sicilian_e6_4.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA">13</font><br />

</center>
</td>
</tr>
</table>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. e4 c5 2. Nf3 e6 3. d4 cxd4 4. Nxd4 a6 5. Be2 Nf6 6. Nc3 Bb4 7. Qd3 d5 8. e5 Ne4 9. O-O Bxc3 10. bxc3 Nd7 11. c4 O-O (11... Nxe5) 12. Qe3 Re8 13. Ba3 Qa5</span><br></pre></td></tr></table></figure>
<p>第2 步不出 Nc6 e6为了d5兵保护 打开相路 但是Nf6不怕e5吗</p>
<p>up推荐的简单版本</p>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Sicilian_e6_5.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'>简单版本</font></b>
</center>
<p></font></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. e4 c5 2. Nf3 e6 3. d4 cxd4 4. Nxd4 a6 5. Be2 Nf6 6. Nc3 Be7 7. O-O Nc6 8. Be3 b5 9. f4</span><br></pre></td></tr></table></figure>
<table rules="none" align="center">
<tr>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Sicilian_e6_5.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA">简单版本</font><br />

</center>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Sicilian_e6_6.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA">另一种变化</font><br />

</center>
</td>
</tr>
</table>
<p>另一种变化</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. e4 c5 2. Nf3 e6 3. d4 cxd4 4. Nxd4 Nc6  5. Nc3 Qc7 6. f4 a6 7. Nxc6 Qxc6 8. Bd3 b5 9. Qe2 Bb7 10. Bd2 Bc5 11. a3</span><br></pre></td></tr></table></figure>
<h2 id="纳道尔夫体系-b90-99">纳道尔夫体系 B90-99</h2>
<p>虽然说是体系但是up没说具体运用orz</p>
<table rules="none" align="center">
<tr>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Najdorf.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA">Najdorf</font><br />

</center>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Najdorf2.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA">Najdorf</font><br />

</center>
</td>
</tr>
</table>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. e4 c5 2. Nf3 d6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 a6 6. g3 (6. Be2 Nbd7 7. Be3 Nc5 8. f3 e6 9. a4 b6 10. O-O Bb7 11. Qd2 Rc8 12. Rfd1 Be7 13. b4 Ncd7 14. b5) 6... b5 (6... e5 7. Nde2 Be6 8. Bg2 Be7 9. O-O Nbd7 10. a4 Rc8 11. h3 Nb6 12. Bg5 d5 (12... h6 13. Bxf6 Bxf6 14. b3 O-O 15. a5 Nd7) 13. exd5 Nfxd5 14. Nxd5 Nxd5) 7. Bg2 Bb7 8. O-O e6 9. Re1 Qc7 10. a4 b4 11. Na2 a5 12. c3</span><br></pre></td></tr></table></figure>
<h2 id="舍文宁根scheveningen-variation-b80-85">舍文宁根Scheveningen
Variation B80-85</h2>
<p>结合了 纳道尔夫和保尔逊</p>
<blockquote>
<p>Scheveningen Variation</p>
<p><strong>5... e6</strong>, building a so-called "small center", is the
signature move of the Scheveningen Variation of the Sicilian Defence.
<strong>5... e6</strong> strengthens Black's control of the important
<strong>d5</strong> square and opens <strong>e7</strong> for the
development of his dark-squared bishop. If Black is able to safely play
<strong>... d5</strong> later on, he will have a good position.</p>
<p>In contrast to the Najdorf Variation, <strong>5... a6</strong>, the
Scheveningen commits Black earlier to a certain pawn structure in the
center and delays queenside operations, but does more to promote Black's
early development and castling. Both systems are considered very solid
choices for Black, however <strong>5... a6</strong> has been played by
even the best Scheveningen specialists (including Garry Kasparov) to
avoid the dangerous <em>Keres Attack</em>, <strong>5... e6 6.
g4!</strong> (Although by no means winning for White, statistics sharply
favour the white pieces.)</p>
<p>.</p>
</blockquote>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Scheveningen%20Variation.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'>Scheveningen Variation</font></b>
</center>
<p></font></p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 c5 2. Nf3 d6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 e6 6. Be3 (6. f4 Nc6 7. Be3 Be7 8. Bd3 O-O 9. O-O Nxd4 10. Bxd4 e5 11. fxe5 dxe5 12. Bxe5 Ng4 13. Bf4 Bc5+ 14. Kh1 Nf2+ 15. Rxf2 Bxf2) (6. Be2 a6 7. f4 (7. O-O Qc7 8. f4 Nc6 9. Kh1 Be7 10. f5 O-O 11. fxe6 fxe6 12. Bc4 Nxd4 13. Qxd4 Kh8 14. Bg5 b5 15. Bb3 Bb7 16. Bxe6 b4 17. Qxb4 d5 18. Qb3 dxe4) 7... Qc7 8. Be3 Be7 9. g4 b5 10. g5 Nfd7 11. a3 Nc6 12. Nxc6 Qxc6 13. h4 Bb7 14. Qd4 O-O 15. O-O-O Nc5 16. Bf3 a5) 6... a6 7. Bd3 b5 8. O-O Bb7 9. Qe1 Nbd7 10. f3 Be7 11. a4 b4 12. Nce2</span><br></pre></td></tr></table></figure>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Scheveningen%20Variation,%20English%20Attack.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'>Scheveningen Variation, English Attack</font></b>
</center>
<p></font></p>
<blockquote>
<p>Scheveningen Variation, English Attack</p>
<p>With 6. Be3, white begins a standard English attack setup. White will
play f3, g4, Qd2 and O-O-O in some order, setting up a kingside pawn
storm targeted towards black's king. In response, black will play a6 and
b5 and set up a pawn attack on the queenside against white's king.</p>
<p>Note that the standard 6...a6 from black transposes into a hybrid
Najdorf/Scheveningen, and allows white to begin the Perenyi Attack with
7.g4 if desired.</p>
<p>.</p>
</blockquote>
<p>###视频教程</p>
<p><a
href="https://www.bilibili.com/video/BV1nk4y1r7QQ/?spm_id_from=333.788.recommend_more_video.-1&amp;vd_source=89cd1bd958a3eea212de763dc113559e">小小小悍马视频教学</a></p>
<h2 id="龙式变例1-b70-79">龙式变例（1） B70-79</h2>
<p>名字好帅 偏向于攻击的变例</p>
<blockquote>
<p>5...g6 introduces the famous "Dragon" variation of the Sicilian
defence. While the general themes are easy to understand, the Dragon is
a very sharp line with immense amounts of established theory. Against
players familiar with the theory, even one slip can be quickly
fatal.</p>
<p>With 5...g6 Black is preparing to fianchetto his dark-squared bishop.
On g7 this bishop will exert considerable pressure on the center and
facilitate a queenside attack. However, 5...g6 weakens Black's kingside
pawn structure and encourages White to pursue a kingside attack of his
own. In most lines, White will castle queenside and attack on the
kingside with his pawns, hoping to exploit Black's structural weakness.
Because both players are attacking on opposite wings, there is no time
to be lost for either side. Subtle maneuvering will tend to take a back
seat to sharp tactics in the Dragon.</p>
</blockquote>
<table rules="none" align="center">
<tr>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Sicilian%20Defence,%20Dragon%20Variation.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA"></font><br />

</center>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Sicilian%20Defence,%20Dragon%20Variation1.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA"></font><br />

</center>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Sicilian%20Defence,%20Dragon%20Variation3.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA"></font><br />

</center>
</td>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Sicilian%20Defence,%20Dragon%20Variation4.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA"></font><br />

</center>
</td>
</tr>
</table>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. e4 c5 2. Nf3 d6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 g6 6. Be3 Bg7 7. f3 O-O 8. Qd2 Nc6 9. Bc4 Na5 (9... Nxd4 10. Bxd4 Be6 11. Bb3 Qa5 12. O-O-O b5 13. Kb1 b4 14. Nd5 Bxd5 15. exd5 Qb5 16. Rhe1 a5 17. Qe2 Qxe2 18. Rxe2 a4 19. Bc4 Rfc8 20. b3 Kf8) 10. Bb3 Nxb3 11. axb3 a6 12. h4 d5 13. e5 Nh5 14. g4 Ng3 15. Rg1 Bxe5 16. O-O-O</span><br></pre></td></tr></table></figure>
<p>###视频教程</p>
<p><a
href="https://www.bilibili.com/video/BV18v411q7jZ/?spm_id_from=333.999.top_right_bar_window_custom_collection.content.click">小小小悍马视频教学</a></p>
<h2 id="龙式变例2之南斯拉夫进攻">龙式变例（2）之南斯拉夫进攻</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. e4 c5 2. Nf3 d6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 g6 6. Be3 Bg7 7. f3 O-O (7... Nc6 8. Qd2 Bd7 9. O-O-O Qa5 10. Kb1 Rc8 11. g4 h6 12. h4 a6 13. Be2 Ne5 14. g5 hxg5 15. hxg5 Rxh1 16. gxf6 Rxd1+ 17. Nxd1 Qxd2 18. fxg7) 8. Qd2 Nc6 9. O-O-O Qa5 10. Kb1 Bd7</span><br></pre></td></tr></table></figure>
<blockquote>
<ol start="7" type="1">
<li>f3 is known as the Yugoslav attack. The f3-pawn defends White's only
center pawn at e4, freeing up her c3-knight. It also sets up a possible
rook lift to the 2nd rank on the f-file following a kingside castling.
Though 7. f3 blocks the diagonal kingside mobility of White's queen, the
queen can occupy a powerful central seat with 8. Qd2, where she can
participate in either a queenside or kingside attack. For more on this,
see Boleslavsky-Lissitzin (Moscow, 1956).</li>
</ol>
</blockquote>
<table rules="none" align="center">
<tr>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Sicilian%20Defense,%20Dragon%20Variation,%20Yugoslav%20Attack.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA"></font><br />

</center>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Sicilian%20Defense,%20Dragon%20Variation,%20Yugoslav%20Attack2.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA"></font><br />

</center>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Sicilian%20Defense,%20Dragon%20Variation,%20Yugoslav%20Attack1.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA"></font><br />

</center>
</td>
</td>
</tr>
</table>
<p>选7. Nc6 可以在第15走 Ng8</p>
<p>###视频教程</p>
<p><a
href="https://www.bilibili.com/video/BV11a4y1E7vJ/?spm_id_from=333.337.search-card.all.click&amp;vd_source=89cd1bd958a3eea212de763dc113559e">小小小悍马视频教学</a></p>
<p>斯帕斯基Vs彼得罗相</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 c5 2. Nf3 d6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 a6 6. Bg5 Nbd7 7. Bc4 Qa5 8. Qd2 h6 9. Bxf6 Nxf6 10. O-O-O e6 11. Rhe1 Be7 12. f4 O-O 13. Bb3 Re8 14. Kb1 Bf8 15. g4 Nxg4 16. Qg2 Nf6 17. Rg1 Bd7 18. f5 Kh8 19. Rdf1 Qd8 20. fxe6 fxe6 21. e5 dxe5 22. Ne4 Nh5 23. Qg6 exd4 24. Ng5 hxg5 25. Qxh5+ Kg8 26. Qf7+ Kh8 27. Rf3 g4 28. Rxg4</span><br></pre></td></tr></table></figure>
<h2 id="意大利开局">意大利开局</h2>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Italian%20Game.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'>只有吃兵是比较正确的走法</font></b>
</center>
<p></font></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. e4 e5 2. Nf3 Nc6 3. Bc4 Nf6 4. d4 exd4 (4... Nxd4 5. Bxf7+ Kxf7 6. Nxe5+ Ke8 7. Qxd4) (4... Nxe4 5. dxe5 Bc5 6. Qd5) 5. O-O Nxe4 (5... Bc5 6. e5 d5 (6... Ng4 7. Bf4 O-O 8. h3 Nh6 9. Bxh6 gxh6) (6... Ne4 7. Re1 d5 8. exd6 Bf5 (8... f5 9. dxc7 Qxc7 10. Nbd2 Be7 11. Nxe4 fxe4 12. Rxe4 Bf5 13. Ng5 Bxe4 14. Bf7+ Kd7 15. Qg4+ Kd6 16. Nxe4+ Ke5 17. Qe6#) 9. dxc7 Qxc7 10. Nbd2) 7. exf6 dxc4 8. Re1+ Be6 9. Ng5 Qxf6 (9... gxf6 10. Nxe6 fxe6 11. Qh5+ Kf8 12. Qxc5+) (9... O-O 10. fxg7 Re8 (10... Kxg7 11. Rxe6 fxe6 12. Nxe6+) 11. Qh5 Bf5 12. Qxf7#) 10. Nxe6 fxe6 11. Qh5+ Kf8 12. Qxc5+) 6. Re1 d5 7. Bxd5 Qxd5 8. Nc3 Qh5 9. Nxe4 Be6 10. Bg5 h6 (10... f6 11. Nxf6+ gxf6 12. Rxe6+ Kd7 13. Rxc6 Kxc6 (13... bxc6 14. Ne5+ Kd6 15. Qxh5) 14. Nxd4+) 11. Bf6 Be7 (11... Qa5 12. Nxd4 gxf6 13. Nxf6+ Ke7 14. b4 Nxb4 15. Nxe6 Kxf6 16. Qd4+ Kg6 17. Qxh8 Nxc2 18. Nf4+ Kf5 19. Qh7+ Kxf4 20. Re4+ Kg5 21. Qxf7 Qe1+ 22. Raxe1 h5 23. h4+ Kh6 24. Re6#) 12. Bxe7 Nxe7 13. Nxd4 Qxd1 14. Raxd1 Bd7</span><br></pre></td></tr></table></figure>
<p>Ali_Chess<a
href="https://www.bilibili.com/video/BV1fo4y1a7Mw/?spm_id_from=333.999.0.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e">视频教学</a>
感觉这个up 白棋好强</p>
<h2 id="应对卡罗康">应对卡罗康</h2>
<p><a
href="https://www.bilibili.com/video/BV11D4y1G7n1/?spm_id_from=333.999.0.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e">应对卡罗康视频</a></p>
<table rules="none" align="center">
<tr>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Caro-Kann%20Defencekinights%20exchangee.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA">兑马变例谱在上面</font><br />

</center>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Caro-Kann%20Defence%20two%20knights.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA">双马攻击</font><br />

</center>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/tockf3.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA">3.f3</font><br />

</center>
</td>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Accelerated%20Panov%20Attack.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA">2.c4帕诺夫攻击 还有部分谱在上面</font><br />

</center>
</td>
</tr>
</table>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. e4 c6 2. Nf3 (2. d4 d5 3. Nc3 (3. f3 dxe4 4. fxe4 e5 5. Nf3 exd4 6. Bc4 Bb4+ 7. c3 dxc3 8. Bxf7+ Kxf7 9. Qxd8 cxb2+ 10. Ke2 bxa1=Q 11. Ng5+ Kg6 12. Qe8+ Kh6 13. Ne6+ Bd2 14. Bxd2+) 3... dxe4 4. Nxe4 Nf6 (4... Bf5 5. Ng3 Bg6 6. h4 h6 7. Nf3 e6 8. Ne5 Bh7 9. Bd3 Qxd4 10. Nxf7 Bxd3 11. Nxh8 Qe5+ 12. Ne2 Bf5 13. Qd8+ Kxd8 14. Nf7+ Ke7 15. Nxe5) (4... Nd7 5. Bc4 Ndf6 6. Ng5) 5. Ng3 h5 6. Bg5 h4 7. Bxf6 hxg3 8. Be5 Rxh2 9. Rxh2 Qa5+ 10. Qd2 (10. c3 Qxe5+ 11. dxe5 gxh2) 10... gxf2+ 11. Ke2 Qxd2+ 12. Kxd2 fxg1=Q) (2. c4 d5 3. cxd5 cxd5 4. exd5 Nf6 5. Nc3 Nbd7 6. Nf3 a6 7. d4 Nb6 8. Ne5 Nbxd5 9. Qa4+ Bd7 10. Nxd7 Nxd7 (10... Qxd7 11. Bb5 axb5 12. Qxa8+ Qd8 13. Qxb7) 11. Nxd5) 2... d5 3. Nc3 dxe4 4. Nxe4 Bf5 5. Ng3 Bg6 6. h4 h6 7. Ne5 Bh7 8. Qh5 g6 9. Bc4 e6 10. Qe2 Bg7 11. Nxf7 Kxf7 12. Qxe6+ Kf8 13. Qf7#</span><br></pre></td></tr></table></figure>
<ol start="6" type="1">
<li>Bg5是一步错招作为提示</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.e4 c6  2. d4 d5 3. Nc3 dxe4 4. Nxe4 Nf6 5. Ng3 h5 6. Bg5 h4 7. Bxf6 hxg3 8. Be5 Rxh2 9. Rxh2 Qa5+ 10. Qd2 (10. c3 Qxe5+ 11. dxe5 gxh2)</span><br></pre></td></tr></table></figure>
<h2 id="应对西西里">应对西西里</h2>
<p><a
href="https://www.bilibili.com/video/BV1Zg4y1p7QS/?spm_id_from=333.788&amp;vd_source=89cd1bd958a3eea212de763dc113559e">视频一</a></p>
<table rules="none" align="center">
<tr>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/e4dealwithSicilian.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA">2. Nf3 Nc6 3. Bb5</font><br />

</center>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/e4dealwithSiciliang6.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA">2. ...g6</font><br />

</center>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/e4dealwithSiciliane6.png" width="100%" /><br />
<br/><br />
<font color="AAAAAA">2. ...e6</font><br />

</center>
</td>
</td>
</tr>
</table>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. e4 c5 2. Nf3 Nc6 (2... g6 3. c3 b6 4. d4 Bb7 5. Bc4 Bxe4 6. Bxf7+ (6. Ng5 d5 7. Bb5+ Nd7 8. Nxe4 dxe4 9. dxc5 a6 10. Bxd7+ Qxd7 11. Qxd7+ Kxd7 12. cxb6) 6... Kxf7 7. Ng5+ Ke8 8. Nxe4) (2... e6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 Bb4 6. e5 Nd5 (6... Ne4 7. Qg4 Nxc3 8. Qxg7 Rf8 9. a3 Nb5+ 10. axb4 Nxd4 11. Bg5 f6 (11... Qb6 12. Bd3 Nf5 13. Bxf5 exf5 14. O-O-O Qg6 15. e6 Qxg7 (15... d6 16. Rxd6 f6 17. Rd8+ Kxd8 18. Qxf8+ Qe8 19. Bxf6+ Kc7 20. Be5+ Kd8 21. Rd1+ Bd7 22. Rxd7+ Nxd7 23. e7+ Kc8 24. Qxe8#) 16. exd7+ Bxd7 17. Rhe1+) 12. exf6 Nf5 13. f7+ Rxf7 14. Qxf7+ Kxf7 15. Bxd8) 7. Qg4 O-O (7... g6 8. a3 Bxc3+ (8... Qa5 9. axb4 Qxa1 10. Nb3) 9. bxc3 Qc7 10. Nb5 Qxe5+ 11. Qe2 Qxe2+ 12. Bxe2) 8. Bh6) 3. Bb5 Qb6 (3... e6 4. O-O Nf6 5. Re1 d5 6. exd5 Nxd5 7. Ne5 Qc7 8. Nc3 (8. Qh5)) (3... g6 4. O-O Bg7 5. Re1 Nf6 6. Nc3 Nd4 7. e5 Ng8 8. d3 Nxb5 9. Nxb5 a6 10. Nd6+ exd6 11. Bg5 Qa5 12. exd6+ Kf8 13. Re8+ Kxe8 14. Qe2+ Kf8 15. Be7+ Nxe7 (15... Ke8 16. Bd8+ Kxd8 17. Ng5) 16. Qxe7+ Kg8 17. Ng5) (3... Nf6 4. Nc3 Nd4 5. e5 Nxb5 6. Nxb5 Nd5 7. Ng5 h6 (7... a6 8. Qf3 f6 9. Qxd5 fxg5 10. Nc3) 8. Nxf7 Kxf7 9. Qf3+ Ke6 10. c4 Nb4 11. a3 Nc2+ 12. Kd1 Nxa1 13. g4) 4. Nc3 Nd4 5. Nxd4 cxd4 6. Nd5 Qd8 7. Qh5 a6 (7... Nf6 8. Nxf6+ gxf6 9. Bc4) 8. Qe5 axb5 (8... f6 9. Nc7+ Kf7 10. Qd5+ e6 11. Nxe6 Qe7 12. Nc7+ Kg6 13. Nxa8) 9. Nc7+ Qxc7 10. Qxc7</span><br></pre></td></tr></table></figure>
<p>复制棋谱点击<a
href="https://lichess.org/analysis">此处</a>到lichess上复盘</p>
<h2 id="伊文思弃兵-evans-gambit">伊文思弃兵 Evans Gambit</h2>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Evans_Gambit.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'>Evans Gambit</font></b>
</center>
<p></font></p>
<h3 id="接受弃兵">接受弃兵</h3>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 e5 2. Nf3 Nc6 3. Bc4 Bc5 4. b4 Bxb4 5. c3 Bc5 (5... Ba5 6. d4 d6) (5... Be7 6. d4 Na5 7. Bd3 d6 8. dxe5 dxe5 9. Nxe5 Nf6) 6. d4 exd4 7. O-O d6 (7... dxc3 8. Bxf7+ Kxf7 9. Qd5+) 8. cxd4 Bb6 9. Nc3</span><br></pre></td></tr></table></figure>
<p>d6兵很重要</p>
<h3 id="不接受弃兵">不接受弃兵</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. e4 e5 2. Nf3 Nc6 3. Bc4 Bc5 4. b4 Bb6 (4... Be7 5. c3 Nf6 6. Qb3 O-O) 5. a4 a6 6. Nc3 Nf6 7. Nd5 Nxd5 8. exd5 e4 9. dxc6 O-O (9... exf3 10. Qxf3 Qe7+ 11. Kd1) 10. Bb2 exf3 11. Qxf3</span><br></pre></td></tr></table></figure>
<h3 id="反弃兵">反弃兵</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. e4 e5 2. Nf3 Nc6 3. Bc4 Bc5 4. b4 d5 5. Bxd5 (5. exd5 Nxb4 6. O-O Nf6 7. Nxe5 Nbxd5 (7... Bd4 8. c3 Bxe5 9. Re1)) 5... Nxb4</span><br></pre></td></tr></table></figure>
<h3 id="视频">视频</h3>
<p>接受弃兵 <a
href="https://www.bilibili.com/video/BV15h411d7iN/?spm_id_from=333.788.recommend_more_video.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e">yixinchess</a></p>
<p>接受弃兵 反弃兵 <a
href="https://www.bilibili.com/video/BV1op4y1v7Pi/?spm_id_from=333.788.recommend_more_video.0&amp;vd_source=89cd1bd958a3eea212de763dc113559e">yixinchess</a></p>
<p>大象弃兵</p>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/Elephant_gambit.png" style="height: 300px; width: auto;"/>
</center>
<center>
<b><font size ='2'>elephant Gambit</font></b>
</center>
<p></font></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. e4 e5 2. Nf3 d5 3. exd5 e4 4. Qe2 (4. Nd4 Qxd5 5. Nb3 Qe5 6. Nc3 Nc6 7. Be2 Bd6 8. d3 exd3 9. Qxd3 Nb4 10. Qd1 Bf5 11. Nd4 Qxd4 12. Qxd4 Nxc2+ 13. Kf1 Nxd4) 4... Nf6 5. Nc3 Be7 6. Nxe4 O-O 7. d3 (7. c4 Nxe4 8. Qxe4 Re8 9. Qd3 Bf6+ 10. Be2 c6 11. O-O cxd5 12. cxd5 b6 13. d6 Ba6 14. Qd5 Bxe2 15. Qxa8 Bxf1 16. Kxf1 Qxd6 17. d4 Qd7 18. d5 Rc8 19. Bf4 Na6) (7. Nxf6+ Bxf6 8. d3 (8. d4 Qxd5 9. Be3 Bg4 10. h3 Bxf3 11. Qxf3 Qa5+ 12. Bd2 (12. c3 Nc6 13. Bd2 (13. Bd3 Bxd4 14. O-O Bxe3 15. Qxe3 Rfe8 16. Qg3 Rad8) 13... Rae8+ 14. Be2 Qb6 15. O-O-O Bxd4 16. cxd4 Nxd4 17. Qd3 Nxe2+ 18. Kb1) 12... Qb6) 8... Re8 9. Be3 Bxb2 10. Rb1 Bc3+ 11. Nd2 Qxd5 12. Rb3 Qa5 13. a3 Nc6 14. Qd1 Bg4 15. Be2 (15. f3 Rxe3+ 16. Kf2 Rae8 17. fxg4 Qf5+ 18. Qf3 Nd4 19. Qxf5 Nxf5) 15... Bxe2 16. Qxe2 Nd4) 7... Nxd5 8. Bd2 Re8 9. O-O-O f5 10. Nc3 (10. Ng3 Bf6 11. Be3 f4) 10... Nxc3 11. Bxc3 Bg5+ 12. Nxg5 Rxe2 13. Bxe2 Qxg5+</span><br></pre></td></tr></table></figure>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">1. e4 e5 2. Nf3 d5 3. Nxe5 Qe7 4. Nf3 (4. Ng4 Qxe4+ 5. Be2 Bxg4 6. f3 Bxf3 7. gxf3 Qh4+ 8. Kf1 Bc5) (4. d4 f6 5. Qh5+ (5. Ng4 Bxg4 6. Qxg4 Qxe4+ 7. Qxe4+ dxe4 8. Bc4 Nc6 9. c3 O-O-O 10. Bf4 Bd6 11. Bg3 Kb8) (5. Nf3 dxe4 6. Nfd2 f5 7. Bc4 Nc6 8. c3 Bd7 9. O-O O-O-O 10. Re1 Nf6 11. Nf1 (11. b4 Ng4 12. h3 h5 13. hxg4 (13. a4 Qh4 14. Qe2 Bd6 15. Nf1 f4 16. Qxe4 Qxf2+ 17. Kh1 f3 18. gxf3 Rde8) 13... hxg4 14. g3 g5)) (5. Nc3 fxe5 6. Nxd5 Qf7 7. Bc4 Be6 8. Nxc7+ Qxc7 9. Bxe6 Nc6 10. d5 (10. c3 exd4 11. cxd4 Qd6 12. Bxg8 (12. d5 Qb4+ 13. Bd2 Qxe4+ 14. Be3 Bb4+ 15. Kf1 Nf6 16. a3 Bd6 17. Qe2 Nd8 18. Qb5+ Ke7 19. Re1 Nxe6 20. dxe6 Rhe8) 12... Rxg8 13. Be3 Qb4+ 14. Qd2 O-O-O) 10... Nd4 11. O-O (11. c3 Nxe6 12. dxe6 Qd6 (12... Nf6))) 5... g6 6. Nxg6 Qxe4+ 7. Be2 Qxg6) 4... dxe4 5. Nd4 Qe5 6. Nb3 Nc6 7. Nc3 Nf6 8. Be2 Bd6 9. d4 exd3 10. Qxd3 Nb4 11. Qd1 Bf5 12. Nd4 Qxd4 13. Qxd4 Nxc2+ 14. Kf1 Nxd4</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. e4 e5 2. Nf3 d5 3. exd5 e4 4. Qe2 Nf6 5. d3 Qxd5 6. Nbd2 (6. Nc3 Bb4 7. Bd2 Bxc3 8. Bxc3 O-O 9. Bxf6 (9. dxe4 Nxe4 10. Rd1 Nxc3 11. Rxd5 Nxe2 12. Bxe2 Be6 13. Rd2 Nc6) 9... exf3 10. Qxf3 Qxf3 11. gxf3 Re8+ 12. Kd2 gxf6) (6. dxe4 Qxe4 7. Qxe4+ Nxe4) 6... Nc6 7. Nxe4 (7. dxe4 Qe6 8. Qc4 Qg4 9. h3 Qg6 10. e5 Be6 11. Qb5 O-O-O 12. exf6 Qxc2 13. fxg7 Bxg7 14. Be2 Rd5 15. Qc4 Rxd2 16. Qxc2 Rxc2 17. Bd1 Rxb2 18. Bxb2 Bxb2 19. Rb1 Bc3+ 20. Kf1 Bxa2) 7... Be6 8. Nxf6+ gxf6 9. Qe4 Qa5+ 10. Bd2 Qb6 11. O-O-O (11. Bc3 Bb4 12. Bxb4 (12. Be2 Bxc3+ 13. bxc3 Qa5 14. O-O Qxc3) 12... Nxb4 13. Qe2 O-O-O 14. O-O-O Nxa2+ 15. Kb1 Nc3+) 11... Qa6 12. a3 Bxa3 13. Bc3 Be7 14. Be2 O-O-O 15. d4 Qa4 16. Rhe1 f5 17. Qe3 Nb4 18. Bxb4 Qa1+ 19. Kd2 Bxb4+ 20. c3 Qxb2+ 21. Kd3 Qxc3#</span><br></pre></td></tr></table></figure>
<h2 id="国际象棋开局代码简介">国际象棋开局代码简介</h2>
<p>现在世界通行的国际象棋开局代码广泛运用在各种电脑软件，最早是南斯拉夫人发明的，《国际象棋开局百科全书》即按此编排，把所有开局分为A、B、C、D、E五类，每一类又分为00-99一百个小类，例如C89是西班牙开局马歇尔弃兵。<br />
下面详细介绍各个开局的分类代码：<br />
A类：<br />
A00-A03是各种非主流开局，包括了一切第一步不走1.e4、1.d4、1.c4、1.Nf3的开局。例如1.f4别尔德开局，被列入在A02-A03<br />
A04-A09是列蒂开局,1.Nf3。<br />
A10-A39是英国式开局，其中A20-A29是先手西西里,1.c4
e5；A30-A39是对称变例1.c4 c5。<br />
A40-A56包括了一些不常见的后兵类开局。<br />
A57-A59是伏尔加弃兵。1.d4 Nf6 2.c4 c5 3.d5 b5<br />
A60-A79是别诺尼防御。1.d4 Nf6 2.c4 c5 3.d5 e6<br />
A80-A89是荷兰防御。1.d4 f5<br />
B类：主要是各种半开放性开局。<br />
B01是斯堪的纳维亚防御，1.e4 d5<br />
B02-B05是阿廖欣防御，1.e4 Nf6<br />
B06通常叫现代防御，1.e4 g6<br />
B07-B09是乌菲姆采夫防御，1.e4 d6<br />
B10-B19是卡罗卡恩防御，1.e4 c6<br />
B20-B99是西西里防御，1.e4 c5。<br />
主要的变例介绍如下：<br />
B33拉斯克变例<br />
B37-B39马洛兹结构<br />
B40-B49保尔逊体系<br />
B58-B59博列斯拉夫斯基变例<br />
B60-B69拉乌吉尔变例<br />
B70-B79龙式变例<br />
B80-B85舍文宁根变例<br />
B86-B89索金攻击<br />
B90-B99纳道尔夫变例<br />
C类：包括了法兰西防御和全部开放性开局<br />
C00-C19法兰西防御，1.e4 e6<br />
C21-C22中心开局，1.e4 e5 2.d4<br />
C23-C24飞象开局，1.e4 e5 2.Bc4<br />
C25-C29维也纳开局，1.e4 e5 2.Nc3<br />
C30-C39王翼弃兵，1.e4 e5 2.f4<br />
C41菲立道尔防御，1.e4 e5 2.Nf3 d6<br />
C42-C43俄罗斯防御1.e4 e5 2.Nf3 Nf6<br />
C44-C45包括苏格兰开局1.e4 e5 2.Nf3 Nc6 3.d4<br />
C46三马开局1.e4 e5 2.Nf3 Nc6 3.Nc3<br />
C47-C49四马开局1.e4 e5 2.Nf3 Nc6 3.Nc3 Nf6<br />
C50包括匈牙利防御1.e4 e5 2.Nf3 Nc63.Bc4 Be7<br />
C51-C52伊文思弃兵1.e4 e5 2.Nf3 Nc6 3.Bc4 Bc5 4.b4<br />
C53-C54意大利开局1.e4 e5 2.Nf3 Nc6 3.Bc4 Bc5 4.c3<br />
C55-C59双马防御1.e4 e5 2.Nf3 Nc6 3.Bc4 Nf6<br />
C60-C99西班牙开局1.e4 e5 2.Nf3 Nc6 3.Bb5<br />
主要变例介绍如下：<br />
C65-C67柏林防御<br />
C68-C69兑换变例<br />
C71-C76现代斯坦尼茨防御<br />
C80-C83开放变例<br />
C88包括吉普斯里斯变例<br />
C89马歇尔弃兵<br />
C92包括扎依采夫变例<br />
C93斯梅斯洛夫变例<br />
C94-C95布雷耶尔变例<br />
C96-C99奇戈林变例<br />
D类：<br />
D00-D05后兵开局，1.d4 d5<br />
D06-D69后翼弃兵，1.d4 d5 2.c4<br />
主要变例介绍如下：<br />
D10-D19斯拉夫防御<br />
D20-D29接受后翼弃兵<br />
D38-D39拉戈金防御<br />
D43-D49半斯拉夫防御<br />
D52剑桥温泉防御<br />
D60-D69正统防御<br />
D70-D99格林菲尔德防御，1.d4 Nf6 2.c4 g6 黑棋第三着有3...d5<br />
E类：<br />
E00-E09卡塔龙开局<br />
E12-E19新印度防御<br />
E20-E59尼姆佐维奇防御<br />
E60-E99古印度防御<br />
主要变例介绍如下：<br />
E62-E69出侧翼象变例<br />
E76-E79四兵变例<br />
E80-E89吉米什变例<br />
E90-E99古典变例</p>
<p><a href="http://blog.sina.com.cn/u/1085848081">原文地址</a></p>
]]></content>
      <tags>
        <tag>国际象棋</tag>
      </tags>
  </entry>
  <entry>
    <title>dogvscat 一个关于协变量偏移（covariate shift）的例子</title>
    <url>/post/ea62bbc2.html</url>
    <content><![CDATA[<table rules="none" align="center">
<tr>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/cat.18.jpg" width="100%" /><br />
<br/><br />
<font color="AAAAAA">猫没卡通化你的训练集</font><br />

</center>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/cat.10.jpg" width="100%" /><br />
<br/><br />
<font color="AAAAAA">猫卡通化过你的测试集</font><br />

</center>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/dog.9835.jpg" width="100%" /><br />
<br/><br />
<font color="AAAAAA">狗没卡通化过你的训练集</font><br />

</center>
</td>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/dog.11712.jpg" width="100%" /><br />
<br/><br />
<font color="AAAAAA">狗卡通化过你的测试集</font><br />

</center>
</td>
</tr>
</table>
<p>为了体验一下协变量偏移（covariate
shift）的例子我自己构建了一个猫狗分类的数据集，数据来自<a
href="https://www.kaggle.com/competitions/dogs-vs-cats/data?select=train.zip">kaggla
dogvscat</a>的训练集，我把它重新分成了训练集和测试集两部分然后对测试集部分进行卡通化处理（<a
href="https://github.com/bryandlee/animegan2-pytorch">卡通化代码地址</a>）构成了一个协变量偏移的例子，试着实现协变量偏移纠正，不过可惜的事效果并不好。</p>
<span id="more"></span>
<h1 id="理论部分">理论部分</h1>
<h2 id="分布偏移的类型">分布偏移的类型</h2>
<p>训练数据分布<span class="math inline">\(p_S(x,y)\)</span>
测试数据分布<span class="math inline">\(p_T(x,y)\)</span>
一个清醒的现实是：如果没有任何关于<span
class="math inline">\(p_S\)</span>和<span
class="math inline">\(p_T\)</span>之间相互关系的假设，
学习到一个分类器是不可能的</p>
<p>如果<span
class="math inline">\(p_S(x)=p_T(x)\)</span>但是标签全部翻转 <span
class="math inline">\(p_S(y|x)=1-p_T(y|x)\)</span>如果我们此时简单的使用<span
class="math inline">\(p_S(x)\)</span>那很难得到好的结果</p>
<p>所以我们可以对数据发生的变化进行一些限制的假设，并以此设计可以检测偏移变化的算法，然后动态调整数据。</p>
<ol type="1">
<li><p>情况一协变量偏移（covariate shift）</p>
<p><span class="math inline">\(p(x)\)</span>改变 <span
class="math inline">\(p(y|x)\)</span>没有改变</p></li>
<li><p>情况二<em>标签偏移</em>（label shift）<br />
<span class="math inline">\(p(y)\)</span>改变 <span
class="math inline">\(p(x|y)\)</span>没有改变</p></li>
<li><p>情况三 概念偏移（concept shift）<br />
标签的定义发生变化</p></li>
</ol>
<p>为了更好的认识这一问题我们要了解经验风险和真实风险的概念</p>
<p><em>经验风险</em>（empirical risk)</p>
<p><span class="math display">\[
\underset{f}{\operatorname{minimize}} \frac{1}{n} \sum_{i=1}^n
l\left(f\left(\mathbf{x}_i\right), y_i\right)
\]</span><br />
真实风险（true risk）<br />
<span class="math display">\[
E_{p(\mathbf{x}, y)}[l(f(\mathbf{x}), y)]=\iint l(f(\mathbf{x}), y)
p(\mathbf{x}, y) d \mathbf{x} d y
\]</span></p>
<h2 id="协变量偏移纠正">协变量偏移纠正</h2>
<p><span class="math inline">\(q(x)\)</span>源分布 <span
class="math inline">\(p(x)\)</span>目标分布 假设：<span
class="math inline">\(p(y|x)=q(y|x)\)</span><br />
<span class="math display">\[
\iint l(f(\mathbf{x}), y) p(y \mid \mathbf{x}) p(\mathbf{x}) d
\mathbf{x} d y=\iint l(f(\mathbf{x}), y) q(y \mid \mathbf{x})
q(\mathbf{x}) \frac{p(\mathbf{x})}{q(\mathbf{x})} d \mathbf{x} d y
\]</span></p>
<p>我们需要根据数据来自正确分布与来自错误分布的概率之比，
来重新衡量每个数据样本的权重<br />
<span class="math display">\[
\beta_i \stackrel{\text { def }}{=}
\frac{p\left(\mathbf{x}_i\right)}{q\left(\mathbf{x}_i\right)}
\]</span></p>
<p>将权重 <span class="math inline">\(\beta_i\)</span>
代入到每个数据样本 <span class="math inline">\(\left(\mathbf{x}_i,
y_i\right)\)</span> 中,
我们可以使用”加权经验风险最小化“来训练模型:<br />
<span class="math display">\[
\underset{f}{\operatorname{minimize}} \frac{1}{n} \sum_{i=1}^n \beta_i
l\left(f\left(\mathbf{x}_i\right), y_i\right) .
\]</span><br />
<span class="math inline">\(\beta_i\)</span>
可以用一个二分类网络生成</p>
<h1 id="代码实现">代码实现</h1>
<h3 id="数据处理">数据处理</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># kaggle原始数据集地址</span></span><br><span class="line">original_dataset_dir = <span class="string">&#x27;....train&#x27;</span></span><br><span class="line">total_num = <span class="built_in">int</span>(<span class="built_in">len</span>(os.listdir(original_dataset_dir))/<span class="number">2</span>)   <span class="comment"># total_num=12500</span></span><br><span class="line"><span class="comment"># os.listdir() 可以查看当前目录下的文件和目录个数</span></span><br><span class="line">random_idx = np.array(<span class="built_in">range</span>(total_num))</span><br><span class="line">np.random.shuffle(random_idx)   <span class="comment"># np.random.shuffle()  对第一维的随机打乱</span></span><br><span class="line">base_dir = <span class="string">&#x27;...dogvscat&#x27;</span>   <span class="comment"># 待处理的数据集地址</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(base_dir):</span><br><span class="line">    os.mkdir(base_dir)               <span class="comment"># 创建目录</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 训练集、测试集的划分</span></span><br><span class="line">sub_dirs = [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;test&#x27;</span>]</span><br><span class="line">animals = [<span class="string">&#x27;cats&#x27;</span>, <span class="string">&#x27;dogs&#x27;</span>]</span><br><span class="line">train_idx = random_idx[:<span class="built_in">int</span>(total_num * <span class="number">0.8</span>):]    <span class="comment"># train_idx=10000</span></span><br><span class="line">test_idx = random_idx[<span class="built_in">int</span>(total_num * <span class="number">0.8</span>)::]  <span class="comment"># test_idx=2500</span></span><br><span class="line">numbers = [train_idx, test_idx]</span><br><span class="line"><span class="keyword">for</span> idx, sub_dir <span class="keyword">in</span> <span class="built_in">enumerate</span>(sub_dirs):</span><br><span class="line">    <span class="built_in">dir</span> = os.path.join(base_dir, sub_dir)   <span class="comment"># os.path.join()函数连接两个或更多的路径名组件</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="built_in">dir</span>):</span><br><span class="line">        os.mkdir(<span class="built_in">dir</span>)</span><br><span class="line">    <span class="keyword">for</span> animal <span class="keyword">in</span> animals:</span><br><span class="line">        animal_dir = os.path.join(<span class="built_in">dir</span>, animal)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(animal_dir):</span><br><span class="line">            os.mkdir(animal_dir)</span><br><span class="line">        fnames = [animal[:-<span class="number">1</span>] + <span class="string">&#x27;.&#123;&#125;.jpg&#x27;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> numbers[idx]]</span><br><span class="line">        <span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">            src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">            dst = os.path.join(animal_dir, fname)</span><br><span class="line">            shutil.copyfile(src, dst)   <span class="comment"># src复制到dst中去</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 验证训练集、验证集、测试集的划分的照片数目</span></span><br><span class="line">        <span class="built_in">print</span>(animal_dir + <span class="string">&#x27; total images : %d&#x27;</span> % (<span class="built_in">len</span>(os.listdir(animal_dir))))</span><br></pre></td></tr></table></figure>
<h4
id="复制test文件夹重命名为testcartoon-进入文件夹下用如下的代码卡通化测试文件夹">复制test文件夹重命名为testcartoon
进入文件夹下用如下的代码卡通化测试文件夹</h4>
<p><code>python test.py --input_dir ./samples/inputs1 --output dir ./samples/result1/ --device cpu</code></p>
<h4 id="创建协变量偏移检测器训练集">创建协变量偏移检测器训练集</h4>
<p>在dogvscat文件夹下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> train2</span><br><span class="line"><span class="built_in">cd</span> train2</span><br><span class="line"><span class="built_in">mkdir</span> cartoon</span><br><span class="line"><span class="built_in">cp</span> ../../testcartoon/cats/*  .</span><br><span class="line"><span class="built_in">cp</span>  ../../testcartoon/dogs/* .</span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"><span class="built_in">mkdir</span> normal</span><br><span class="line"><span class="built_in">cd</span> normal</span><br><span class="line"><span class="built_in">cp</span> ../../train/cats/*  .</span><br><span class="line"><span class="built_in">cp</span> ../../train/dogs/*  .</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># 处理过的数据文件</span></span><br><span class="line">original_dataset_dir = <span class="string">&#x27;.....train2&#x27;</span><span class="comment">#你的文件位置</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> [<span class="string">&#x27;cartoon&#x27;</span>,<span class="string">&#x27;normal&#x27;</span>]:</span><br><span class="line">    original_dataset_dir2 = os.path.join(original_dataset_dir,j)</span><br><span class="line">    ll=os.listdir(original_dataset_dir2)</span><br><span class="line">    </span><br><span class="line">    total_num = <span class="built_in">int</span>(<span class="built_in">len</span>(ll))</span><br><span class="line">    random_idx = np.array(<span class="built_in">range</span>(total_num))</span><br><span class="line">    np.random.shuffle(random_idx)   <span class="comment"># np.random.shuffle()  对第一维的随机打乱</span></span><br><span class="line">    base_dir = <span class="string">&#x27;...cartoonvsnormal&#x27;</span>   <span class="comment"># 待处理的数据集地址</span></span><br><span class="line">    <span class="comment">#base_dir=os.path.join(base_dir,j)</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(base_dir):</span><br><span class="line">           os.mkdir(base_dir)               <span class="comment"># 创建目录</span></span><br><span class="line">    train_idx = random_idx[:<span class="built_in">int</span>(total_num * <span class="number">0.8</span>):]    <span class="comment"># train_idx=10000</span></span><br><span class="line">    test_idx = random_idx[<span class="built_in">int</span>(total_num * <span class="number">0.8</span>)::]</span><br><span class="line">    <span class="built_in">print</span>(j,<span class="string">&#x27;train:&#x27;</span>,<span class="built_in">len</span>(train_idx),<span class="string">&#x27;test&#x27;</span>,<span class="built_in">len</span>(test_idx))</span><br><span class="line">    dir1=os.path.join(base_dir, <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dir1):</span><br><span class="line">          os.mkdir(dir1) </span><br><span class="line">    dir1=os.path.join(dir1, j)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dir1):</span><br><span class="line">          os.mkdir(dir1)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> train_idx:</span><br><span class="line">        src = os.path.join(original_dataset_dir2, ll[i])</span><br><span class="line">        dst = os.path.join(dir1, ll[i])</span><br><span class="line">        shutil.copyfile(src, dst)</span><br><span class="line">    <span class="built_in">print</span>(j,<span class="string">&#x27;train&#x27;</span>,<span class="built_in">len</span>(os.listdir(dir1)))</span><br><span class="line">    dir1=os.path.join(base_dir, <span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dir1):</span><br><span class="line">          os.mkdir(dir1) </span><br><span class="line">    dir1=os.path.join(dir1, j)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dir1):</span><br><span class="line">          os.mkdir(dir1)      </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> test_idx:</span><br><span class="line">        src = os.path.join(original_dataset_dir2, ll[i])</span><br><span class="line">        dst = os.path.join(dir1, ll[i])</span><br><span class="line">        shutil.copyfile(src, dst)</span><br><span class="line">    <span class="built_in">print</span>(j,<span class="string">&#x27;test&#x27;</span>,<span class="built_in">len</span>(os.listdir(dir1)))</span><br></pre></td></tr></table></figure>
<p>然后你可以删除train2</p>
<p>以下是大概的文件结构</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">│─cartoonvsnormal</span><br><span class="line">│ ├───train</span><br><span class="line">│ │	 │─cats</span><br><span class="line">│ │   └─dogs</span><br><span class="line">│ ├───test</span><br><span class="line">│     ├─cats</span><br><span class="line">│     └─dogs</span><br><span class="line">|</span><br><span class="line">|</span><br><span class="line">|───dogvscat</span><br><span class="line">│   ├───train</span><br><span class="line">│   │	│─cartoon</span><br><span class="line">│   │  	└─normal</span><br><span class="line">│   ├───test</span><br><span class="line">│   │  ├─cartoon</span><br><span class="line">│   │  └─normal</span><br><span class="line">│   ├───testcartoon</span><br><span class="line">│      ├─cartoon</span><br><span class="line">│      └─normal</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="展示部分图片">展示部分图片</h2>
<table rules="none" align="center">
<tr>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/cat.18.jpg" width="100%" /><br />
<br/><br />
<font color="AAAAAA">猫没卡通化你的训练集</font><br />

</center>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/cat.10.jpg" width="100%" /><br />
<br/><br />
<font color="AAAAAA">猫卡通化过你的测试集</font><br />

</center>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/dog.9835.jpg" width="100%" /><br />
<br/><br />
<font color="AAAAAA">狗没卡通化过你的训练集</font><br />

</center>
</td>
</td>
<td>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/dog.11712.jpg" width="100%" /><br />
<br/><br />
<font color="AAAAAA">狗卡通化过你的测试集</font><br />

</center>
</td>
</tr>
</table>
<p>别问为什么没有对齐就是要逼死强迫症
不过值得一提这些图片是我挑选过的卡通化有些图效果不是很好
你可以尝试修改代码让它效果更好 加油</p>
<h3 id="协变量偏移检测器实现">协变量偏移检测器实现</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets,models,transforms</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.utils.data</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l<span class="comment">#李沐动手学习深度学习的课的库 没有可以注释掉</span></span><br><span class="line"><span class="keyword">import</span> gc </span><br><span class="line">gc.collect()<span class="comment">#清理内存</span></span><br><span class="line"><span class="comment">#加载函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getmean_str</span>(<span class="params">data_dir,name</span>):</span><br><span class="line">    data_trainsforms = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">224</span>,<span class="number">224</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    ])</span><br><span class="line">    image_datasets = datasets.ImageFolder(root=data_dir,</span><br><span class="line">                          transform=data_trainsforms)</span><br><span class="line">    data_loader = torch.utils.data.DataLoader(</span><br><span class="line">        image_datasets, batch_size=<span class="number">1</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    mean = torch.zeros(<span class="number">3</span>)</span><br><span class="line">    std = torch.zeros(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">for</span> X, _ <span class="keyword">in</span> data_loader:</span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">            mean[d] += X[:, d, :, :].mean()</span><br><span class="line">            std[d] += X[:, d, :, :].std()</span><br><span class="line">    mean.div_(<span class="built_in">len</span>(image_datasets))</span><br><span class="line">    std.div_(<span class="built_in">len</span>(image_datasets))</span><br><span class="line">    <span class="built_in">print</span>(name ,<span class="string">&quot; mean:&quot;</span>,mean,<span class="string">&quot;std:&quot;</span>,std)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(mean.numpy()), <span class="built_in">list</span>(std.numpy())</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data_cartoonvsnormal</span>(<span class="params">data_dir,meanlist, stdlist,batch_size=<span class="number">32</span></span>): </span><br><span class="line">    data_trainsforms = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">224</span>,<span class="number">224</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(meanlist, stdlist),</span><br><span class="line">    ])</span><br><span class="line">    <span class="comment">#拼接路径</span></span><br><span class="line">    image_datasets = datasets.ImageFolder(root=data_dir,</span><br><span class="line">                          transform=data_trainsforms)</span><br><span class="line">    <span class="comment">#数据加载器</span></span><br><span class="line">    data_iter=torch.utils.data.DataLoader(image_datasets, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> (data_iter,image_datasets)<span class="comment">#(train_iter,test_iter,image_train_datasets,image_test_datasets)</span></span><br><span class="line"><span class="comment">#训练函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_epoch_ch4_9</span>(<span class="params">net, train_iter, loss, updater, Use_gpu,detector=<span class="literal">None</span></span>): </span><br><span class="line">    train_acc=<span class="number">0.0</span></span><br><span class="line">    train_loss=<span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> batch,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_iter,<span class="number">1</span>):</span><br><span class="line">            X,y = data</span><br><span class="line">            <span class="keyword">if</span> Use_gpu:</span><br><span class="line">                X,y = Variable(X.cuda()),Variable(y.cuda())</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                X,y = Variable(X),Variable(y)</span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            <span class="keyword">if</span> detector!=<span class="literal">None</span>:</span><br><span class="line">                </span><br><span class="line">                beta= detector(X.detach())</span><br><span class="line">                <span class="keyword">if</span> Use_gpu:</span><br><span class="line">                    beta=Variable(beta.cuda())</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            l = loss(y_hat,y) <span class="keyword">if</span> detector==<span class="literal">None</span> <span class="keyword">else</span> loss(y_hat,y,beta)</span><br><span class="line">            l.backward()<span class="comment">#反向传播</span></span><br><span class="line">            optimizer.step()<span class="comment">#优化</span></span><br><span class="line">            _,pred =torch.<span class="built_in">max</span>(y_hat,<span class="number">1</span>)</span><br><span class="line">            train_acc += torch.<span class="built_in">sum</span>(pred == y)</span><br><span class="line">            train_loss += l.item()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> batch%<span class="number">200</span> == <span class="number">0</span> :</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Batch:&#123;&#125;,Train Loss:&#123;:.4f&#125;,Train ACC:&#123;:.4f&#125;%&quot;</span>.<span class="built_in">format</span>(batch,train_loss/batch,<span class="number">100</span>*train_acc/(y.numel()*batch)))</span><br><span class="line">    <span class="keyword">return</span> (train_loss/(<span class="built_in">len</span>(train_iter))),(train_acc/((batch_size)*<span class="built_in">len</span>(train_iter))).cpu().numpy()</span><br><span class="line"><span class="comment">#评价函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_accuracy_ch4_9</span>(<span class="params">net, data_iter, Use_gpu</span>): </span><br><span class="line">    <span class="keyword">if</span> Use_gpu:</span><br><span class="line">        net = net.cuda()</span><br><span class="line">    net.<span class="built_in">eval</span>()  <span class="comment"># 将模型设置为评估模式</span></span><br><span class="line">    <span class="comment">#metric = d2l.Accumulator(2)  # 正确预测数、预测总数</span></span><br><span class="line">    test_acc=<span class="number">0.0</span></span><br><span class="line">    number=<span class="number">0.0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_iter:</span><br><span class="line">            X,y=data</span><br><span class="line">            <span class="keyword">if</span> Use_gpu:<span class="comment">#有gpu在gpu下评估</span></span><br><span class="line">                X,y = Variable(X.cuda()),Variable(y.cuda())</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                X,y = Variable(X),Variable(y)</span><br><span class="line">            y_pred = net(X)<span class="comment">#metric.add(d2l.accuracy(net(X), y), y.numel())</span></span><br><span class="line">            _,pred =torch.<span class="built_in">max</span>(y_pred,<span class="number">1</span>)</span><br><span class="line">            test_acc += torch.<span class="built_in">sum</span>(pred == y)</span><br><span class="line">            number+=y.numel()</span><br><span class="line">        test_acc=((test_acc / number).cpu().numpy())    </span><br><span class="line">    <span class="keyword">return</span> test_acc</span><br><span class="line"><span class="comment">#训练函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_ch4_9</span>(<span class="params">net, train_iter, test_iter, loss, num_epochs, updater,Use_gpu,test_iter2=<span class="literal">None</span>,savename=<span class="string">&#x27;../data/ch04-4-9-2and4-9-3/covariate_shift_detectormodel.pth&#x27;</span>,detector=<span class="literal">None</span></span>): </span><br><span class="line">    <span class="keyword">if</span> test_iter2==<span class="literal">None</span>:</span><br><span class="line">        animator = d2l.Animator(xlabel=<span class="string">&#x27;epoch&#x27;</span>,ylabel=<span class="string">&#x27;Y&#x27;</span>, xlim=[<span class="number">1</span>, num_epochs],</span><br><span class="line">                        legend=[<span class="string">&#x27;train loss&#x27;</span>, <span class="string">&#x27;train acc&#x27;</span>, <span class="string">&#x27;test acc&#x27;</span>])<span class="comment">#李沐动手学习深度学习的课的库 没有可以注释掉</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        animator = d2l.Animator(xlabel=<span class="string">&#x27;epoch&#x27;</span>,ylabel=<span class="string">&#x27;Y&#x27;</span>, xlim=[<span class="number">1</span>, num_epochs],</span><br><span class="line">                        legend=[<span class="string">&#x27;train loss&#x27;</span>, <span class="string">&#x27;train acc&#x27;</span>, <span class="string">&#x27;test cartoon acc&#x27;</span>,<span class="string">&#x27;test normal acc &#x27;</span>])<span class="comment">#李沐动手学习深度学习的课的库 没有可以注释掉</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        train_metrics = train_epoch_ch4_9(net, train_iter, loss, updater,Use_gpu,detector)</span><br><span class="line">        test_acc = evaluate_accuracy_ch4_9(net, test_iter,Use_gpu)</span><br><span class="line">        <span class="keyword">if</span> test_iter2!=<span class="literal">None</span>:</span><br><span class="line">            test_acc2 = evaluate_accuracy_ch4_9(net, test_iter2,Use_gpu)</span><br><span class="line">            animator.add(epoch + <span class="number">1</span>, train_metrics + (test_acc,test_acc2,))<span class="comment">#李沐动手学习深度学习的课的库 没有可以注释掉</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;epoch&#123;&#125; Loss:&#123;:.4f&#125; Train Acc:&#123;:.4f&#125;% Test Cartoon Acc:&#123;:.4f&#125;% Test Normal Acc:&#123;:.4f&#125;%&quot;</span>.<span class="built_in">format</span>(epoch+<span class="number">1</span>, train_metrics[<span class="number">0</span>], <span class="number">100</span>*train_metrics[<span class="number">1</span>],<span class="number">100</span>*test_acc,<span class="number">100</span>*test_acc2))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            animator.add(epoch + <span class="number">1</span>, train_metrics + (test_acc,))<span class="comment">#李沐动手学习深度学习的课的库 没有可以注释掉</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;epoch&#123;&#125; Loss:&#123;:.4f&#125; Train Acc:&#123;:.4f&#125;% Test  Acc:&#123;:.4f&#125;%&quot;</span>.<span class="built_in">format</span>(epoch+<span class="number">1</span>, train_metrics[<span class="number">0</span>], <span class="number">100</span>*train_metrics[<span class="number">1</span>],<span class="number">100</span>*test_acc))</span><br><span class="line">    </span><br><span class="line">    train_loss, train_acc = train_metrics</span><br><span class="line">   </span><br><span class="line">    torch.save(net.state_dict(),savename)</span><br><span class="line">    </span><br><span class="line">    torch.cuda.empty_cache()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;save&quot;</span>,savename,<span class="string">&quot;over&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">assert</span> train_loss &lt; <span class="number">0.5</span>, train_loss</span><br><span class="line">    <span class="keyword">assert</span> train_acc &lt;= <span class="number">1</span> <span class="keyword">and</span> train_acc &gt; <span class="number">0.7</span>, train_acc</span><br><span class="line">    <span class="keyword">assert</span> test_acc &lt;= <span class="number">1</span> <span class="keyword">and</span> test_acc &gt; <span class="number">0.7</span>, test_acc</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#数据加载</span></span><br><span class="line"></span><br><span class="line">batch_size=<span class="number">32</span></span><br><span class="line">data_dir = <span class="string">&quot;../data/ch04-4-9-2and4-9-3/cartoonvsnormal&quot;</span></span><br><span class="line">mean_train_list,std_train_list=getmean_str(os.path.join(data_dir, <span class="string">&#x27;train&#x27;</span>),<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">mean_test_list,std_test_list=getmean_str(os.path.join(data_dir, <span class="string">&#x27;test&#x27;</span>),<span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">cartoon_num=<span class="number">1.0</span>*(<span class="built_in">len</span>(os.listdir(os.path.join(data_dir, <span class="string">&#x27;train&#x27;</span>,<span class="string">&#x27;cartoon&#x27;</span>)))+<span class="built_in">len</span>(os.listdir(os.path.join(data_dir, <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;cartoon&#x27;</span>))))</span><br><span class="line">normal_num=<span class="number">1.0</span>*(<span class="built_in">len</span>(os.listdir(os.path.join(data_dir, <span class="string">&#x27;train&#x27;</span>,<span class="string">&#x27;normal&#x27;</span>)))+<span class="built_in">len</span>(os.listdir(os.path.join(data_dir, <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;normal&#x27;</span>))))</span><br><span class="line">train_iter,image_train_datasets=load_data_cartoonvsnormal(os.path.join(data_dir, <span class="string">&#x27;train&#x27;</span>),mean_train_list,std_train_list,batch_size)</span><br><span class="line">test_iter,image_test_datasets=load_data_cartoonvsnormal(os.path.join(data_dir, <span class="string">&#x27;test&#x27;</span>),mean_test_list,std_test_list,batch_size)</span><br><span class="line">index_classes = <span class="built_in">list</span>(image_test_datasets.class_to_idx.keys())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;类别一 &#123;&#125;，数量&#123;&#125;，类别二 &#123;&#125; 数量&#123;&#125;&quot;</span>.<span class="built_in">format</span>(index_classes[<span class="number">0</span>],cartoon_num,index_classes[<span class="number">1</span>],normal_num))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;类别一 &#123;&#125;，数量&#123;&#125;，类别二 &#123;&#125; 数量&#123;&#125;&quot;</span>.<span class="built_in">format</span>(index_classes[<span class="number">0</span>],cartoon_num,index_classes[<span class="number">1</span>],normal_num))</span><br><span class="line"><span class="comment">#加载模型</span></span><br><span class="line">model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)</span><br><span class="line">Use_gpu = torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> parma <span class="keyword">in</span> model.parameters():</span><br><span class="line">    parma.requires_grad = <span class="literal">False</span><span class="comment">#屏蔽预训练模型的权重，只训练最后一层的全连接的权重</span></span><br><span class="line">model.fc = torch.nn.Linear(<span class="number">2048</span>,<span class="number">2</span>)</span><br><span class="line">nn.init.xavier_uniform_(model.fc.weight)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> Use_gpu:</span><br><span class="line">    model = model.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失函数和优化器</span></span><br><span class="line">weight=torch.tensor([normal_num,cartoon_num])</span><br><span class="line">weight=weight.cuda() <span class="keyword">if</span> Use_gpu <span class="keyword">else</span> weight</span><br><span class="line">loss_f = torch.nn.CrossEntropyLoss(weight=weight)<span class="comment">#不同类别数据量不同 添加权重来平衡</span></span><br><span class="line">optimizer = torch.optim.SGD(model.fc.parameters(),lr = <span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">15</span></span><br><span class="line">train_ch4_9(model, train_iter, test_iter, loss_f, num_epochs,optimizer,Use_gpu)</span><br><span class="line"><span class="comment">#清除内存</span></span><br><span class="line"><span class="keyword">del</span> model</span><br><span class="line">torch.cuda.empty_cache()</span><br></pre></td></tr></table></figure>
<h4 id="定义检测器">定义检测器</h4>
<p>这里convariate_shift_detecor<span class="math inline">\((x_i)=\beta_i
=\frac{p\left(\mathbf{x}_i\right)}{q\left(\mathbf{x}_i\right)}\)</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span>  <span class="title function_">covariate_shift_detector</span>(<span class="params">input_image,model_pth=<span class="string">&#x27;../data/ch04-4-9-2and4-9-3/covariate_shift_detectormodel.pth&#x27;</span></span>):</span><br><span class="line">    softmax=nn.Softmax(dim = <span class="number">1</span>)</span><br><span class="line">    Use_gpu = torch.cuda.is_available()</span><br><span class="line">    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)</span><br><span class="line">    model.fc = torch.nn.Linear(<span class="number">2048</span>,<span class="number">2</span>)</span><br><span class="line">    model.load_state_dict(torch.load(model_pth))</span><br><span class="line">    <span class="keyword">if</span> Use_gpu:</span><br><span class="line">        model = model.cuda()</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    beta=<span class="keyword">lambda</span> x:<span class="built_in">min</span>(x[<span class="number">0</span>][<span class="number">0</span>]/x[<span class="number">0</span>][<span class="number">1</span>],<span class="number">1.0</span>)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(input_image)==<span class="number">1</span>:</span><br><span class="line">            output=beta(softmax(model(input_image)))</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            output=torch.tensor(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: beta(softmax(model(torch.unsqueeze(x,<span class="number">0</span>)))),input_image )))</span><br><span class="line">        <span class="keyword">del</span> model</span><br><span class="line">        torch.cuda.empty_cache()</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h4 id="测试结果">测试结果</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="comment">#test_iter,image_test_datasets=load_data_cartoonvsnormal(os.path.join(data_dir, &#x27;test&#x27;),batch_size)</span></span><br><span class="line">testnum=random.randint(<span class="number">0</span>,<span class="built_in">len</span>(image_test_datasets)-<span class="number">1</span>)</span><br><span class="line">index_classes = <span class="built_in">list</span>(image_test_datasets.class_to_idx.keys())</span><br><span class="line">input_image=torch.unsqueeze(image_test_datasets[testnum][<span class="number">0</span>],<span class="number">0</span>)</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    input_image=input_image.cuda()</span><br><span class="line">output=index_classes[<span class="number">0</span>] <span class="keyword">if</span> covariate_shift_detector(input_image)&gt;=<span class="number">1</span> <span class="keyword">else</span> index_classes[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;testnum &quot;</span>,testnum,<span class="string">&quot; 推断类别：&quot;</span>,output,<span class="string">&quot;实际类别：&quot;</span>,index_classes[image_test_datasets[testnum][<span class="number">1</span>]])</span><br><span class="line"><span class="keyword">del</span> input_image</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gc.collect()</span><br><span class="line">Use_gpu = torch.cuda.is_available()</span><br><span class="line"><span class="keyword">if</span> Use_gpu:</span><br><span class="line">    torch.cuda.empty_cache()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;clear&#x27;</span>)</span><br><span class="line">input_image=[i[<span class="number">0</span>].cuda() <span class="keyword">for</span> i <span class="keyword">in</span> image_test_datasets] <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> [i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> image_test_datasets]</span><br><span class="line">output=covariate_shift_detector(input_image)</span><br><span class="line">test_label=torch.tensor([i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> image_test_datasets])</span><br><span class="line">cartoonacc=torch.tensor(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt;=<span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> ,output-torch.mul(output,test_label)))).<span class="built_in">sum</span>()/(<span class="built_in">len</span>(test_label)-test_label.<span class="built_in">sum</span>())</span><br><span class="line">normalacc=torch.tensor(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> <span class="number">0</span>&lt;x &lt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> ,torch.mul(output,test_label)))).<span class="built_in">sum</span>()/(test_label.<span class="built_in">sum</span>())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;卡通图片预测正确率:&#123;:.4f&#125;% ,正常图片预测正确率:&#123;:.4f&#125;%&#x27;</span>.<span class="built_in">format</span>(<span class="number">100</span>*cartoonacc,<span class="number">100</span>*normalacc))</span><br><span class="line"><span class="keyword">del</span> input_image</span><br></pre></td></tr></table></figure>
<h3 id="实现协变量偏移纠正">实现协变量偏移纠正</h3>
<p>首先展示没有使用分类器来训练模型的结果，可以看到训练的后期，即使各个数据曲线已经趋平，训练准确率仍然高于测试准确率。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#import库 以及 用到的函数定义见4.9.2</span></span><br><span class="line"><span class="comment">#数据加载</span></span><br><span class="line"></span><br><span class="line">batch_size=<span class="number">32</span></span><br><span class="line">data_dir = <span class="string">&quot;../data/ch04-4-9-2and4-9-3/dogvscat&quot;</span></span><br><span class="line">mean_train_list,std_train_list=getmean_str(os.path.join(data_dir, <span class="string">&#x27;train&#x27;</span>),<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">mean_testcartoon_list,std_testcartoon_list=getmean_str(os.path.join(data_dir, <span class="string">&#x27;testcartoon&#x27;</span>),<span class="string">&#x27;testcartoon&#x27;</span>)</span><br><span class="line">mean_testnormal_list,std_testnormal_list=getmean_str(os.path.join(data_dir, <span class="string">&#x27;test&#x27;</span>),<span class="string">&#x27;testnormal&#x27;</span>)</span><br><span class="line">train_iter,image_train_datasets=load_data_cartoonvsnormal(os.path.join(data_dir, <span class="string">&#x27;train&#x27;</span>),mean_train_list,std_train_list,batch_size)</span><br><span class="line">testcartoon_iter,image_testcartoon_datasets=load_data_cartoonvsnormal(os.path.join(data_dir, <span class="string">&#x27;testcartoon&#x27;</span>),mean_testcartoon_list,std_testcartoon_list,batch_size)</span><br><span class="line">testnormal_iter,image_testnormal_datasets=load_data_cartoonvsnormal(os.path.join(data_dir, <span class="string">&#x27;test&#x27;</span>),mean_testnormal_list,std_testnormal_list,batch_size)</span><br><span class="line"><span class="comment">#加载模型</span></span><br><span class="line">model_no_detector = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)</span><br><span class="line">Use_gpu = torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> parma <span class="keyword">in</span> model_no_detector.parameters():</span><br><span class="line">    parma.requires_grad = <span class="literal">False</span><span class="comment">#屏蔽预训练模型的权重，只训练最后一层的全连接的权重</span></span><br><span class="line">model_no_detector.fc = torch.nn.Linear(<span class="number">2048</span>,<span class="number">2</span>)</span><br><span class="line">nn.init.xavier_uniform_(model_no_detector.fc.weight);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> Use_gpu:</span><br><span class="line">    model_no_detector = model_no_detector.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失函数和优化器</span></span><br><span class="line">loss_f = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(model_no_detector.fc.parameters(),lr =  <span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">10</span></span><br><span class="line">train_ch4_9(model_no_detector, train_iter, testcartoon_iter, loss_f, num_epochs,optimizer,Use_gpu,test_iter2=testnormal_iter,savename=<span class="string">&#x27;../data/ch04-4-9-2and4-9-3/dogvscatwithoutdetectormodel.pth&#x27;</span>)</span><br><span class="line"><span class="comment">#清除内存</span></span><br><span class="line"><span class="keyword">del</span> model_no_detector</span><br><span class="line">torch.cuda.empty_cache()</span><br></pre></td></tr></table></figure>
<h4 id="使用分类器来训练模型的结果">使用分类器来训练模型的结果</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gc.collect()<span class="comment">#内存清理</span></span><br><span class="line"><span class="comment">#数据加载</span></span><br><span class="line">batch_size=<span class="number">32</span></span><br><span class="line">data_dir = <span class="string">&quot;../data/ch04-4-9-2and4-9-3/dogvscat&quot;</span></span><br><span class="line">mean_train_list,std_train_list=getmean_str(os.path.join(data_dir, <span class="string">&#x27;train&#x27;</span>),<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">mean_testcartoon_list,std_testcartoon_list=getmean_str(os.path.join(data_dir, <span class="string">&#x27;testcartoon&#x27;</span>),<span class="string">&#x27;testcartoon&#x27;</span>)</span><br><span class="line">mean_testnormal_list,std_testnormal_list=getmean_str(os.path.join(data_dir, <span class="string">&#x27;test&#x27;</span>),<span class="string">&#x27;testnormal&#x27;</span>)</span><br><span class="line">train_iter,image_train_datasets=load_data_cartoonvsnormal(os.path.join(data_dir, <span class="string">&#x27;train&#x27;</span>),mean_train_list,std_train_list,batch_size)</span><br><span class="line">testcartoon_iter,image_testcartoon_datasets=load_data_cartoonvsnormal(os.path.join(data_dir, <span class="string">&#x27;testcartoon&#x27;</span>),mean_testcartoon_list,std_testcartoon_list,batch_size)</span><br><span class="line">testnormal_iter,image_testnormal_datasets=load_data_cartoonvsnormal(os.path.join(data_dir, <span class="string">&#x27;test&#x27;</span>),mean_testnormal_list,std_testnormal_list,batch_size)</span><br><span class="line"><span class="comment">#加载模型</span></span><br><span class="line">model_detector = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)</span><br><span class="line">Use_gpu = torch.cuda.is_available()</span><br><span class="line"><span class="keyword">if</span> Use_gpu:</span><br><span class="line">    <span class="comment">#del modelwithoutdetector</span></span><br><span class="line">    torch.cuda.empty_cache()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;clear&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> parma <span class="keyword">in</span> model_detector.parameters():</span><br><span class="line">    parma.requires_grad = <span class="literal">False</span><span class="comment">#屏蔽预训练模型的权重，只训练最后一层的全连接的权重</span></span><br><span class="line">model_detector.fc = torch.nn.Linear(<span class="number">2048</span>,<span class="number">2</span>)</span><br><span class="line">nn.init.xavier_uniform_(model_detector.fc.weight); </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> Use_gpu:</span><br><span class="line">    model_detector = model_detector.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment">#损失函数和优化器</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">myloss</span>(<span class="params">y_hat,y,beta</span>):</span><br><span class="line">    loss_f = torch.nn.CrossEntropyLoss(reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">    l=loss_f(y_hat,y)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">25</span>*torch.mul(beta,l).mean() <span class="comment">#直接使用beta计算结果 并没有改善 这可能是因为beta小于1 使loss变小 导致更新梯度以后 变化不大 所以乘以一个数 以改善这种情况</span></span><br><span class="line">     </span><br><span class="line">    </span><br><span class="line">optimizer = torch.optim.SGD(model_detector.fc.parameters(),lr =<span class="number">1e-4</span>) </span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">10</span></span><br><span class="line">train_ch4_9(model_detector, train_iter, testcartoon_iter,myloss, num_epochs,optimizer,Use_gpu,test_iter2=testnormal_iter,savename=<span class="string">&#x27;../data/ch04-4-9-2and4-9-3/dogvscatwithdetectormodel.pth&#x27;</span>,detector=covariate_shift_detector)</span><br><span class="line"><span class="comment">#清除内存</span></span><br><span class="line"><span class="keyword">del</span> model_detector</span><br><span class="line">torch.cuda.empty_cache()</span><br></pre></td></tr></table></figure>
<h4 id="比较">比较</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gc.collect()</span><br><span class="line">Use_gpu = torch.cuda.is_available()</span><br><span class="line"><span class="keyword">if</span> Use_gpu:</span><br><span class="line">    <span class="comment">#del modelwithoutdetector</span></span><br><span class="line">    torch.cuda.empty_cache()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;clear&#x27;</span>)</span><br><span class="line">data_dir = <span class="string">&quot;../data/ch04-4-9-2and4-9-3/dogvscat&quot;</span></span><br><span class="line">batch_size=<span class="number">32</span></span><br><span class="line">mean_testcartoon_list,std_testcartoon_list=getmean_str(os.path.join(data_dir, <span class="string">&#x27;testcartoon&#x27;</span>),<span class="string">&#x27;testcartoon&#x27;</span>)</span><br><span class="line">testcartoon_iter,image_testcartoon_datasets=load_data_cartoonvsnormal(os.path.join(data_dir, <span class="string">&#x27;testcartoon&#x27;</span>),mean_testcartoon_list,std_testcartoon_list,batch_size)</span><br><span class="line"><span class="comment">#加载模型</span></span><br><span class="line">model_detector = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)</span><br><span class="line">model_detector.fc = torch.nn.Linear(<span class="number">2048</span>,<span class="number">2</span>)</span><br><span class="line">model_detector.load_state_dict(torch.load(<span class="string">&#x27;../data/ch04-4-9-2and4-9-3/dogvscatwithdetectormodel.pth&#x27;</span>))</span><br><span class="line"><span class="comment">#加载模型\</span></span><br><span class="line">model_no_detector = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)</span><br><span class="line">model_no_detector.fc = torch.nn.Linear(<span class="number">2048</span>,<span class="number">2</span>)</span><br><span class="line">model_no_detector.load_state_dict(torch.load(<span class="string">&#x27;../data/ch04-4-9-2and4-9-3/dogvscatwithoutdetectormodel.pth&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;没使用分类器测试准确率：&#123;:.4f&#125;%,使用分类器测试准确率：&#123;:.4f&#125;%&quot;</span>.<span class="built_in">format</span>(<span class="number">100</span>*evaluate_accuracy_ch4_9(model_no_detector,testcartoon_iter,Use_gpu),<span class="number">100</span>*evaluate_accuracy_ch4_9(model_detector, testcartoon_iter,Use_gpu)))</span><br><span class="line"><span class="comment">#清除内存</span></span><br><span class="line"><span class="keyword">del</span> model_no_detector</span><br><span class="line"><span class="keyword">del</span> model_detector</span><br><span class="line">torch.cuda.empty_cache()</span><br></pre></td></tr></table></figure>
<h3 id="结果">结果</h3>
<p>testcartoon mean: tensor([0.4168, 0.3945, 0.3463]) std:
tensor([0.2118, 0.2033, 0.1590])
没使用分类器测试准确率：89.8000%,使用分类器测试准确率：92.3600%</p>
<p>事实上如果你在优化器不用SGD而是用Adam会得到更好的结果
而且你会发现用不用分类器结果都差不多orz</p>
<p>在训练的时候会遇见test_acc高于train_acc的情况 这可能是因为train_acc
是在每个batchsize之后统计的 而
test_acc是在一个epoch后统计的（一个牵强的解释，始终不能理解为什么可以在一个epoch后就产生这么高的test_acc）</p>
]]></content>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>MMDetection3D 实践</title>
    <url>/post/9f7e2fde.html</url>
    <content><![CDATA[<p>MMDetection3D 实践<br />
<span id="more"></span></p>
<h1 id="mmdetection3d-实践">MMDetection3D 实践</h1>
<p>参考视频：https://www.bilibili.com/video/BV1aG4y197is/?spm_id_from=333.788&amp;vd_source=89cd1bd958a3eea212de763dc113559e</p>
<p>参考文档：https://mmdetection3d.readthedocs.io/en/latest/</p>
<h2 id="mmdetection3d-安装配置">MMDetection3D 安装配置</h2>
<p>在已经配置好torch 和openmim情况下</p>
<p>激活配置环境</p>
<p>安装open3d</p>
<p><code>pip install open3d</code></p>
<p><code>git clone https://github.com/open-mmlab/mmdetection3d.git</code></p>
<p><code>cd mmdetection3d</code></p>
<p><code>mim install -e .</code></p>
<p>一小段报错信息。。。。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ERROR: pip&#x27;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.`</span><br><span class="line">`mmsegmentation 0.30.0 requires mmcv-full&lt;1.7.0,&gt;=1.4.4, but you have mmcv-full 1.7.1 which is incompatible.`</span><br><span class="line">`Successfully installed Flask-2.2.5 Jinja2-3.1.2 MarkupSafe-2.1.3 PyWavelets-1.4.1 Send2Trash-1.8.2 absl-py-1.4.0 anyio-3.7.0 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 arrow-1.2.3 attrs-23.1.0 beautifulsoup4-4.12.2 black-23.3.0 bleach-6.0.0 cachetools-5.3.1 cffi-1.15.1 configargparse-1.5.3 dash-2.10.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 defusedxml-0.7.1 descartes-1.1.0 exceptiongroup-1.1.1 fastjsonschema-2.17.1 fire-0.5.0 flake8-6.0.0 fqdn-1.5.1 google-auth-2.20.0 google-auth-oauthlib-1.0.0 grpcio-1.54.2 imageio-2.31.1 iniconfig-2.0.0 ipython-genutils-0.2.0 isoduration-20.11.0 itsdangerous-2.1.2 joblib-1.2.0 jsonpointer-2.4 jsonschema-4.17.3 jupyter-1.0.0 jupyter-console-6.6.3 jupyter-events-0.6.3 jupyter-server-2.6.0 jupyter-server-terminals-0.4.4 jupyterlab-pygments-0.2.2 lazy_loader-0.2 llvmlite-0.40.1rc1 lyft_dataset_sdk-0.0.8 matplotlib-3.5.2 mccabe-0.7.0 mistune-3.0.1 mmcv-2.0.0 mmdet-3.0.0 mmdet3d-1.1.1 mmengine-0.7.4 mypy-extensions-1.0.0 nbclassic-1.0.0 nbclient-0.8.0 nbconvert-7.6.0 nbformat-5.7.0 networkx-3.1 notebook-6.5.4 notebook-shim-0.2.3 numba-0.57.0 nuscenes-devkit-1.1.10 oauthlib-3.2.2 open3d-0.17.0 overrides-7.3.1 pandocfilters-1.5.0 pathspec-0.11.1 plotly-5.15.0 pluggy-1.0.0 plyfile-0.9 prometheus-client-0.17.0 protobuf-4.23.3 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycodestyle-2.10.0 pycparser-2.21 pyflakes-3.0.1 pyquaternion-0.9.9 pyrsistent-0.19.3 pytest-7.3.2 python-json-logger-2.0.7 pywinpty-2.0.10 qtconsole-5.4.3 qtpy-2.3.1 requests-oauthlib-1.3.1 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rsa-4.9 scikit-image-0.21.0 scikit-learn-1.2.2 shapely-1.8.5 sniffio-1.3.0 soupsieve-2.4.1 tenacity-8.2.2 tensorboard-2.13.0 tensorboard-data-server-0.7.1 terminado-0.17.1 threadpoolctl-3.1.0 tifffile-2023.4.12 tinycss2-1.2.1 tomli-2.0.1 trimesh-3.22.1 uri-template-1.2.0 webcolors-1.13 webencodings-0.5.1 websocket-client-1.6.0 werkzeug-2.2.3</span><br></pre></td></tr></table></figure>
<p><code>import mmdet3d</code></p>
<p><code>mmdet3d.__version__</code><br />
<code>'1.1.1'</code></p>
<p>使用预训练模型推理</p>
<p>点云数据清理</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install open3d </span><br></pre></td></tr></table></figure>
<p>ImportError: cannot import name 'show_result_meshlab' from
'mmdet3d.apis'</p>
<p>在使用’show_result’处改为’model.show_result（）’。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">model.show_result(</span><br><span class="line">img,result,model.CLASSES, score_thr=args.score_thr, wait_time=1)</span><br></pre></td></tr></table></figure>
<p><code>!mim download mmdet3d --config pointpillars_hv_secfpn_8xb6-160e_kitti-3d-car --dest checkpoints</code></p>
<p><code>!python demo/pcd_demo.py demo/data/kitti/000008.bin checkpoints/pointpillars_hv_secfpn_8xb6-160e_kitti-3d-car.py checkpoints/hv_pointpillars_secfpn_6x8_160e_kitti-3d-car_20220331_134606-d42d15ed.pth --show</code></p>
<p><img
src="E:/WechatFiles/WeChat%20Files/wxid_vnbsys77zytt22/FileStorage/Temp/1687337312236.png"
alt="1687337312236" /></p>
]]></content>
      <tags>
        <tag>OpenMMLab</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>mathematica 代码片段</title>
    <url>/post/30c85c6d.html</url>
    <content><![CDATA[<p>存放一下mma代码片段</p>
<span id="more"></span>
<p>找到二维右上最近邻位置函数</p>
<figure class="highlight mathematica"><table><tr><td class="code"><pre><span class="line"><span class="variable">nextright</span><span class="punctuation">[</span><span class="type">x_</span><span class="punctuation">]</span> <span class="operator">:=</span> </span><br><span class="line"> <span class="built_in">Block</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="variable">n</span> <span class="operator">=</span> <span class="built_in">Length</span><span class="operator">@</span><span class="variable">x</span><span class="punctuation">&#125;</span><span class="operator">,</span> </span><br><span class="line">  <span class="built_in">Table</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="variable">x</span><span class="punctuation">[</span><span class="punctuation">[</span><span class="variable">i</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="operator">,</span> <span class="variable">x</span><span class="punctuation">[</span><span class="punctuation">[</span><span class="built_in">If</span><span class="punctuation">[</span><span class="variable">i</span> <span class="operator">+</span> <span class="number">1</span> <span class="operator">&gt;</span> <span class="variable">n</span><span class="operator">,</span> <span class="number">1</span><span class="operator">,</span> <span class="variable">i</span> <span class="operator">+</span> <span class="number">1</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="operator">,</span> <span class="punctuation">&#123;</span><span class="variable">i</span><span class="operator">,</span> <span class="variable">n</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">]</span></span><br><span class="line"><span class="variable">nextleft</span><span class="punctuation">[</span><span class="type">x_</span><span class="punctuation">]</span> <span class="operator">:=</span> </span><br><span class="line"> <span class="built_in">Table</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="variable">x</span><span class="punctuation">[</span><span class="punctuation">[</span><span class="variable">i</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="operator">,</span> <span class="variable">x</span><span class="punctuation">[</span><span class="punctuation">[</span><span class="built_in">If</span><span class="punctuation">[</span><span class="variable">i</span> <span class="operator">-</span> <span class="number">1</span> <span class="operator">&lt;=</span> <span class="number">0</span><span class="operator">,</span> <span class="operator">-</span><span class="number">1</span><span class="operator">,</span> <span class="variable">i</span> <span class="operator">-</span> <span class="number">1</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="operator">,</span> <span class="punctuation">&#123;</span><span class="variable">i</span><span class="operator">,</span> <span class="built_in">Length</span><span class="operator">@</span><span class="variable">x</span><span class="punctuation">&#125;</span><span class="punctuation">]</span></span><br><span class="line"><span class="variable">nextup</span><span class="punctuation">[</span><span class="type">x_</span><span class="operator">,</span> <span class="type">y_</span><span class="punctuation">]</span> <span class="operator">:=</span> <span class="built_in">MapThread</span><span class="punctuation">[</span><span class="built_in">List</span><span class="operator">,</span> <span class="punctuation">&#123;</span><span class="variable">x</span><span class="operator">,</span> <span class="variable">y</span><span class="punctuation">&#125;</span><span class="punctuation">]</span></span><br><span class="line"><span class="variable">nextdown</span><span class="punctuation">[</span><span class="type">x_</span><span class="operator">,</span> <span class="type">y_</span><span class="punctuation">]</span> <span class="operator">:=</span> <span class="built_in">MapThread</span><span class="punctuation">[</span><span class="built_in">List</span><span class="operator">,</span> <span class="punctuation">&#123;</span><span class="variable">y</span><span class="operator">,</span> <span class="variable">x</span><span class="punctuation">&#125;</span><span class="punctuation">]</span></span><br><span class="line"><span class="variable">next</span><span class="punctuation">[</span><span class="type">L_</span><span class="punctuation">]</span> <span class="operator">:=</span> </span><br><span class="line"> <span class="built_in">Block</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="variable">M</span> <span class="operator">=</span> <span class="built_in">ArrayReshape</span><span class="punctuation">[</span><span class="built_in">Range</span><span class="punctuation">[</span><span class="variable">L</span><span class="operator">*</span><span class="variable">L</span><span class="punctuation">]</span><span class="operator">,</span> <span class="punctuation">&#123;</span><span class="variable">L</span><span class="operator">,</span> <span class="variable">L</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="operator">,</span> <span class="variable">n</span> <span class="operator">=</span> <span class="variable">L</span><span class="operator">*</span><span class="variable">L</span><span class="punctuation">&#125;</span><span class="operator">,</span> </span><br><span class="line">  <span class="built_in">Flatten</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="variable">nextup</span><span class="punctuation">[</span><span class="built_in">Sequence</span> <span class="operator">@@</span> <span class="type">#</span><span class="punctuation">]</span> <span class="operator">&amp;</span> <span class="operator">/@</span> <span class="variable">nextleft</span><span class="punctuation">[</span><span class="variable">M</span><span class="punctuation">]</span><span class="operator">,</span> <span class="variable">nextright</span> <span class="operator">/@</span> <span class="variable">M</span><span class="punctuation">&#125;</span><span class="operator">,</span> <span class="number">2</span><span class="punctuation">]</span><span class="punctuation">]</span></span><br><span class="line"><span class="variable">nextall</span><span class="punctuation">[</span><span class="type">L_</span><span class="punctuation">]</span> <span class="operator">:=</span> </span><br><span class="line"> <span class="built_in">Block</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="variable">M</span> <span class="operator">=</span> <span class="built_in">ArrayReshape</span><span class="punctuation">[</span><span class="built_in">Range</span><span class="punctuation">[</span><span class="variable">L</span><span class="operator">*</span><span class="variable">L</span><span class="punctuation">]</span><span class="operator">,</span> <span class="punctuation">&#123;</span><span class="variable">L</span><span class="operator">,</span> <span class="variable">L</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="operator">,</span> <span class="variable">n</span> <span class="operator">=</span> <span class="variable">L</span><span class="operator">*</span><span class="variable">L</span><span class="punctuation">&#125;</span><span class="operator">,</span> </span><br><span class="line">  <span class="built_in">Sort</span><span class="punctuation">[</span><span class="built_in">Flatten</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="variable">nextup</span><span class="punctuation">[</span><span class="built_in">Sequence</span> <span class="operator">@@</span> <span class="type">#</span><span class="punctuation">]</span> <span class="operator">&amp;</span> <span class="operator">/@</span> <span class="variable">nextleft</span><span class="punctuation">[</span><span class="variable">M</span><span class="punctuation">]</span><span class="operator">,</span> </span><br><span class="line">     <span class="variable">nextup</span><span class="punctuation">[</span><span class="built_in">Sequence</span> <span class="operator">@@</span> <span class="type">#</span><span class="punctuation">]</span> <span class="operator">&amp;</span> <span class="operator">/@</span> <span class="variable">nextright</span><span class="punctuation">[</span><span class="variable">M</span><span class="punctuation">]</span><span class="operator">,</span> <span class="variable">nextleft</span> <span class="operator">/@</span> <span class="variable">M</span><span class="operator">,</span> </span><br><span class="line">     <span class="variable">nextright</span> <span class="operator">/@</span> <span class="variable">M</span><span class="punctuation">&#125;</span><span class="operator">,</span> <span class="number">2</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="punctuation">]</span></span><br><span class="line"><span class="variable">nextall2</span><span class="punctuation">[</span><span class="type">L_</span><span class="punctuation">]</span> <span class="operator">:=</span> </span><br><span class="line"> <span class="built_in">Block</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="variable">M</span> <span class="operator">=</span> <span class="built_in">ArrayReshape</span><span class="punctuation">[</span><span class="built_in">Range</span><span class="punctuation">[</span><span class="variable">L</span><span class="operator">*</span><span class="variable">L</span><span class="punctuation">]</span><span class="operator">,</span> <span class="punctuation">&#123;</span><span class="variable">L</span><span class="operator">,</span> <span class="variable">L</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="operator">,</span> <span class="variable">n</span> <span class="operator">=</span> <span class="variable">L</span><span class="operator">*</span><span class="variable">L</span><span class="punctuation">&#125;</span><span class="operator">,</span> </span><br><span class="line">  <span class="built_in">Partition</span><span class="punctuation">[</span></span><br><span class="line">   <span class="built_in">Sort</span><span class="punctuation">[</span><span class="built_in">Flatten</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="variable">nextup</span><span class="punctuation">[</span><span class="built_in">Sequence</span> <span class="operator">@@</span> <span class="type">#</span><span class="punctuation">]</span> <span class="operator">&amp;</span> <span class="operator">/@</span> <span class="variable">nextleft</span><span class="punctuation">[</span><span class="variable">M</span><span class="punctuation">]</span><span class="operator">,</span> </span><br><span class="line">      <span class="variable">nextup</span><span class="punctuation">[</span><span class="built_in">Sequence</span> <span class="operator">@@</span> <span class="type">#</span><span class="punctuation">]</span> <span class="operator">&amp;</span> <span class="operator">/@</span> <span class="variable">nextright</span><span class="punctuation">[</span><span class="variable">M</span><span class="punctuation">]</span><span class="operator">,</span> <span class="variable">nextleft</span> <span class="operator">/@</span> <span class="variable">M</span><span class="operator">,</span> </span><br><span class="line">      <span class="variable">nextright</span> <span class="operator">/@</span> <span class="variable">M</span><span class="punctuation">&#125;</span><span class="operator">,</span> <span class="number">2</span><span class="punctuation">]</span><span class="punctuation">]</span><span class="operator">,</span> <span class="variable">L</span><span class="punctuation">]</span><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>mathematica</tag>
      </tags>
  </entry>
  <entry>
    <title>ChatGPT (可能)是怎麼煉成的 - GPT 社會化的過程</title>
    <url>/post/3f37b543.html</url>
    <content><![CDATA[<h1 id="chatgpt-可能是怎麼煉成的---gpt-社會化的過程">ChatGPT
(可能)是怎麼煉成的 - GPT 社會化的過程</h1>
<span id="more"></span>
<p>李宏毅老师YouTube原视频</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/e0aKI2GGZNg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>
</iframe>
<p>Instruct GPT https://arxivorg/abs/2203.02155</p>
<p>GPT-3 https://arxiv.org/pdf/2005.14165</p>
<p>https://openai.com/blog/chatgpt/</p>
<p>GPT =Generative Pre-trained Transformer</p>
<ol type="1">
<li><p>学习文字接龙</p>
<ul>
<li>学习一堆词后面出现什么词的概率 比如给一个不完整的句子 “你好”
让他后面接词</li>
<li>GPT先从网络中看大量文句 从而知道 一段文字后出现词的几率分布
在回答时按这种几率分布回答 从而每次回答都不一样</li>
</ul></li>
<li><p>人类老师引导文字接龙的方向</p>
<ul>
<li>找人来思考想问GPT的问题，并提供正确答案 提供比较好的数据
让他学习</li>
</ul></li>
<li><p>模仿人类老师的喜好</p>
<ul>
<li>找一批人评价GPT的回答 然后用这个评价数据 训练一个 teacher model
用来评分</li>
</ul></li>
<li><p>增强式学习向老师模拟老师学习</p>
<ul>
<li>当别人问GPT 问题 GPT 给出答案 并把问题和答案输入Teacher model
得到评分 修改GPT参数（Reward）</li>
</ul>
<p>但是ChatGPT仍然不完美 问一下 没用的问题（训练中没有考虑到的问题问法）
他就不行了</p></li>
</ol>
]]></content>
      <tags>
        <tag>-人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenMMLab实战营第六课 语义分割算法基础</title>
    <url>/post/6823557e.html</url>
    <content><![CDATA[<h2 id="什么是语义分割">什么是语义分割</h2>
<p>任务： 将图像按照物体的类别分割成不同的区域<br />
等价于： 对每个像素进行分类</p>
<span id="more"></span>
<p>应用：</p>
<ul>
<li><p>无人驾驶汽车
自动驾驶车辆，会将行人，其他车辆，行车道，人行道、交通标志、房屋、草地与树木等等按照类别在图像中分割出来，从而辅助车辆对道路的情况进行识别与认知。</p></li>
<li><p>人像分割 实时替换视频的背景
在智慧互娱和智能会议场景中，可以通过这种方法增加交互的多样性</p></li>
<li><p>智能遥感
通过智能遥感能够监测不同季节地表水域的变化，从而辅助农业生产，以及旱灾洪灾的预测等等。</p>
<table>
<colgroup>
<col style="width: 39%" />
<col style="width: 29%" />
<col style="width: 30%" />
</colgroup>
<thead>
<tr class="header">
<th>语义分割</th>
<th>实例分割</th>
<th>全景分割</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>仅考虑像素的类别不分割同一类的不同实体</td>
<td>分割不同的实体 仅考虑前景物体</td>
<td>背景仅考虑类别前景需要区分实体</td>
</tr>
</tbody>
</table>
<h2 id="一些以前的思路">一些以前的思路</h2>
<ul>
<li><p>按颜色分割</p>
<ul>
<li>先验知识 物体内部颜色相近，物体交界颜色变化</li>
<li>问题</li>
<li>先验知识不完全准确：不同物体颜色可能相近，物体内也会包含多种颜色</li>
</ul></li>
<li><p>逐像素分类 搞很多滑窗</p>
<ul>
<li><p>优势：可以充分利用已有的图像分类模型</p></li>
<li><p>问题：效率低下，重叠区域重复计算卷积</p></li>
</ul></li>
</ul></li>
</ul>
<h2 id="现在的方法">现在的方法</h2>
<h3 id="全卷积网络-fully-convolutional-network-2015">全卷积网络 Fully
Convolutional Network 2015</h3>
<p>复用卷积计算 直接对全图进行卷积 得到特征图</p>
<p>全连接层的卷积化(不在固定特征图大小 原来全连接层多少个神经元
变成多少个卷积核)</p>
<p>预测图的升采样</p>
<p>问题：</p>
<p>图像分类模型使用降采样层（步长卷积或池化）获得高层次特征，导致全卷积网络输出尺寸小于原图，而分割要求同尺寸输出</p>
<p>解决方法：<br />
对预测的分割图升采样，恢复原图分辨率，升采样方案：<br />
1. 双线性插值 Bilinear Interpolation 等效于把特征图零插值
在用一个固定参数卷积核 作用它</p>
<ol start="2" type="1">
<li>转置卷积Transposed Convolution：可学习的升采样层</li>
</ol>
<h3 id="unet-2015">UNet 2015</h3>
<p>基于多层级特征的上采样<br />
问题：基于顶层特征预测，再升采样32 倍得到的预测图较为粗糙。<br />
分析：高层特征经过多次降采样，细节丢失严重。<br />
解决思路：结合低层次和高层次特征图。<br />
解决方案FCN：<br />
基于低层次和高层次特征图分别产生类别预测，升采样到原图大小，再平均得到最终结果</p>
<h3 id="pspnet-2016">PSPNet 2016</h3>
<p>图像周围的内容（也称上下文）可以帮助我们做出更准确的判断。<br />
方案：增加感受野更大的网络分支，将上下文信息导入局部预测中<br />
PSPNet 2016<br />
(a) 对特征图进行不同尺度的池化，得到不同尺度的上下文特征<br />
(b) 上下文特征经过通道压缩和空间上采样之后拼接回原特征图→
同时包含局部和上下文特征<br />
(c) 基于融合的特征产生预测图<br />
### DeepLab 系列<br />
DeepLab 是语义分割的又一系列工作，其主要贡献为：<br />
• 使用空洞卷积解决网络中的下采样问题（减少下采样保留空间分辨率）</p>
<ul>
<li><p>图像分类模型中的下采样层使输出尺寸变小</p>
<ul>
<li>如果将池化层和卷积中的步长去掉：
<ul>
<li>可以减少下采样的次数；</li>
<li>特征图就会变大，需要对应增大卷积核，以维持相同的感受野，但会增加大量参数</li>
<li>使用空洞卷积（Dilated Convolution/Atrous
Convolution），在不增加参数的情况下增大感受野</li>
</ul></li>
</ul></li>
<li><p>使用条件随机场CRF 作为后处理手段，精细化分割图</p>
<ul>
<li><p>条件随机场Conditional Random Field, CRF</p>
<p>模型直接输出的分割图较为粗糙，尤其在物体边界处不能产生很好的分割结果。<br />
DeepLab v1&amp;v2 使用条件随机场(CRF)
作为后处理手段，结合原图颜色信息和神经网络预测的类<br />
别得到精细化分割结果。</p>
<p>CRF 是一种概率模型。DeepLab 使用CRF
对分割结果进行建模，用能量函数用来表示分割结果优劣，通过最小化能量函数获得更好的分割结果。</p>
<p><span class="math display">\[E(\boldsymbol{x})=\sum_i
\theta_i\left(x_i\right)+\sum_{i, j} \theta_{i j}\left(x_i,
x_j\right)\]</span></p>
<p><span class="math display">\[\theta_i\left(x_i\right)=-log
P\left(x_i\right)\]</span></p>
<p><span class="math inline">\(x_i\)</span>,<span
class="math inline">\(x_j\)</span>
特定像素的预测结果（向量化后只有1维坐标）</p>
<p><strong>x</strong> 全部像素的预测结果</p>
<p><span class="math inline">\(\theta_i(x_i)\)</span>
单个预测对能量函数的贡献</p>
<p><span class="math inline">\(\theta_{i,j}(x_i,x_j)\)</span>
一对预测对能量函数的贡献</p></li>
</ul></li>
<li><p>使用多尺度的空洞卷积（ASPP 模块）捕捉上下文信息<br />
DeepLab v1 发表于2014 年，后于2016、2017、2018 年提出v2、v3、v3+
版本。</p></li>
</ul>
<h2 id="语义分割算法总结">语义分割算法总结</h2>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93.png"/>
</center>
<center>
<b><font size ='2'>来自同济自豪兄OpenMMlab AI 实训营课件</font></b>
</center>
<p></font></p>
<h2 id="语义分割模型的评估">语义分割模型的评估</h2>
<p>基于交并集给出评估指标</p>
<p><img
src="https://www.jeremyjordan.me/content/images/2018/05/target_prediction.png" /></p>
<p><img
src="https://www.jeremyjordan.me/content/images/2018/05/intersection_union.png" /></p>
<p>图片出处
https://www.jeremyjordan.me/evaluating-image-segmentation-models/</p>
<p>Accuracy =GT∩Pred/GT</p>
<p>IoU =GT∩Pred/GT∪Pred</p>
<p>Dice =2 × GT∩Pred/（GT+Pred）</p>
<p>对每类计算指标再按类别平均</p>
<h2 id="问题与回答">问题与回答</h2>
]]></content>
      <tags>
        <tag>OpenMMLab</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>openmmlab实战营第五课 MMDetection 代码教学</title>
    <url>/post/1554c19c.html</url>
    <content><![CDATA[<h1 id="mmdetection-可以做什么">MMDetection 可以做什么</h1>
<ul>
<li><p><a
href="https://mmdetection.readthedocs.io/en/latest/">MMDetection</a>
提供400 余个性能优良的预训练模型，开箱即用，几行Python API
即可调用强大的检测能力</p></li>
<li><p><a
href="https://mmdetection.readthedocs.io/en/latest/">MMDetection</a>
涵盖60
余个目标检测算法，并提供方便易用的工具，经过简单的配置文件改写和调参就可以训练自己的目标检测模型</p>
<span id="more"></span></li>
</ul>
<div class="text" style=" text-align:center;">
<font size="30">MMDetection</font>
</div>
<table>
<thead>
<tr class="header">
<th>任务支持</th>
<th>覆盖广泛</th>
<th>算法丰富</th>
<th>算法丰富</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>目标检测</td>
<td>440+ 个预训练模型</td>
<td>两阶段检测器</td>
<td>训练工具</td>
</tr>
<tr class="even">
<td>目标检测</td>
<td>60+ 篇论文复现</td>
<td>一阶段检测器</td>
<td>测试工具</td>
</tr>
<tr class="odd">
<td>全景分割</td>
<td>常用学术数据集</td>
<td>级联检测器</td>
<td>推理 API</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>无锚框检测器</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>Transformer</td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="openmmlab-项目中的重要概念配置文件">OpenMMLab
项目中的重要概念——配置文件</h3>
<p>深度学习模型的训练涉及几个方面：<br />
− 模型结构模型有几层、每层多少通道数等等<br />
−
数据集用什么数据训练模型：数据集划分、数据文件路径、数据增强策略等等<br />
−
训练策略梯度下降算法、学习率参数、batch_size、训练总轮次、学习率变化策略等等<br />
− 运行时GPU、分布式环境配置等等<br />
− 一些辅助功能如打印日志、定时保存checkpoint等等</p>
<p>在OpenMMLab
项目中，所有这些项目都涵盖在一个配置文件中，一个配置文件定义了一个完整的训练过程<br />
− model 字段定义模型<br />
− data 字段定义数据<br />
− optimizer、lr_config 等字段定义训练策略<br />
− load_from 字段定义与训练模型的参数文件</p>
<pre class="mermaid">

 
flowchart LR;
subgraph 配置文件
模型结构
数据集
数据处理策略
学习率策略
优化器策略
运行环境配置
end


subgraph 模型库
预训练模型
end

subgraph 内部模块
A[模型构建]
B[数据加载器构建]
C[优化器构建]
D[Runner]
A--&gt;D
B--&gt;D
C--&gt;D
end

subgraph 工具
训练工具
测试工具
推理工具
end

subgraph 数据文件
COCO
自定义数据
推理工具
S[Pascal VOC]
Cityscapes
end
内部模块 --&gt;工具
数据文件--&gt;内部模块
模型库--&gt;内部模块
配置文件--&gt;内部模块
</pre>
<p>安装环境</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install openmim</span><br><span class="line">mim install mmcv-full==1.3.17</span><br><span class="line">mim install mmdet==2.22.0</span><br></pre></td></tr></table></figure>
<p>验证是否成功 参考<a
href="https://mmdetection.readthedocs.io/zh_CN/latest/index.html">官方的文档</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> mmdet.apis <span class="keyword">import</span> init_detector, inference_detector,show_result_pyplot</span><br><span class="line">config_file = <span class="string">&#x27;放faster_rcnn_r50_fpn_1x_coco.py的地址&#x27;</span></span><br><span class="line"><span class="comment"># 从 model zoo 下载 checkpoint 并放在 `checkpoints/` 文件下</span></span><br><span class="line"><span class="comment"># 网址为: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth</span></span><br><span class="line">checkpoint_file = <span class="string">&#x27;放faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth的地址&#x27;</span></span><br><span class="line">device = <span class="string">&#x27;cuda:0&#x27;</span></span><br><span class="line"><span class="comment"># 初始化检测器</span></span><br><span class="line">model = init_detector(config_file, checkpoint_file, device=device)</span><br><span class="line"><span class="comment"># 推理演示图像</span></span><br><span class="line">result=inference_detector(model, <span class="string">&#x27;图像地址可以用demo里的图&#x27;</span>)</span><br><span class="line">show_result_pyplot(model,<span class="string">&#x27;图像地址可以用demo里的图&#x27;</span>,result) <span class="comment">#展示图片</span></span><br></pre></td></tr></table></figure>
<p>如何把一个新的数据集转化为coco数据集训练
以这次课程的balloon数据集为例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> os.path <span class="keyword">as</span> osp</span><br><span class="line"><span class="keyword">import</span> mmcv</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_balloon_to_coco</span>(<span class="params">ann_file, out_file, image_prefix</span>):</span><br><span class="line">    data_infos = mmcv.load(ann_file)</span><br><span class="line"></span><br><span class="line">    annotations = []</span><br><span class="line">    images = []</span><br><span class="line">    obj_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> idx, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(mmcv.track_iter_progress(data_infos.values())):</span><br><span class="line">        filename = v[<span class="string">&#x27;filename&#x27;</span>]</span><br><span class="line">        img_path = osp.join(image_prefix, filename)</span><br><span class="line">        height, width = mmcv.imread(img_path).shape[:<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        images.append(<span class="built_in">dict</span>(</span><br><span class="line">            <span class="built_in">id</span>=idx,</span><br><span class="line">            file_name=filename,</span><br><span class="line">            height=height,</span><br><span class="line">            width=width))</span><br><span class="line"></span><br><span class="line">        bboxes = []</span><br><span class="line">        labels = []</span><br><span class="line">        masks = []</span><br><span class="line">        <span class="keyword">for</span> _, obj <span class="keyword">in</span> v[<span class="string">&#x27;regions&#x27;</span>].items():</span><br><span class="line">            <span class="keyword">assert</span> <span class="keyword">not</span> obj[<span class="string">&#x27;region_attributes&#x27;</span>]</span><br><span class="line">            obj = obj[<span class="string">&#x27;shape_attributes&#x27;</span>]</span><br><span class="line">            px = obj[<span class="string">&#x27;all_points_x&#x27;</span>]</span><br><span class="line">            py = obj[<span class="string">&#x27;all_points_y&#x27;</span>]</span><br><span class="line">            poly = [(x + <span class="number">0.5</span>, y + <span class="number">0.5</span>) <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(px, py)]</span><br><span class="line">            poly = [p <span class="keyword">for</span> x <span class="keyword">in</span> poly <span class="keyword">for</span> p <span class="keyword">in</span> x]</span><br><span class="line"></span><br><span class="line">            x_min, y_min, x_max, y_max = (</span><br><span class="line">                <span class="built_in">min</span>(px), <span class="built_in">min</span>(py), <span class="built_in">max</span>(px), <span class="built_in">max</span>(py))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            data_anno = <span class="built_in">dict</span>(</span><br><span class="line">                image_id=idx,</span><br><span class="line">                <span class="built_in">id</span>=obj_count,</span><br><span class="line">                category_id=<span class="number">0</span>,</span><br><span class="line">                bbox=[x_min, y_min, x_max - x_min, y_max - y_min],</span><br><span class="line">                area=(x_max - x_min) * (y_max - y_min),</span><br><span class="line">                segmentation=[poly],</span><br><span class="line">                iscrowd=<span class="number">0</span>)</span><br><span class="line">            annotations.append(data_anno)</span><br><span class="line">            obj_count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    coco_format_json = <span class="built_in">dict</span>(</span><br><span class="line">        images=images,</span><br><span class="line">        annotations=annotations,</span><br><span class="line">        categories=[&#123;<span class="string">&#x27;id&#x27;</span>:<span class="number">0</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;balloon&#x27;</span>&#125;])</span><br><span class="line">    mmcv.dump(coco_format_json, out_file)</span><br></pre></td></tr></table></figure>
<p>下载已经有的模型 可以用 mim search mmdet --model
"模型id"查有的模型<br />
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mim download mmdet --config mask_rcnn_r50_fpn_2x_coco --desk . </span><br></pre></td></tr></table></figure><br />
准备一个配置文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"> 这个新的配置文件继承自一个原始配置文件，只需要突出必要的修改部分即可</span><br><span class="line">_base_ = <span class="string">&#x27;mask_rcnn_r50_fpn_2x_coco.py&#x27;</span></span><br><span class="line"><span class="comment"># 我们需要对头中的类别数量进行修改来匹配数据集的标注</span></span><br><span class="line">model = <span class="built_in">dict</span>(</span><br><span class="line">    roi_head=<span class="built_in">dict</span>(</span><br><span class="line">        bbox_head=<span class="built_in">dict</span>(num_classes=<span class="number">1</span>),</span><br><span class="line">        mask_head=<span class="built_in">dict</span>(num_classes=<span class="number">1</span>)))</span><br><span class="line"> </span><br><span class="line">dataset_type = <span class="string">&#x27;CocoDataset&#x27;</span></span><br><span class="line">classes = (<span class="string">&#x27;balloon&#x27;</span>,)</span><br><span class="line">data = <span class="built_in">dict</span>(</span><br><span class="line">    train=<span class="built_in">dict</span>(</span><br><span class="line">        img_prefix=<span class="string">&#x27;/input0/balloon/train/&#x27;</span>,</span><br><span class="line">        classes=classes,</span><br><span class="line">        ann_file=<span class="string">&#x27;/input0/balloon/train/via_region_data2.json&#x27;</span>),</span><br><span class="line">    val=<span class="built_in">dict</span>(</span><br><span class="line">        img_prefix=<span class="string">&#x27;/input0/balloon/val/&#x27;</span>,</span><br><span class="line">        classes=classes,</span><br><span class="line">        ann_file=<span class="string">&#x27;/input0/balloon/val/via_region_data2.json&#x27;</span>),</span><br><span class="line">    test=<span class="built_in">dict</span>(</span><br><span class="line">        img_prefix=<span class="string">&#x27;/input0/balloon/val/&#x27;</span>,</span><br><span class="line">        classes=classes,</span><br><span class="line">        ann_file=<span class="string">&#x27;/input0/balloon/val/via_region_data2.json&#x27;</span>))</span><br><span class="line"><span class="comment">#model= dict(bbox_head=dict(num_classes=1))</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 我们可以使用预训练的 Mask R-CNN 来获取更好的性能</span></span><br><span class="line">load_from =<span class="string">&#x27;mask_rcnn_r50_fpn_2x_coco_bbox_mAP-0.392__segm_mAP-0.354_20200505_003907-3e542a40.pth&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>训练模型</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mim train mmdet balloon.py</span><br></pre></td></tr></table></figure>
<p>测试模型</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mim test mmdet balloon.py --checkpoint work_dirs/balloon/latest.pth --show-dir work_dirs/balloon</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>OpenMMLab</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenMMLab实战营第四课 目标检测算法基础</title>
    <url>/post/b64f8832.html</url>
    <content><![CDATA[<h2 id="什么是目标检测">什么是目标检测</h2>
<p>识别出大图片里的感兴趣部分 并且框出来</p>
<h2 id="目标检测的应用">目标检测的应用</h2>
<span id="more"></span>
<h2 id="滑窗sliding-windows">滑窗(Sliding Windows)</h2>
<h3 id="步骤">步骤</h3>
<ol type="1">
<li><p>设定一个固定大小的窗口</p></li>
<li><p>遍历图像所有位置，所到之处用分类模型（假设已经训练好）识别窗口中的内容</p></li>
<li><p>为了检测不同大小、不同形状的物体，可以使用不同大小、长宽比的窗口扫描图片</p></li>
</ol>
<h3 id="缺点与改进思路">缺点与改进思路</h3>
<p>简单的滑窗需要很多窗口 计算成本太大</p>
<p>改进思路1：基于图像颜色或底层特征
使用启发式算法替换暴力遍历例（找出可能含有物体的区域）如R-CNN，Fast
R-CNN 中使用Selective Search
产生提议框依赖外部算法，系统实现复杂，难以联合优化性能</p>
<p>改进思路2：减少冗余计算，使用卷积网络实现密集预测（用卷积一次性计算所有特征，再取出对应位置的特征完成分类）。</p>
<p>目前普遍采用的方式改进思路2</p>
<h2 id="目标检测的基本范式">目标检测的基本范式</h2>
<p>两阶段方法（基于区域的方法）R-CNN Fast R-CNN<br />
以某种方式产生窗，再基于窗口内的特征进行预测</p>
<p>单阶段方法<br />
在特征图上基于单点特征实现密集预测 YOLO SSD</p>
<p>其他方法</p>
<p>级联方法 Transformer方法</p>
<p>介绍了目标检测的技术演进</p>
<pre class="mermaid">

flowchart LR;
subgraph A[传统方法]

DPM

end

subgraph B[两阶段方法]
1[R-CNN]
2[Fast R-CNN]
3[Faster R-CNN]
4[RPN]
1--&gt;2
2--&gt;3
4--&gt;3
3--&gt;111( )
111--&gt;5[Mask R-CNN]
end

subgraph C[单阶段方法]
6[YOLO]
7[SSD]
88[YOLO v3]
89[YOLO v5]
90[FCOS]
91[YOLO X]
RetinaNet
end
subgraph D[Transformer 方法]
DETR
Deformable
DETR
end
subgraph F[级联方法]
Cascade 
R-CNN
end

A--&gt; B
B--多尺度技术--&gt;C
C--&gt;|特征金字塔Feature Pyramid Networks,FPN|B
111 --&gt; F
</pre>
<h2 id="基础知识">基础知识</h2>
<h3 id="框边界框bounding-box">框，边界框（Bounding Box）</h3>
<p>描述一个框需要4 个像素值：<br />
• 方式1：左上右下边界坐标𝑙, 𝑡, 𝑟, 𝑏<br />
• 方式2：中心坐标和框的长宽𝑥, 𝑦, 𝑤, ℎ</p>
<p>边界框通常指紧密包围感兴趣物体的框<br />
检测任务要求为图中出现的每个物体预测一个边界框</p>
<h3 id="框相关的概念">框相关的概念</h3>
<ol type="1">
<li>区域（Region）：框的同义词</li>
<li>区域提议（Region Proposal，Proposal）<br />
指算法预测的可能包含物体的框，某种识别能力不强的算法的初步预测结果</li>
<li>感兴趣区域（Region of Interest，RoI）<br />
当我们谈论需要进一步检测这个框中是否有物体时，通常称框为感兴趣区域</li>
<li>锚框（Anchor Box，Anchor）<br />
图中预设的一系列基准框，类似滑窗，一些检测算法会基于锚框预测边界框</li>
</ol>
<h3 id="交并比intersection-over-union">交并比(Intersection Over
Union)</h3>
<p>定义为两矩形框交集面积与并集面积之比，是矩形框重合程度的衡量指标</p>
<p><img
src="http://ronny.rest/media/tutorials/localization/ZZZ_IMAGES_DIR/iou_formula.png" /></p>
<h3 id="置信度confidence-score">置信度(Confidence Score)</h3>
<p>模型认可自身预测结果的程度，通常需要为每个框预测一个置信度</p>
<h3 id="非极大值抑制non-maximum-suppression">非极大值抑制(Non-Maximum
Suppression)</h3>
<p>滑窗类算法通常会在物体周围给出多个相近的检测框。这些框实际指向同一物体，只需要保留其中置信度最高的</p>
<p>通过非极大值抑制（NMS）算法实现：</p>
<p>输入：检测器产生的一系列检测框<span class="math inline">\(𝐵 =\left\{
𝐵_1, … , 𝐵_𝑛\right\}\)</span> 及对应的置信度<br />
<span class="math inline">\(𝑠 =\left\{ 𝑠_1, … , 𝑠_𝑛\right\}\)</span>
,IoU 阈值𝑡（通常0.7）<br />
步骤：</p>
<ol type="1">
<li>初始化结果集𝑅 = ∅</li>
<li>重复直至𝐵 为空集<br />
① 找出𝐵 中置信度最大的框𝐵𝑖 并加入𝑅<br />
② 从𝐵 中删除<span class="math inline">\(𝐵_𝑖\)</span>以及与<span
class="math inline">\(𝐵_𝑖\)</span>交并比大于𝑡 的框<br />
输出：结果集𝑅</li>
</ol>
<h3 id="边界框回归bounding-box-regression">边界框回归(Bounding Box
Regression)</h3>
<h4 id="问题">问题</h4>
<p>滑窗（或其他方式产生的基准框）与物体精准边界通常有偏差</p>
<h4 id="处理方法">处理方法</h4>
<p>让模型在预测物体类别同时预测边界框相对于滑窗的偏移量</p>
<pre class="mermaid">

graph LR;

A[图像x]---B[卷积网络]
B---C[特征]
C---D[全连接层]
C---D2[全连接层]
D---F[c+1维分类概率]
D2---F2[4维偏移量]
F---分类损失
F2---回归损失

</pre>
<p>边界框编码Bbox Coding<br />
边界框的绝对偏移量在数值上通常较大，不利于神经网络训练，通常需要对偏移量进行编码，作为回归模型的预测目标</p>
<h2 id="两阶段算法概述">两阶段算法概述</h2>
<p>两阶段的检测范式最早由R-CNN
确立，因包含<strong>区域提议</strong>和<strong>区域识别</strong>两个阶段得名</p>
<p>经历一些列发展到Faster R-CNN 和Mask RCNN逐渐成熟</p>
<p>结合比较先进的主干网络和多尺度技术可以达到比较优越的检测精度，使用广泛</p>
<p>近几年（2020~）随着单阶段算法精度和速度的提高逐渐被取代</p>
<pre class="mermaid">

graph LR;

A[输入图像]---|传统视觉算法|B[区域提议]
B---C[裁剪缩放将提议框内的图像缩放至固定大小]
C---D[分类]

D---[汇总再NMS产生最终结果]

</pre>
<p>R-CNN（Region-based CNN 2013）缺点</p>
<p>慢：区域提议一般产生2000 个框，每个框都需要送入CNN
前传，推理一张图要几秒至几十秒
在裁剪提议框时进行了重复计算（物体重叠导致提议框重叠）</p>
<p>Fast R-CNN (2014)</p>
<p>对全图进行卷积网络产生了特征图
在裁剪提议框后找到对应的特征图在分类。</p>
<p>应为各个物体的提议框大小不一所以我们要在分类之前处理一下 使用RoI
Pooling 和RoI Align</p>
<p>RoI Pooling</p>
<p>将不同尺寸的提议框处理成相同尺寸，使之可以送入后续的全连接层计算分类和回归</p>
<ol type="1">
<li><p>将提议框切分成固定数目的格子（上图中2×2，实际常用7×7，对齐ResNet等经典结构）</p></li>
<li><p>如果格子边界不在整数坐标，则膨胀至整数坐标</p></li>
<li><p>在每个格子内部池化，得到固定尺寸的输出特征图</p></li>
</ol>
<p>RoI Align</p>
<p><img
src="https://camo.qiitausercontent.com/ad51aede3139b16e684fec813def4034b5763519/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3133393830392f64306366326635362d363866382d353836632d313436392d3233373666656338323964392e706e67" /></p>
<p>图片出处：https://qiita.com/yu4u/items/5cbe9db166a5d72f9eb8</p>
<p>• 将提议区域切成固定数目的格子，例如7×7<br />
• 在每个格子中，均匀选取若干采样点，如2×2=4 个<br />
• 通过插值方法得到每个采样点处的精确特征<br />
• 所有采样点做Pooling 得到输出结果</p>
<p>Faster R-CNN (2015)</p>
<p>增加了锚框Anchor的概念 以及从锚框到提议框的区域提议网络Region
Proposal Network</p>
<p>锚框Anchor</p>
<p>在原图上设置不同尺寸的基准框，称为锚框，基于特征独立预测每个锚框中是否包含物体<br />
① 可以生成不同尺寸的提议框<br />
② 可以在同一位置生成多个提议框覆盖不同物体</p>
<p>多尺度方法</p>
<p>使用固定大小的卷积后的特征图预测不同尺度的物体效果比较差(特征图越小空间分辨率就越低预测小物体就会困难)
所以有应对不同尺度物体的方法</p>
<p>图像金字塔Image Pyramid</p>
<p>比较直觉的方法 把一张图片 缩放成不同大小图分别检测
就像使用不同度数的镜头看图会看到不同的物体。</p>
<p>优势：算法不经改动可以适应不同尺度的物体<br />
劣势：计算成本成倍增加</p>
<p>层次化特征</p>
<p>基于主干网络自身产生的多级特征图产生预测结果<br />
由于不同层的感受大小不同，因此不同层级的特征天然适用于检测不同尺寸的物体</p>
<p>优势：计算成本低<br />
劣势：低层特征抽象级别不够，预测物体比较困难</p>
<p>特征金字塔网络Feature Pyramid Network (2016)<br />
在层次化特征基础上
对低层特征用特征求和融入高层特征补充低层特征的语义信息</p>
<p>单阶段目标检测算法</p>
<p>One-Stage Detectors</p>
<p>正负样本不均衡问题</p>
<p>单阶段算法需要为每个位置的每个锚框预测一个类别，训练时需要为每个预测计算分类损失<br />
图中锚框的数量远远大于真值框（数万vs
数个），大量锚框的预测真值为背景（负样本）</p>
<p>使用类别不平衡的数据训练出的分类器倾向给出背景预测，导致漏检</p>
<p>锚框vs 无锚框</p>
<p>基于锚框（Anchor-based）<br />
• Faster R-CNN、YOLO v3 / v5、RetinaNet 都是基于锚框的检测算法<br />
•
模型基于特征预测对应位置的锚框中是否有物体，以及精确位置相对于锚框的偏移量<br />
•
需要手动设置锚框相关的超参数（如大小、长宽比、数量等），设置不当影响检测精度❌</p>
<p>无锚框（Anchor-free）<br />
•
不依赖锚框，模型基于特征直接预测对应位置是否有物体，以及边界框的位置<br />
• 边界框预测完全基于模型学习，不需要人工调整超参数✔️<br />
• YOLO v1
是无锚框算法，但由于提出时间较早，相关技术并不完善，性能不如基于锚框的算法</p>
<h2 id="目标检测模型的评估方法">目标检测模型的评估方法</h2>
<p>正确结果(True Positive
TP)：算法检测到了某类物体(Positive)，图中也确实有这个物体，检测结果正确(True)<br />
假阳性(False Positive
FP)：算法检测到了某类物体(Positive)，但图中其实没有这个物体，检测结果错误(False)<br />
假阴性(False Negative
FN)：算法没有检测到物体(Negative)，但图中其实有某类物体，检测结果错误(False)</p>
<p>检测到的衡量标准：对于某个检测框，图中存在同类型的真值框且与之交并比大于阈值（通常取0.5）</p>
<h3 id="准确率precision-与召回率recall">准确率Precision
与召回率Recall</h3>
<p>召回率recall =正确结果总数/真值框总数=#TP/#TP + #FN</p>
<p>准确率precision =正确结果总数/检测框总数=#TP/#TP + #FP</p>
<p>两种极端情况：<br />
1.
检测器将所有锚框都判断为物体：召回率≈100%，但大量背景框预测为物体，FP很高，准确率很低</p>
<ol start="2" type="1">
<li>检测器只输出确信度最高的1个检测框：以很大概率检测正确，准确率=100%，但因为大量物体被预测<br />
为背景，FN很高，召回率很低</li>
</ol>
<p>一个完美的检测器应该有100%召回率和100%的精度；在算法能力有限的情况下,应该平衡二者<br />
通常做法：将检测框按置信度排序， 仅输出置信度最高的若干个框<br />
置信度= 分类概率，或修正后的分类概率（YOLO、FCOS）</p>
<h3 id="pr-曲线与ap-值">PR 曲线与AP 值</h3>
<p><img
src="https://www.jeremyjordan.me/content/images/2018/12/calculated-PR-curve-1.png" /></p>
<p>图片出处
https://www.jeremyjordan.me/evaluating-image-segmentation-models/</p>
<p>为得到阈值无关的评分，可以遍历阈值，并对Precision 和Recall 求平均</p>
<p>具体做法：</p>
<ul>
<li>检测框按置信度排序，取前K 个框计算Precision 和<br />
Recall</li>
<li>遍历K 从1 至全部检测框，将得到的Precision 和<br />
Recall 值绘制在坐标系上，得到PR 曲线</li>
<li>定义Average Precision = Precision 对Recall 的平均<br />
值，即PR 曲线下的面积，作为检测器的性能衡量指标</li>
</ul>
]]></content>
      <tags>
        <tag>OpenMMLab</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenMMLab实战营第三课 图像分类代码实战与超算平台介绍</title>
    <url>/post/b64f8831.html</url>
    <content><![CDATA[<h1 id="pytorch简单代码结构展示">Pytorch简单代码结构展示</h1>
<span id="more"></span>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> ToTensor</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download training data from open datasets.</span></span><br><span class="line">training_data = datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;data&quot;</span>,</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=ToTensor(),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download test data from open datasets.</span></span><br><span class="line">test_data = datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;data&quot;</span>,</span><br><span class="line">    train=<span class="literal">False</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=ToTensor(),</span><br><span class="line">)</span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create data loaders.</span></span><br><span class="line">train_dataloader = DataLoader(training_data, batch_size=batch_size)</span><br><span class="line">test_dataloader = DataLoader(test_data, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> test_dataloader:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Shape of X [N, C, H, W]: <span class="subst">&#123;X.shape&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Shape of y: <span class="subst">&#123;y.shape&#125;</span> <span class="subst">&#123;y.dtype&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># Get cpu or gpu device for training.</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;mps&quot;</span> <span class="keyword">if</span> torch.backends.mps.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Using <span class="subst">&#123;device&#125;</span> device&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define model</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNetwork</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line">        self.linear_relu_stack = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">28</span>*<span class="number">28</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        logits = self.linear_relu_stack(x)</span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line">model = NeuralNetwork().to(device)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"><span class="comment">## Define loss funtion and Optimizer</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">dataloader, model, loss_fn, optimizer</span>):</span><br><span class="line">    size = <span class="built_in">len</span>(dataloader.dataset)</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> batch, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        X, y = X.to(device), y.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute prediction error</span></span><br><span class="line">        pred = model(X)</span><br><span class="line">        loss = loss_fn(pred, y)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Backpropagation</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> batch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            loss, current = loss.item(), batch * <span class="built_in">len</span>(X)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;loss: <span class="subst">&#123;loss:&gt;7f&#125;</span>  [<span class="subst">&#123;current:&gt;5d&#125;</span>/<span class="subst">&#123;size:&gt;5d&#125;</span>]&quot;</span>)</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">dataloader, model, loss_fn</span>):</span><br><span class="line">    size = <span class="built_in">len</span>(dataloader.dataset)</span><br><span class="line">    num_batches = <span class="built_in">len</span>(dataloader)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    test_loss, correct = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> dataloader:</span><br><span class="line">            X, y = X.to(device), y.to(device)</span><br><span class="line">            pred = model(X)</span><br><span class="line">            test_loss += loss_fn(pred, y).item()</span><br><span class="line">            correct += (pred.argmax(<span class="number">1</span>) == y).<span class="built_in">type</span>(torch.<span class="built_in">float</span>).<span class="built_in">sum</span>().item()</span><br><span class="line">    test_loss /= num_batches</span><br><span class="line">    correct /= size</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Test Error: \n Accuracy: <span class="subst">&#123;(<span class="number">100</span>*correct):&gt;<span class="number">0.1</span>f&#125;</span>%, Avg loss: <span class="subst">&#123;test_loss:&gt;8f&#125;</span> \n&quot;</span>)</span><br><span class="line">    </span><br><span class="line">epochs = <span class="number">5</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;t+<span class="number">1</span>&#125;</span>\n-------------------------------&quot;</span>)</span><br><span class="line">    train(train_dataloader, model, loss_fn, optimizer)</span><br><span class="line">    test(test_dataloader, model, loss_fn)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Done!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Saving Models</span></span><br><span class="line">torch.save(model.state_dict(), <span class="string">&quot;model.pth&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Saved PyTorch Model State to model.pth&quot;</span>)</span><br><span class="line"><span class="comment"># Deployment</span></span><br><span class="line"><span class="comment"># loading Models</span></span><br><span class="line">model = NeuralNetwork()</span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&quot;model.pth&quot;</span>))</span><br><span class="line"><span class="comment">#Predict new images</span></span><br><span class="line">classes = [</span><br><span class="line">    <span class="string">&quot;T-shirt/top&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Trouser&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Pullover&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Dress&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Coat&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Sandal&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Shirt&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Sneaker&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Bag&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Ankle boot&quot;</span>,</span><br><span class="line">]</span><br><span class="line"><span class="comment">#没有归一化</span></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">x, y = test_data[<span class="number">0</span>][<span class="number">0</span>], test_data[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    pred = model(x)</span><br><span class="line">    predicted, actual = classes[pred[<span class="number">0</span>].argmax(<span class="number">0</span>)], classes[y]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Predicted: &quot;<span class="subst">&#123;predicted&#125;</span>&quot;, Actual: &quot;<span class="subst">&#123;actual&#125;</span>&quot;&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h1 id="openmmlab里是怎么做的">OpenMMLab里是怎么做的</h1>
<p>OpenMMLab 项目中的重要概念--配置文件 比pytorch更简单的的方式
通过它OpenMMLab可以还原回pytorch代码</p>
<p>深度学习模型的训练涉及几个方面:</p>
<ul>
<li>模型结构模型 有几层、每层多少通道数等等</li>
<li>数据集
用什么数据训练模型:数据集划分、数据文件路径、数据增强策略等等</li>
<li>训练策略 梯度下降算法、学习率参数、batch
size训练总轮次、学习率变化策略等等</li>
<li>运行时 GPU、分布式环境配置等等</li>
<li>一些辅助功能 如打印日志、定时保存checkpoint等等</li>
</ul>
<h1 id="一些问题和回答整理">一些问题和回答整理</h1>
<p>只记录了一些我感兴趣的问题和回答（并不是原话经过整理）</p>
<p><strong>问题</strong>： 输入图片的尺寸可以不固定吗？</p>
<p><strong>回答</strong>： 对于早期的存在全链接层的卷积神经网络必须
输入图像是固定的，而后续一些下经网络（如ResNet）用了全局平均池化
，代替了全连接层所以不限制图像尺寸。</p>
<p><strong>问题</strong>：
神经网络也需要像人一样使用多种感官感知吗？</p>
<p><strong>回答</strong>： 为了更好感知信息神经网络确实需要这样的策略
如多模态学习。</p>
<p><strong>问题</strong>： 出现分类错误 如何修改错误？</p>
<p><strong>回答</strong>： 可以通过可解释学习 来了解
程序哪里出了错。</p>
<h1
id="超算平台应用北京超级云计算中心">超算平台应用（北京超级云计算中心）</h1>
<p>登录官网下载客户端</p>
<p>利用云桌面平台</p>
<p>先用ssh 选择合适的分区（N30分区）</p>
<p>界面目录 cd run 分配了300G内存</p>
<p>查看模块</p>
<p><code>module avail</code></p>
<h3 id="搭建环境">搭建环境</h3>
<p>创建环境</p>
<p><code>module load anaconda/2021.05</code></p>
<p><code>conda create --name mmclassification python=3.8</code></p>
<p>激活环境</p>
<p><code>source activate mmclassification</code></p>
<p>加载cuda/11.1</p>
<p><code>module load cuda/11.1</code></p>
<p>安装pytorch 通过pip安装CUDA不能低于 11.1 不推荐用conda装</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html</span><br></pre></td></tr></table></figure>
<p>安装 mmcv-full 模块，mmcv-full 模块安装时候需要注意 torch 和 cuda
版本。参考<a
href="https://mmcv.readthedocs.io/en/latest/get_started/installation.html">这里</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install mmcv-full==1.7.0 -f</span><br><span class="line">https://download.openmmlab.com/mmcv/dist/cu111/torch1.10/index.html</span><br></pre></td></tr></table></figure>
<p>安装 openmmlab/mmclassification
模块，建议通过下载编译的方式进行安装；安装该模块需要 gcc ≥ 5，使用
module 加载一个 gcc ，例如 module load gcc/7.3</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载 gcc/7.3 模块</span></span><br><span class="line"> module load gcc/7.3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">git 下载 mmclassification 代码</span></span><br><span class="line"> git clone https://github.com/openmmlab/mmclassification.git</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">编译安装</span></span><br><span class="line"> cd mmclassification</span><br><span class="line"> pip install -e .</span><br></pre></td></tr></table></figure>
<p>总结环境信息，可以使用 module list
查看当前环境中加载的依赖模块，如下：</p>
<p><code>module list</code></p>
<p>准备 shell 脚本，将环境信息预先保存在脚本中。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">加载模块</span></span><br><span class="line">module load anaconda/2021.05</span><br><span class="line">module load cuda/11.1</span><br><span class="line">module load gcc/7.3</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">激活环境</span></span><br><span class="line">source activate mmclassification</span><br></pre></td></tr></table></figure>
<p>使用快传传输本地数据集到超算 创建data目录存放</p>
<h3 id="划分数据集">划分数据集</h3>
<p>自己写的脚本文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mymkdir</span>(<span class="params">file</span>):</span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file):</span><br><span class="line">            os.mkdir(file)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getData</span>(<span class="params">dirPath</span>):</span><br><span class="line">    subDirs=os.listdir(dirPath)</span><br><span class="line">    mymkdir(os.path.join(dirPath,<span class="string">&#x27;data&#x27;</span>))</span><br><span class="line">    destdir=os.path.join(dirPath,<span class="string">&#x27;data&#x27;</span>,<span class="string">&#x27;val&#x27;</span>)</span><br><span class="line">    mymkdir(destdir)</span><br><span class="line">    destdir2=os.path.join(dirPath,<span class="string">&#x27;data&#x27;</span>,<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">    mymkdir(destdir2)</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">dir</span> <span class="keyword">in</span> subDirs:</span><br><span class="line">        tempDir=os.path.join(dirPath,<span class="built_in">dir</span>)</span><br><span class="line">        destdirnow=os.path.join(destdir,<span class="built_in">dir</span>)</span><br><span class="line">        destdirnow2=os.path.join(destdir2,<span class="built_in">dir</span>)</span><br><span class="line">        mymkdir(destdirnow)</span><br><span class="line">        mymkdir(destdirnow2)</span><br><span class="line">        fs=os.listdir(tempDir)</span><br><span class="line">        random.shuffle(fs)</span><br><span class="line">        le=<span class="built_in">int</span>(<span class="built_in">len</span>(fs)*<span class="number">0.8</span>)  <span class="comment">#这个可以修改划分比例</span></span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> fs[le:]:</span><br><span class="line">            shutil.move(os.path.join(tempDir,f), destdirnow)</span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> fs[:le]:</span><br><span class="line">            shutil.move(os.path.join(tempDir,f), destdirnow2)</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#print(os.path.join(os.getcwd(),&#x27;flower_dataset&#x27;))</span></span><br><span class="line">getData(os.path.join(os.getcwd(),<span class="string">&#x27;flower_dataset&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="mmcls-配置文件">MMCls 配置文件</h3>
<p><code>mkdir configs/resnet18</code></p>
<p><code>cp ~/run/opnemmlab/resnet18_b32_flower.py ./configs/resnet18/</code></p>
<p>按要求修改配置文件</p>
<h3 id="提交计算">提交计算</h3>
<p>准备作业脚本</p>
<p>取消计算</p>
<p><code>scancel 279704 # 279704 为作业ID</code></p>
<p>查看GPU利用率</p>
<p>在提交作业之后，使用 parajobs 或 squeue 查看作业的第八列
NODELIST（REASON）对于运行作业（R状态）显示作业使用的节点列表</p>
<p><code>squeue</code></p>
<p>查看到使用的节点列表之后，使用 ssh [节点] 进入GPU环境，执行
nvidia-smi 可查看 GPU 利用率。</p>
<p><code>ssh g0004 #g0004节点</code></p>
<p><code>nvidia-smi</code></p>
]]></content>
      <tags>
        <tag>OpenMMLab - 计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenMMLab实战营第二课 计算机视觉之图像分类算法基础</title>
    <url>/post/a3e368ef.html</url>
    <content><![CDATA[<p>有点事 先简单写一下 晚上完善</p>
<span id="more"></span>
<p>传统方法： 设计图像特征（1990—2000)<br />
人工设置特征 保留图像这种特征 以简化数据表达 从而可以计算分类 。<br />
特征工程的天花板<br />
在ImageNet 图像识别挑战赛里，2010 和2011
年的冠军队伍都使用了经典的视觉方法，基于手工设计的特征+
机器学习算法实现图像分类，Top-5 错误率在25% 上下。<br />
传统的特征工程由于人工设置受限存在性能瓶颈。<br />
于是有人提出了 利用机器直接学习提取用于分类的特征的方法<br />
卷积实现一步特征提取👉 卷积神经网络</p>
<ol type="1">
<li><p>特征和图像一样具有二维空间结构</p></li>
<li><p>后层特征为空间邻域内前层特征的加权求和<br />
多头注意力实现一步特征提取👉 Transformer<br />
AlexNet 的诞生&amp; 深度学习时代的开始<br />
在2012
年的竞赛中，来自多伦多大学的团队首次使用深度学习方法，一举将错误率降低至15.3%
，而传统视觉算法的性能已经达到瓶颈，2015
年，卷积网络的性能超越人类。</p></li>
<li><p>模型设计：设计适合图像的<span
class="math inline">\(𝐹_Θ(𝑋)\)</span>模型 例子如下<br />
• 卷积神经网络<br />
• 轻量化卷积神经网络<br />
• 神经结构搜索<br />
• Transformer</p></li>
<li><p>模型学习：求解一组好的参数Θ<br />
• 监督学习：基于标注数据学习<br />
• 损失函数<br />
• 随机梯度下降算法<br />
• 视觉模型常用训练技巧<br />
• 自监督学习：基于无标注的数据学习</p></li>
</ol>
<h2 id="卷积神经网络发展">卷积神经网络发展</h2>
<p>AlexNet (2012)<br />
Going Deeper (2012~2014)<br />
VGG (2014)<br />
残差网络ResNet (2015)<br />
神经结构搜索Neural Architecture Search (2016+)<br />
Vision Transformers (2020+)<br />
ConvNeXt (2022)</p>
<h2 id="轻量化卷积神经网络">轻量化卷积神经网络</h2>
<p>GoogLeNet 使用不同大小的卷积核
基本思路：并不是所有特征都需要同样大的感受野，在同一层中混合使用不同尺寸的特征可以减少参数量<br />
ResNet 使用1×1卷积压缩通道数<br />
可分离卷积 将常规卷积分解为逐层卷积和逐点卷积，降低参数量和计算量
MobileNet V1/V2/V3 (2017~2019)<br />
ResNeXt 将ResNet 的bottleneck block 中3×3
的卷积改为分组卷积，降低模型计算量<br />
可分离卷积为分组卷积的特殊情形，组数=通道数</p>
<h2 id="模型学习">模型学习</h2>
<center>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/%E5%9F%BA%E4%BA%8E%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B.png"/>
</center>
<center>
<b><font size ='2'>模型训练流程图</font></b>
</center>
<p></font></p>
<p>目标：确定模型<span class="math inline">\(𝐹_\Theta\)</span>
的具体形式后，找寻最优参数<span
class="math inline">\(\Theta^\ast\)</span> ，使得模型<span
class="math inline">\(𝐹_{\Theta^\ast}(x)\)</span>
给出准确的分类结果<span class="math inline">\(𝑃(𝑦|x)\)</span></p>
<h3 id="监督学习">监督学习</h3>
<pre class="mermaid">

graph LR;
0[真值y]---1[损失L]
A[图像]---B[模型$F_θ$]
B---C[概率P]
C---1

</pre>
<ol type="1">
<li><p>标注一个数据集<span
class="math inline">\(\mathcal{D}=\left\{\left(X_i,
y_i\right)\right\}_{i=1}^N\)</span></p></li>
<li><p>定义损失函数<span class="math inline">\(L:[0,1]^K \times
\mathbb{N} \rightarrow
\mathbb{R}\)</span>，衡量单个预测结果的"好/坏"</p></li>
<li><p>解一个最优化问题，寻找使得总损失最小的参数<span
class="math inline">\(\Theta^\ast\)</span><br />
<span class="math display">\[
\Theta^*=\underset{\Theta}{\arg \min } \sum_{i=1}^N
L\left(F_{\Theta}\left(X_i\right), y_i\right)
\longrightarrow梯度下降法+针对视觉问题的技巧和策略
\]</span></p></li>
</ol>
<p>优化参数用 随机梯度下降算法（SGD）</p>
<ol type="1">
<li><p>随机初始化参数<span class="math inline">\(Θ^{( 0)}\)</span></p>
<ul>
<li>按照均与分布 或者高斯分布 <span class="math inline">\(W_{ij},b_i
\sim U \left(-a,a \right)\)</span> or <span class="math inline">\(W_{i
j}, b_i \sim \mathcal{N}\left(0, \sigma^2\right)\)</span></li>
<li>or Xavier 方法(2010)：前传时维持激活值的方差，反传维持梯度的方差
没懂</li>
<li>Kaiming 方法(2015)：同上，但针对ReLU 激活函数 还是没懂orz</li>
<li>或者用训练好的模型参数（通常基于ImageNet 数据集）
替换预训练模型的分类头，进行微调训练(finetune)</li>
</ul></li>
<li><p>随机选取数据子集ℬ，计算近似损失𝐿( Θ|ℬ)</p></li>
<li><p>前向+反向传播，计算梯度<span class="math inline">\(∇_Θ𝐿(Θ^{𝑡−1}
|ℬ)\)</span></p></li>
<li><p>更新参数<span class="math inline">\(Θ ^{(𝑡)} = Θ^ {(𝑡−1)} −
𝜂∇_Θ𝐿(Θ ^{(𝑡−1)} |ℬ)\)</span></p></li>
<li><p>不断重复2-3知道收敛</p></li>
</ol>
<h3 id="学习率对训练的影响">学习率对训练的影响</h3>
<p><img
src="http://www.bdhammel.com/assets/learning-rate/lr-types.png" /></p>
<p>训练初期可使用较大的学习率(or
在训练前几轮学习率逐渐上升，直到预设的学习率，以稳定训练的初始阶段<span
class="math inline">\(\eta_t=\frac{t}{T_0}𝜂_0(t\leq
T_0)\)</span>)损失函数稳定后下降学习率：<br />
- 按步长下降</p>
<ul>
<li><p>按比例下降<span
class="math inline">\(\eta_t=𝜂_0𝑒^{−𝑘𝑡}\)</span></p></li>
<li><p>按倒数下降 <span
class="math inline">\(\eta_t=\frac{𝜂_0}{\epsilon+t}\)</span></p></li>
<li><p>按余弦函数下降 <span class="math inline">\(\eta_t=\eta_{\min
}^i+\frac{1}{2}\left(\eta_{\max }^i-\eta_{\min }^i\right)\left(1+\cos
\left(\frac{T_{\mathrm{cur}}}{T_i} \pi\right)\right)\)</span></p></li>
</ul>
<h3 id="动量momentum-sgd">动量Momentum SGD</h3>
<h3 id="自适应梯度算法">自适应梯度算法</h3>
<h3 id="正则化与权重衰减weight-decay">正则化与权重衰减Weight Decay</h3>
<h3 id="数据增强data-augmentation">数据增强Data Augmentation</h3>
<p>训练泛化性好的模型，需要大量多样化的数据，<br />
而数据的采集标注是有成本的</p>
<p>图像可以通过简单的变换产生一系列"副本"，扩<br />
充训练数据集</p>
<p>数据增强操作可以组合，生成变化更复杂的图像</p>
<ul>
<li>几何变换</li>
<li>色彩变换</li>
<li>随机遮挡</li>
</ul>
<h3 id="组合数据增强autoaugment-randaugment">组合数据增强AutoAugment
&amp; RandAugment</h3>
<p>AutoAugment 借助强化学习，搜索数据增强的组合策略</p>
<p>RandAugment 更简单的搜索空间：随机选取N
个数据增强操作组合，幅度为M</p>
<p>Mixup 逐像素混合图像</p>
<p>CutMix 遮盖原图并用另一幅图填充</p>
<h3 id="标签平滑label-smoothing">标签平滑Label Smoothing</h3>
<p>动机：类别标注可能错误或不准确，让模型最大限度拟合标注类别可能会有碍于泛化性<br />
做法：引入平滑参数𝜀，降低标签的"自信程度"</p>
<p>传统的one-hot 标签：<span class="math inline">\(P_i= \begin{cases}1,
&amp; i=y \\ 0, &amp; i \neq y\end{cases}\)</span></p>
<p>平滑标签：<span class="math inline">\(P_i=\left\{\begin{array}{cl}
1-\varepsilon, &amp; i=y \\ \frac{\varepsilon}{K-1}, &amp; i \neq y
\end{array}\right.\)</span></p>
<p>其中，𝐾 为类别总数</p>
<h3 id="丢弃层dropout">丢弃层Dropout</h3>
<p>神经网络在训练时会出现共适应现象(co-adaption)，神经元之间产生高度关联，导致过拟合<br />
训练时随机丢弃一些连接，破坏神经元之间的关联，鼓励学习独立的特征<br />
推理时使用全部连接<br />
常用于全连接层，通常不与BN 混用</p>
<h3 id="自监督学习">自监督学习</h3>
<pre class="mermaid">

graph LR;
B-.-&gt;B2
subgraph part 1
A3[由图像自身产生的标签y^ ]---3[$L^\prime$]
A2[图像x]---B2[模型$F_θ$]
B2---C2[特征z ]
C2---D[辅助任务]
D---3
end

subgraph part 2

A[图像x]---B[模型$F_θ$]
B---C[特征z ]
C---D2[分类器]
D2---1[损失L]
0[真值y]---1

end


</pre>
<p>标注数据是昂贵的 我们希望程序自己标注好</p>
<ol type="1">
<li>通过恰当设计辅助任务，让模型在<strong>无标注</strong>数据集 <span
class="math inline">\(\mathcal{D}^\prime=\left\{X^\prime_i\right\}_{i=1}^N\)</span>上学习好的特征</li>
<li>再把模型放在一个相对小的标注数据集上<span
class="math inline">\(\mathcal{D}\)</span> 训练分类（可选）</li>
</ol>
<p>常见类型</p>
<ul>
<li>基于代理任务 https://zhuanlan.zhihu.com/p/150224914</li>
<li>基于对比学习 arXiv:2006.09882, 2020.</li>
<li>基于掩码学习arXiv:2111.06377, 2021</li>
</ul>
<p>Relative Location (ICCV 2015)
基本假设：模型只有很好地理解到图片内容，才能够预测图像块之间的关系</p>
<p>SimCLR (ICML 2020)
基本假设：如果模型能很好地提取图片内容的本质，那么无论图片经过什么样的数据增强操作，提取出来的特征都应该极为相似。</p>
<p>Masked autoencoders (MAE, CVPR 2022)
基本假设：模型只有理解图片内容、掌握图片的上下文信息，才能恢复出图片中被随机遮挡的内容。</p>
]]></content>
      <tags>
        <tag>OpenMMLab</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenMMLab实战营第一课  计算机视觉算法基础与OpenMMLab介绍</title>
    <url>/post/bd762e03.html</url>
    <content><![CDATA[<h1 id="计算机视觉简单介绍">计算机视觉简单介绍</h1>
<p>Computer Vision Tasks 通过计算机算法对图像视频等可视化的信息进行
数据挖掘模式识别特征提取等等操作</p>
<h2 id="计算机视觉基本问题">计算机视觉基本问题</h2>
<ul>
<li><p>图像分类问题 (Classification or Classification Localization)
输入一张图 输出其分类（只限于单一对象）</p></li>
<li><p>目标检测 (Object Detection) 每个物体用框框来且给出其类别信息
（多对象）</p></li>
<li><p>图像分割(Segmentation) 精确的划分物体边缘
且给出其类别信息(多对象)分割有两类:语义分割(Semantic
Segmentation)直接对每个像素进行分类、实例分割(Instance
Segmentation)不仅分出像素还识别出叠在一起的物体。</p></li>
</ul>
<span id="more"></span>
<h2 id="计算机视觉应用">计算机视觉应用</h2>
<ul>
<li><p>各种目标检测 通用目标检测（识别大千万物）
特殊目标检测（如人脸识别 路牌识别）</p></li>
<li><p>无人驾驶 中的视觉感知部分</p></li>
<li><p>对遥感卫星图片进行语义分割</p></li>
<li><p>图像生成、风格迁移：从一张图片生成一张内容类似但风格不同的图像</p></li>
<li><p>虚拟主播人脸关键点检测</p></li>
<li><p>视频理解自动剪辑</p></li>
</ul>
<h2 id="计算机视觉发展历史">计算机视觉发展历史</h2>
<ul>
<li><p>早期萌芽 1960-1980 边缘提取 以及有人提出如何识别3维世界Machine
perceptionof 3d solids Larry Roberts 1964 三维的视觉计算理论David Marr
1982</p></li>
<li><p>统计机器学习于模式识别（1990-2000） Eigen Face Turk &amp;
Pentland 1991 VJ人脸检测Viola &amp; Jones 2001</p></li>
<li><p>ImageNet 大型数据库（2006）斯坦福大学的李飞飞教授于2006
年启动了ImageNet
项目，旨在为计算机视觉算法研究提供一个大规模、优质的图片数据库，ImageNet
迄今包含约2万类，共计约1500 万张图片<br />
自2010 年起ImageNet 官方举办了一年一度的大规模视觉识别挑战赛
LSVRC，图像分类赛道要求参赛组在一个包含1000类别、100万张图像的ImageNet
子集上完成图像分类任务</p></li>
<li><p>初有成效的视觉系统（-2010）ImageNet Classification72% Top-5
Accuracy NEC-UIUC 2010 、Deformable Part Modelfor object detection
但底层还是依赖人工定义特征机器只是告诉我们什么特征比较重要</p></li>
<li><p>深度学习的时代（2012-)让AI自主定义特征 AlexNet。
突破传统视觉系统性能 、Fast R-CNN 目标检测走入深度学习时代
、深度生成对抗网络实现图像生成</p></li>
</ul>
<h1 id="openmmlab简介">OpenMMLab简介</h1>
OpenMMLab
是一个适用于学术研究和工业应用的开源项目，涵盖了计算机视觉的许多研究课题，如：图像分类、目标检测、目标分割、超分辨率图像生成等<br />

<table>
<tr>
<td>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/OpenMMLab%E6%80%BB%E4%BD%93%E4%B8%80%E8%A7%88.png"border=0>
</td>
<td>
<img src="https://cdn.jsdelivr.net/gh/catcooc/catcoocblogimg@main/img/OpenMMLab%E9%83%A8%E7%BD%B2%E4%B8%80%E4%BD%93%E5%8C%96.png" border=0>
</td>
</tr>
</font>
</table>
<p>MMDeploy可以把算法库训练得到的模型转换成开发者想要的格式
部署在各种平台<br />
## 算法框架介绍</p>
<ul>
<li>MMDetection 支持目标检测 实例分割
全景分割（在实例分割基础上把背景也抠进来 对无人驾驶很重要）</li>
<li>MMDetection3D 用于3D目标检测 通过点云数据 或者说纯视觉数据
来画出物体3d的框</li>
<li>MMClassification 图像分类库</li>
<li>MMSegmentation 用于语义分割</li>
<li>MMPose &amp;MMHumam3D 2维的关键点检测和3维的立体重建
可以做体感游戏</li>
<li>MMTracking 可以追踪视频中的物体</li>
<li>MMAction2 对时序视频进行动作检测 可以实现行为识别</li>
<li>MMOCR 文本检测</li>
<li>MMEditing 在像素层面进行操作识别 如图像修复 抠图 图像生成
超分辨率</li>
</ul>
<h1 id="机器学习卷积神经网络基础知识">机器学习卷积神经网络基础知识</h1>
<h2 id="机器学习基础">机器学习基础</h2>
<h3 id="什么是机器学习">什么是机器学习？</h3>
<blockquote>
<p>”A computer program is said to learn from experience E with respect
to some class of tasks T andperformance measure P if its performance at
tasks in T, as measured by P, improves with experienceE“ --Tom
M.Mitchell (1997)</p>
</blockquote>
<p>从数据中学习经验，以解决特定问题</p>
<pre class="mermaid">graph TD
    问题---收集数据
    收集数据---拟合模型</pre>
<p>​</p>
<ul>
<li>监督学习</li>
<li>无监督学习</li>
<li>自监督学习</li>
<li>强化学习</li>
</ul>
<h2 id="机器学习中的分类问题">机器学习中的分类问题</h2>
<p>提取数据中的特征 拟合出一个边界来分类 边界的“弯” “直”
区分为线性分类器 非线性分类器</p>
<h3 id="机器学习的基本流程">机器学习的基本流程</h3>
<ol type="1">
<li>训练
我们需要采集一些数据，标注它们的类别，从中选取一部分用于训练分类器，得到一个可以用于分类的分类器</li>
<li>验证
从采集、标注的数据中另外选取一部分，测试所得分类器的分类精度验证所用的数据不能和训练重合，以保证分类器的泛化性能:在一部分数据上训练的分类器可以在其余的数据上表现出足够的分类精度</li>
<li>应用
将经过验证的分类器集成到实际的业务系统中，实现对应的功能在应用阶段，分类器面对的数据都是在训练、验证阶段没有见过的</li>
</ol>
<h2 id="神经网络的结构">神经网络的结构</h2>
<p>神经网络是一种 非线性的分类器</p>
<center>
单个神经元示意图
</center>
<pre class="mermaid">graph LR
A1((1)) -- b --> B((Σ))
A2((x1)) -- w1 --> B
A3((x2))-- w2 --> B
...
A4((xd))-- wd --> B
B-->C((Z))-->D((激活函数))-->f((y输出))</pre>
<p>多个神经元堆叠 就是神经网络</p>
<h2 id="神经网络的训练">神经网络的训练</h2>
<h2 id="卷积神经网络">卷积神经网络</h2>
<h2 id="pytorch环境配置与基础使用">Pytorch环境配置与基础使用</h2>
]]></content>
      <tags>
        <tag>OpenMMLab</tag>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能 现代方法 第三章读书笔记(持续更新）</title>
    <url>/post/49fc3cb6.html</url>
    <content><![CDATA[<h1 id="占个位置">占个位置</h1>
<span id="more"></span>
<h1 id="无信息搜索策略">3.4无信息搜索策略</h1>
<p>  无信息搜索算法不提供有关某个状态与目标状态的接近程度的任何线索。</p>
<h2 id="广度优先搜索breadth-first-search">广度优先搜索(breadth-first
search)</h2>
<hr />
<p><strong>function</strong> Breadth-First-Search(problem)
<strong>returns</strong> 一个解节点或 failure<br><br />
 node ← Node(problem.Initial)<br><br />
 <strong>if</strong> problem.Is-Goal(node.State) <strong>then
return</strong> node<br><br />
 frontier ← 一个FIFO队列，其中一个元素为node<br><br />
 reached ←{problem.Initial}<br><br />
 <strong>while not</strong> Is-Empty(frontier)
<strong>do</strong><br><br />
  node ← Pop(frontier)<br><br />
  <strong>for each</strong> child <strong>in</strong> Expand(problem,
node) <strong>do</strong><br><br />
   s ← child.State<br><br />
   <strong>if</strong> problem.Is-Goal(s) <strong>then return</strong>
child<br><br />
   <strong>if</strong> s不在reached中 <strong>then</strong><br><br />
    将s添加到reached<br><br />
    将child添加到frontier<br><br />
<strong>return</strong> failure<br></p>
<hr />
<p><strong>优先队列</strong>（priority queue）首先弹出根据评价函数f
计算得到的代价最小的节点。它被用于最佳优先搜索。</p>
<p><strong>FIFO 队列</strong>（FIFO
queue），即先进先出队列（first-in-first-out
queue），首先弹出最先添加到队列中的节点；它被用于广度优先搜索。</p>
<p><strong>LIFO 队列</strong>（LIFO
queue），即后进先出队列（last-in-first-out
queue），也称为栈（stack），首先弹出最近添加的节点；它被用于深度优先搜索。</p>
<h2 id="dijkstra-算法或一致代价搜索">Dijkstra 算法或一致代价搜索</h2>
<hr />
<p><strong>function</strong> Uniform-Cost-Search(problem)
<strong>returns</strong> 一个解节点或failure<br><br />
<strong>return</strong> Best-First-Search(problem, Path-Cost)<br></p>
<p><strong>function</strong> Best-First-Search(problem, f )
<strong>returns</strong> 一个解节点或 failure<br><br />
 node ← Node(State=problem.Initial)<br><br />
 frontier ← 一个以 f 排序的优先队列，其中一个元素为node<br><br />
 reached ←
一个查找表，其中一个条目的键为problem.Initial，值为node<br><br />
 <strong>while not</strong> Is-Empty(frontier)
<strong>do</strong><br><br />
  node ← Pop(frontier)<br><br />
  if problem.Is-Goal(node.State) then return node<br><br />
  for each child in Expand(problem, node) <strong>do</strong><br><br />
  s ← child.State<br><br />
  if s不在reached中 or child.Path-Cost reached[s].Path-Cost
then<br><br />
    reached[s] ← child<br><br />
    将child添加到frontier中<br><br />
<strong>return</strong> failure<br><br />
<strong>function</strong> Expand(problem, node) <strong>yields</strong>
节点<br><br />
 s ← node.State<br><br />
 <strong>for each</strong> action <strong>in</strong> problem.Actions(s)
<strong>do</strong><br><br />
  s' ← problem.Result(s, action)<br><br />
   cost ← node.Path-Cost + problem.Action-Cost(s, action, s')<br><br />
   <strong>yield</strong> Node(State=s', Parent=node, Action=action,
Path-Cost=cost)<br></p>
<hr />
<h2 id="深度优先搜索depth-first-search">深度优先搜索（depth-first
search）</h2>
<hr />
<p><strong>function</strong> Depth-Limited-Search(problem, ℓ)
<strong>returns</strong>一个解节点或failure cutoff //当ℓ=∞
就是深度优先搜索<br />
 frontier ←
一个LIFO队列（栈），其中一个元素为Node(problem.Initial)<br><br />
 result ← failure<br><br />
 <strong>while not</strong> Is-Empty(frontier)
<strong>do</strong><br><br />
  node ← Pop(frontier)<br><br />
  <strong>if</strong> problem.Is-Goal(node.State) then return
node<br><br />
  <strong>if</strong> Depth(node) ℓ <strong>then</strong><br><br />
   result ← cutoff<br><br />
  <strong>else if not</strong> Is-Cycle(node)
<strong>do</strong><br><br />
   <strong>for each</strong> child <strong>in</strong> Expand(problem,
node) <strong>do</strong><br><br />
    将child添加到frontier<br><br />
<strong>return</strong> result<br></p>
<p><strong>function</strong> Iterative-Deepening-Search(problem)
<strong>returns</strong> 一个解节点或failure<br><br />
 <strong>for</strong> depth = 0 to ∞ <strong>do</strong><br><br />
  result ← Depth-Limited-Search(problem, depth)<br></p>
<p><strong>if </strong> result <span class="math inline">\(\neq\)</span>
cutoff then <strong>return</strong> result<br></p>
<hr />
<h2 id="双向搜索">双向搜索</h2>
<p>  我们传入问题和评价函数的两个版本，一个是正向的（下标F），另一个是反向的（下标B）。当评价函数是路径代价时，找到的第一个解将是最优解，但是对于不同的评价函数，这一结论不一定是正确的。因此，我们会记录迄今为止找到的最优解，并且可能不得不多次更新最优解，直到Terminated
测试证明不可能再有<br />
更好的解。</p>
<hr />
<p><strong>function</strong> BiBF-Search(problemF, fF, problemB, fB)
<strong>returns</strong> 一个解节点或 failure<br><br />
 node_F ← Node(problem_F.initial) // 初始状态节点<br><br />
 node_B ← Node(problem_B.initial) // 目标状态节点<br><br />
 frontier_F ← 按f_F排序的优先队列，其中一个元素为node_F<br><br />
 frontier_B ← 按 f_B排序的优先队列，其中一个元素为node_B<br><br />
 reached_F ←
一个查找表，其中一个条目的键是node_F.State且值是node_F<br><br />
 reached_B ←
一个查找表，其中一个条目的键是node_B.State且值是node_B<br><br />
 solution ← failure<br><br />
 <strong>while not</strong> Terminated(solution, frontier_F, frontier_B)
<strong>do</strong><br><br />
  <strong>if</strong> f_F(Top(frontier_F)) f_B(Top(frontier_B))
<strong>then</strong><br><br />
   solution ← Proceed(F, problem_F , frontier_F , reached_F, reached_B,
solution)<br><br />
  <strong>else</strong> solution ← Proceed(B, problem_B, frontier_B,
reached_B, reached_F, solution)<br><br />
<strong>return </strong>solution<br></p>
<p><strong>function</strong> Proceed(dir, problem, frontier, reached,
reached2, solution) <strong>returns</strong>一个解<br><br />
/ / 在frontier上扩展节点，对照reached2中的另一个边界<br><br />
/ / 变量dir是方向：要么是F（代表正向），要么是B（代表反向）<br><br />
node ← Pop(frontier)<br><br />
<strong>for each</strong> child in Expand(problem, node) do<br><br />
 s ← child.State<br><br />
 <strong>if</strong> s不在 reached 中 or Path-Cost(child)
Path-Cost(reached[s]) <strong>then</strong><br><br />
  reached[s] ← child<br><br />
  //将child添加到frontier<br><br />
 if s不在reached2中 then<br><br />
  solution_2 ← Join-Nodes(dir, child, reached_2[s])<br><br />
  <strong>if</strong> Path-Cost(solution_2) Path-Cost(solution)
<strong>then</strong><br><br />
   solution ← solution_2<br><br />
<strong>return</strong> solution<br></p>
<hr />
<p>Terminated测试怎么实现？</p>
<table>
<colgroup>
<col style="width: 16%" />
<col style="width: 15%" />
<col style="width: 22%" />
<col style="width: 22%" />
<col style="width: 22%" />
</colgroup>
<thead>
<tr class="header">
<th>算法</th>
<th>采用队列和搜索</th>
<th>时间复杂度/空间复杂度</th>
<th>优点 /缺点</th>
<th>应用场景</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>广度优先搜索(breadth-first search)</td>
<td>先进先出总能得到新节点 图搜索</td>
<td><span class="math inline">\(O(b^d)\)</span><a href="#fn1"
class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></td>
<td>总能找到动作（深度）最少（浅）的解/需要很多内存和时间</td>
<td>所有动作的代价相同（把深度看作代价）</td>
</tr>
<tr class="even">
<td>Dijkstra 算法或一致代价搜索</td>
<td>优先队列 图搜索</td>
<td><span class="math inline">\(O(b^{1+C^*/ \epsilon})\)</span><a
href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a></td>
<td>一致代价搜索是完备的，也是代价最优的，因为它找到的第一个解的代价至少与边界上的任何其他节点的代价一样小。一致代价搜索会按照代价递增的顺序系统地考虑所有路径，而不会陷入一直沿单一无限路径探索的困境。</td>
<td>动作代价不同时（累加从根节点到当前节点的代价）</td>
</tr>
<tr class="odd">
<td>深度优先搜索（depth-first search）</td>
<td>树状搜索（不维护已达状态表）</td>
<td><span class="math inline">\(O(b^m)\)</span>/<span
class="math inline">\(O(bm)\)</span></td>
<td>内存小/不是最优解 且不完备容易陷入循环</td>
<td>节约内存</td>
</tr>
<tr class="even">
<td>回溯搜索（backtracking search）</td>
<td>树状搜索</td>
<td><span class="math inline">\(O(b^m)\)</span>/<span
class="math inline">\(O(m)\)</span></td>
<td>节省大量资源，通过回溯，我们还可以为当前路径上的状态维护一个有效的集合数据结构，从而使检查循环的时间从<span
class="math inline">\(O(m)\)</span> 减少到<span
class="math inline">\(O(1)\)</span>。</td>
<td>回溯对许多具有大型状态描述的问题（例如机器人组装）的成功求解至关重要。</td>
</tr>
<tr class="odd">
<td>深度受限搜索（depth-limited search）</td>
<td>树状搜索（不维护已达状态表）设置深度界限ℓ</td>
<td><span class="math inline">\(O(b^ℓ)\)</span>/<span
class="math inline">\(O(bℓ)\)</span></td>
<td></td>
<td>深度优先搜索的改进版本</td>
</tr>
<tr class="even">
<td>迭代加深搜索（iterative deepening search）</td>
<td></td>
<td>存在解时<span class="math inline">\(O(b^d)\)</span>/<span
class="math inline">\(O(bd)\)</span>不存在解时<span
class="math inline">\(O(b^m)\)</span> / <span
class="math inline">\(O(bm)\)</span></td>
<td>在搜索树顶端状态会被重复生成</td>
<td>解决了如何选择一个合适的的问题</td>
</tr>
<tr class="odd">
<td>双向搜索（bidirectional search）</td>
<td></td>
<td></td>
<td></td>
<td><span class="math inline">\(b^{d/2}+b^{d/2}\)</span>要比<span
class="math inline">\(b^d\)</span>小得多</td>
</tr>
</tbody>
</table>
<h1 id="有信息启发式搜索策略">3.5 有信息（启发式）搜索策略</h1>
<p>  引入启发式函数（heuristic function) h(n) = 从节点n
的状态到目标状态的最小代价路径的代价估计值（它的来源后面的章节回讲）</p>
<h2
id="贪心最佳优先搜索greedy-best-first-search">贪心最佳优先搜索（greedy
best-first search）</h2>
<p>  使用最优先搜索的方式 去评价函数f(n)=h(n)。例如寻径问题
我们用两地的直线距离<span
class="math inline">\(h_{SLD}\)</span>作为启发函数。对于这一特定问题，使用<span
class="math inline">\(h_{SLD}\)</span>的贪心最佳优先搜索无须扩展不在解路径上的节点就找到了解。但是，它找到的解并不是代价最优的。它保证了每一步最优但无法保证全局最优。其在有限空间是完备的，在无限空间是不完备的。最坏情况下时间复杂性和空间复杂性为O(|v|),
采用一个好的启发式函数，复杂性可以降低到O(bm)。</p>
<h2 id="aast搜索aast-search"><span
class="math inline">\(A^\ast\)</span>搜索（<span
class="math inline">\(A^\ast\)</span> search）</h2>
<p>  <span class="math inline">\(A^\ast\)</span>
搜索也是一种最佳优先搜索 评价函数取 f(n)= g(n)+h(n)。
g(n)是从初始状态到节点n的路径代价，h(n)是从节点n
到一个目标状态的最短路径的代价估计值。</p>
<p><span class="math inline">\(A^\ast\)</span> 搜索是完备的的
。它是否是代价最优则取决于启发式函数的性质。</p>
<p>可容许性（admissibility）一个可容许的启发式（admissible
heuristic）函数永远不会高估到达某个目标的代价</p>
<p>一致性（consistency）<span class="math inline">\(h(n) \leq
c(n,a,n^\prime)+h(n^\prime)\)</span></p>
<pre class="mermaid">

graph LR
A((n))--&quot;c(n,a,n&#39;)&quot;--&gt; B((n&#39;))
B -.&quot;h(n&#39;)&quot;.-&gt; f
A -.&quot;h(n)&quot;.-&gt; f((G_n&#39;))

</pre>
<p>  一致的启发式函数都是可容许的（反过来不成立）。使用一致的启发函数
A*搜索的解总是最优的且第一次到达的状态就是最优解的路径。</p>
<p>  搜索等值线
一种对搜索进行可视化的方法是在状态空间中绘制等值线（contour），就像在地形图中绘制等高线一样。</p>
<p>  <span
class="math inline">\(A^\ast\)</span>之所以高效，是因为它会对那些对于寻找最优解没有帮助的搜索树节点进行剪枝（pruning）。对许多人工智能领域来说，剪枝（不必进行检查就可以排除不正确的答案）非常重要。需要注意的是<span
class="math inline">\(A^\ast\)</span>并不适用与所有搜索需求，它可能受困于过多的扩展节点数。</p>
<h2
id="满意搜索不可容许的启发式函数与加权aast-搜索">满意搜索：不可容许的启发式函数与加权<span
class="math inline">\(A^\ast\)</span> 搜索</h2>
<p>  虽然 <span
class="math inline">\(A^\ast\)</span>算法可以找到最优的解
但是代价需要扩展大量节点
，如果我们退而求其次,接受一个来自不可容许（但更准确）的启发函数带来的次优的解,将花费更少的时间和空间的代价，这样的解我们也称之为满意的解。</p>
<p>  我们采用一种称为加权<span
class="math inline">\(A^\ast\)</span>搜索（weighted <span
class="math inline">\(A^\ast\)</span>
search）的方法，对启发式函数的值进行更重的加权，评价函数为<span
class="math inline">\(f(n) = g(n) + W × h(n)\)</span>，其中<span
class="math inline">\(W\geq1\)</span>。一般会找到一个介于<span
class="math inline">\(W\times C^\ast\)</span>与<span
class="math inline">\(C^\ast\)</span>之间的解。这种方法也被成为有界次优搜索（bounded
suboptimal search），与之相反还存在无界代价搜索（unbounded-cost
search），我们接受任何代价的解，只要能快速找到它。</p>
<h2 id="内存受限搜索">内存受限搜索</h2>
<p>  束搜索（beam search）限定边界大小通过限定可扩展节点个数 或者只扩展
在最优f值一定范围内的节点数。</p>
<p>  迭代加深<span
class="math inline">\(A^\ast\)</span>搜索（iterative-deepening <span
class="math inline">\(A^\ast\)</span> search，ID<span
class="math inline">\(A^\ast\)</span>）
每次迭代更新截断的f值，新的f截断值为超过上一次迭代截断值的节点中最小的f代价。换句话说，每次迭代都会彻底地搜索一个f
等值线，找到一个刚好超出该等值线的节点，并使用该节点的f
代价作为下一个等值线。</p>
<p>递归最佳优先搜索（recursive best-first search，RBFS）</p>
<p>  使用$f_limit
$变量跟踪从当前节点的任意祖先节点可得到的最优备选路径的f
值。如果当前节点超过了这个限制，那么递归将回到备选路径上。随着递归的展开，RBFS
将路径上每个节点的f 值替换为一个倒推值（backed-up
value）——其子节点的最优f 值。通过这种方式，RBFS
可以记住被它遗忘的子树中最优叶节点的f 值，因此，在之后的某个时刻，RBFS
可以决定是否要重新扩展该子树。</p>
<hr />
<p><strong>function</strong> Recursive-Best-First-Search(problem)
<strong>returns</strong> 一个解或者failure<br> solution, fvalue ←
RBFS(problem, Node(problem.Initial), ∞)<br><br />
<strong>return</strong> solution<br><br />
<strong>function</strong> RBFS(problem, node, f_limit) returns
一个解或failure，以及一个新的 f代价限制<br><br />
 <strong>if</strong> problem.Is-Goal(node.State) <strong>then
return</strong> node<br><br />
successors ← list(Expand(node))<br><br />
 <strong>if</strong> successors为空 <strong>then return
failure</strong>, ∞<br><br />
 <strong>for each</strong> s <strong>in</strong> successors
<strong>do</strong> //用前一次搜索中的值更新 f<br><br />
  s.f ← max(s.Path-Cost + h(s), node.f )<br><br />
<strong>while</strong> true <strong>do</strong><br><br />
 best ← successors 中 f 值最低的节点<br><br />
 <strong>if </strong>best. f &gt;f_limit <strong>then return</strong>
failure, best. f<br><br />
 alternative ← successors中第二低的 f 值<br><br />
 result, best. f ← RBFS(problem, best, min(f_limit,
alternative))<br><br />
 <strong>if</strong> result<span class="math inline">\(\neq\)</span>
failure <strong>then return</strong> result, best. f<br></p>
<hr />
<p>  有多少可用内存使用多少内存的算法 <span
class="math inline">\(MA^\ast\)</span>（memory-bounded <span
class="math inline">\(A^\ast\)</span>，内存受限的<span
class="math inline">\(A^\ast\)</span>）和<span
class="math inline">\(SMA^\ast\)</span>（simplified <span
class="math inline">\(MA^\ast\)</span>，简化的<span
class="math inline">\(MA^\ast\)</span>）。<span
class="math inline">\(SMA^\ast\)</span> 像<span
class="math inline">\(A^\ast\)</span>一样，但是当内存满时，它不在添加节点
除非它判断以后删除最老的最差叶节点。和RBFS 一样，SMA*
将被遗忘节点的值备份到其父节点。</p>
<h2 id="双向启发式搜索">双向启发式搜索</h2>
<p>  考虑启发函数的双向最佳优先搜索。正向搜索用<span
class="math inline">\(f_F(n)=g_F(n)+h_F(n)\)</span>作为评价函数，反向搜索用<span
class="math inline">\(f_B(n)=g_B(n)+h_B(n)\)</span>作为评价函数。他们拥有不同的评价函数。</p>
<p>解代价的下界</p>
<p><span class="math display">\[
lb(m,n)=max(g_F(m)+g_B(n),f_F(m),f_B(n))
\]</span></p>
<h1 id="启发式函数">3.6　启发式函数</h1>
<p>  一种描述启发式函数质量的方法是<strong>有效分支因子（effective
branching factor）</strong><span
class="math inline">\(b^\ast\)</span>。如果针对一个特定问题，<span
class="math inline">\(A^\ast\)</span>
搜索所生成的总节点数是n，而解的深度是d，那么<span
class="math inline">\(b^\ast\)</span> 就是深度为d 的均衡树要包含n + 1
个节点所必需的分支因子。因此有</p>
<p><span class="math display">\[
n+1=1+b^\ast+(b^\ast)^2+...+(b^\ast)^d=\frac{1-(b^\ast)^{d+1}}{1-b^\ast}
\]</span><br />
  科尔夫和里德（Korf and Reid,
1998）提出了另一个刻画对于一个使用给定启发式函数h 的<span
class="math inline">\(A^\ast\)</span> 剪枝效果的概念:
相对于不使用启发函数的算法所用有效深度的减小量<span
class="math inline">\(k_h\)</span> ,即无信息搜索的代价为<span
class="math inline">\(O(b^d)\)</span> 使用启发函数后代价为<span
class="math inline">\(O(b^{d-k_h})\)</span> 。</p>
<p>  对于同一个问题当一个启发函数<span
class="math inline">\(h_1\)</span>
在每个节点的值总是大于等于另一个启发函数<span
class="math inline">\(h_2\)</span> 时 我们说<span
class="math inline">\(h_1\)</span> 占优于 <span
class="math inline">\(h_2\)</span> 。</p>
<h2 id="从松弛问题出发生成启发式函数">从松弛问题出发生成启发式函数</h2>
<p>  启发函数很重要
那么如何找到好的启发函数或者如何让计算机自动找到一个启发函数呢?我们可以通过求解一个原问题的<strong>松弛问题（relaxed
problem）</strong>的最优代价解作为启发函数。所谓松弛问题就是减少动作限制的问题，它的状态空间比原问题多了一些边，可以简单的理解为是一个相对简化的问题。我们可以删除一两个条件构造松弛问题。</p>
<p>  如果一个可容许的启发式函数集合<span class="math inline">\(h_1, …,
h_m\)</span>
可以求解同一个问题，但没有一个函数明显优于其他函数，那么我们应该选择哪个函数？事实证明，我们可以通过如下定义，得到最优的启发式函数：</p>
<p><span class="math display">\[
h(n)=max\left\{h_1(n),..,h_k(n)\right\}
\]</span><br />
  这种复合启发式函数将选择对于所讨论节点最准确的函数。因为<span
class="math inline">\(h_i\)</span> 都是可容许的，所以h
也是可容许的（如果<span class="math inline">\(h_i\)</span>
都是一致的，则h 也是一致的）。此外，h
优于所有组成它的启发式函数。唯一的缺点是<span
class="math inline">\(h(n)\)</span>
的计算时间更长。如果考虑这一问题，另一种选择是在每次评价时随机选择一个启发式函数，或者使用机器学习算法来预测哪个启发式函数是最优的。这样做可能会导致启发式函数失去一致性（即使每个<span
class="math inline">\(h_i\)</span>
都是一致的），但在实践中，它通常能更快地求解问题。</p>
<h2
id="从子问题出发生成启发式函数模式数据库">从子问题出发生成启发式函数：模式数据库</h2>
<p>  <strong>模式数据库（pattern
database）</strong>的思想是为每个可能的子问题存储准确的解代价。然后，通过在数据库中查找相应的子问题，为搜索过程中遇到的每个状态计算一个可容许的启发式函数<span
class="math inline">\(h_{DB}\)</span>。</p>
<p>  子问题和松弛问题区别在于 子问题状态数小于原问题
,而松弛问题状态数和原问题相同只是多了一些边。</p>
<p>  当原问题可以被划分成若干个子问题且这些问题解不重叠
我们可以建立一个<strong>不相交模式数据库（disjoint pattern
database）</strong>并且把其中每个子问题的解构成复合启发式函数。</p>
<h2 id="使用地标生成启发式函数">使用地标生成启发式函数</h2>
<p>为了减少搜索时间我们可以使用<strong>预计算（precomputation）</strong>技巧，比如
先花费时间计算各个顶点的最优路径存储下 以满足以后用户的搜索需求。</p>
<p>如果简单的进行每个顶点的预计算需要花费大量时间和储存是不太明智的。更好的方法是从顶点中选择一些（也许10
个或20 个）<strong>地标点（landmark
point)</strong>L，然后计算存储各个顶点v到地标L的最优代价<span
class="math inline">\(C^\ast(v,L)\)</span>（以及地标到顶点的<span
class="math inline">\(C^\ast(L,v)\)</span>
对于无向图则不用），最后构造出</p>
<p><span class="math display">\[
h_L(n)= min C^\ast(n,L)+C^\ast(L,goal)
\]</span><br />
<span
class="math inline">\(h_L(n)\)</span>是高效的，但不是可容许的。只要稍加注意，我们就可以提出一种既高效又可容许的启发式函数:</p>
<p><span class="math display">\[
h_{DH}(n)= max |C^\ast(n,L)-C^\ast(L,goal)|
\]</span></p>
<p>这被称为<strong>差分启发式（differential
heuristic）</strong>函数（因为包含减法）。可以把它理解为在比目标还要远的某个位置设置一个地标点。如果目标恰好在从n
到该地标点的最优路径上，那么“考<br />
虑从n 到L 的完整路径，然后减去这条路径的最后一部分，即从goal
到L，即可得到从n 到goal
的这段路径的准确代价”。如果目标稍微偏离到地标的最优路径，启发式函数将是不准确的，但仍然是可容许的。比目标近的地标是没有用的；例如，一个恰好位于n
和goal 正中间的地标将导致<span class="math inline">\(h_{DH} =
0\)</span>，这是没有用的。</p>
<p>介绍几种选择地标点的方法。</p>
<ul>
<li>贪心方法是随机选择第一个地标，然后找到离它最远的点，将其添加到地标集合中，接着在每次迭代中添加离最近地标最远的点。</li>
<li>如果通过用户过去的搜索请求日志，那么选择搜索中经常请求的地点作为地标。</li>
<li>对于差分启发式函数，地标分布在图的周界上更好。因此，一个比较好的技术是找到图的质心，围绕质心划分出k
个楔形（就像饼状图一样），并在每个楔形中选择离中心最远的顶点。</li>
</ul>
<p>一些寻径算法通过在图中添加<strong>捷径（shortcut）</strong>——人工定义的对应于一条最优多行动路径的边——来节省更多的时间。</p>
<p>我们还可以人为考虑几个与问题有关的状态特征，然后把他们线性组合得到启发函数。</p>
<p>我们也可以期盼智能体从搜索过程中产生的搜索树序列（<strong>元级状态空间（metalevel
state space）</strong>）里学习优化搜索的方法
即<strong>元级学习（metalevel learning）</strong></p>
<h1 id="参考">参考</h1>
<p>Artificial Intelligence: A Modern Approach, Fourth Edition人工智能:
现代方法（第4 版）[ 美] 斯图尔特• 罗素（Stuart Russell） 著 彼得•
诺维格（Peter Norvig） 张博雅 陈坤 田超 顾卓尔 吴凡 赵申剑 译 张志华
审校 人 民 邮 电 出 版 社</p>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>(b为节点d为深度)<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>(<span class="math inline">\(C^*\)</span> 算法最优代价
<span class="math inline">\(\epsilon\)</span>每个动作下界 &gt;0)<a
href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能 现代方法 第二章读书笔记(持续更新）</title>
    <url>/post/eb31a1ba.html</url>
    <content><![CDATA[<h1 id="占个位置">占个位置</h1>
<span id="more"></span>
]]></content>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>用hexo搭建博客的尝试</title>
    <url>/post/4a17b156.html</url>
    <content><![CDATA[<h2 id="github准备">github准备</h2>
<span id="more"></span>
<h2 id="node.js-安装">Node.js 安装</h2>
<h2 id="hexo安装">hexo安装</h2>
<p>hexo命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo clean &amp;&amp;hexo g &amp;&amp; hexo s</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo d</span><br></pre></td></tr></table></figure>
<h2 id="使用buttfly主题">使用buttfly主题</h2>
<h2 id="写博客">写博客</h2>
<p><code>hexo new [layout]  &lt;title&gt;</code></p>
<p>比如 <code>hexo new "时间序列比赛(一)"</code></p>
<h2
id="npm查看已安装的包全局和本地">npm查看已安装的包（全局、和本地）</h2>
<p>查看全局已安装（-g 的意思是 global 全局的意思）<br />
<code>npm ls -g</code><br />
加上层级控制显示深度：<code>--depth 0</code><br />
<code>npm ls -g --depth 0</code><br />
查看项目中已安装<br />
<code>npm ls</code><br />
如果只想显示生产环境依赖的包<br />
<code>npm ls --depth 0 --prod</code><br />
只显示开发环境依赖的包<br />
<code>npm ls --depth 0 --dev</code></p>
<h2 id="hexo-多种markdown渲染器对比分析">Hexo
多种Markdown渲染器对比分析</h2>
<p>https://zsyyblog.com/b73ceb85.html</p>
]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title>mkk</title>
    <url>/post/e3278bdd.html</url>
    <content><![CDATA[<h1 align="center">
MKK
</h1>
<span id="more"></span>
<hr />
<center>
<img src="../../public/img/favicon.png">
</center>
<h2 id="install-from-butterfly">Install from butterfly</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone -b dev https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly</span><br></pre></td></tr></table></figure>
<h2 id="licence">Licence</h2>
<p>MIT</p>
]]></content>
      <tags>
        <tag>介绍</tag>
      </tags>
  </entry>
</search>
